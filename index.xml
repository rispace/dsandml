<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Mohammad Rafiqul Islam</title>
<link>https://mrislambd.github.io/</link>
<atom:link href="https://mrislambd.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.5.54</generator>
<lastBuildDate>Mon, 02 Dec 2024 05:00:00 GMT</lastBuildDate>
<item>
  <title>Boosting Algorithm: Adaptive Boosting Method (AdaBoost)</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/adaboost/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Boosting is a powerful ensemble learning technique that focuses on improving the performance of weak learners to build a robust predictive model. <br> <br> Now the question is what the heck is weak learner? Well, roughly speaking, a statistical learning algorithm is called a weak learner if it is slightly better than just random guess. In contrast, a statistical learning algorithm is called a strong learner if it can be made arbitrarily close to the true value.<br> <br> Unlike bagging (bootstrap aggregating, e.g.&nbsp;random forest), which builds models independently, boosting builds models sequentially, where each new model corrects the errors of its predecessors. This approach ensures that the ensemble concentrates on the difficult-to-predict instances, making boosting highly effective for both classification and regression problems.
</p>
<section id="key-characteristics-of-boosting" class="level3">
<h3 class="anchored" data-anchor-id="key-characteristics-of-boosting">Key Characteristics of Boosting:</h3>
<ol type="1">
<li><strong>Sequential Model Building:</strong> Boosting builds one model at a time, with each model improving upon the errors of the previous one.</li>
<li><strong>Weight Assignment:</strong> It assigns weights to instances, emphasizing misclassified or poorly predicted ones in subsequent iterations.</li>
<li><strong>Weak to Strong Learners:</strong> The goal of boosting is to combine multiple weak learners (models slightly better than random guessing) into a strong learner.</li>
</ol>
</section>
<section id="mathematical-visualization" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-visualization">Mathematical Visualization</h3>
<p>Before writing the formal algorithm, let’s do some math by hand. Say, we have a toy dataset:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><img src="https://latex.codecogs.com/png.latex?x_1"></th>
<th><img src="https://latex.codecogs.com/png.latex?x_2"></th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>2</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>3</td>
<td>2</td>
<td>-1</td>
</tr>
<tr class="even">
<td>4</td>
<td>3</td>
<td>-1</td>
</tr>
</tbody>
</table>
<p>Here:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2"> are features.</li>
<li><img src="https://latex.codecogs.com/png.latex?y"> is the target label, with values <img src="https://latex.codecogs.com/png.latex?+1"> or <img src="https://latex.codecogs.com/png.latex?-1">.</li>
</ul>
<p>Now, let’s apply the AdaBoost algorithm step-by-step using this dataset.</p>
<section id="iteration-1" class="level4">
<h4 class="anchored" data-anchor-id="iteration-1">Iteration 1</h4>
<p><em>Step 1: Initialize Weights</em><br>
Initially, all data points are assigned equal weights: <img src="https://latex.codecogs.com/png.latex?%0Aw_i%5E%7B(1)%7D%20=%20%5Cfrac%7B1%7D%7BN%7D%20=%20%5Cfrac%7B1%7D%7B4%7D%20=%200.25%0A"></p>
<p>Weights: <img src="https://latex.codecogs.com/png.latex?w%20=%20%5B0.25,%200.25,%200.25,%200.25%5D">.</p>
<p><em>Step 2: Train Weak Learner</em></p>
<p>Suppose we use a decision stump (a simple decision rule) as the weak learner. The first decision stump might split on <img src="https://latex.codecogs.com/png.latex?x_1"> as:</p>
<ul>
<li>Predict <img src="https://latex.codecogs.com/png.latex?+1"> if <img src="https://latex.codecogs.com/png.latex?x_1%20%5Cleq%201.5">, otherwise <img src="https://latex.codecogs.com/png.latex?-1">.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah_1(x)%20=%0A%5Cbegin%7Bcases%7D%0A+1%20&amp;%20%5Ctext%7Bif%20%7D%20x_1%20%5Cleq%201.5%20%5C%5C%0A-1%20&amp;%20%5Ctext%7Botherwise%7D%0A%5Cend%7Bcases%7D%0A"></p>
<p style="text-align: justify">
Note, that even though we are deciding based on the feature <img src="https://latex.codecogs.com/png.latex?x_1">, however, for <img src="https://latex.codecogs.com/png.latex?h_1(x)"> learner, <img src="https://latex.codecogs.com/png.latex?x"> is the row from the data set, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?x=%5Bx_1,%20x_2%5D">. Therefore, for <img src="https://latex.codecogs.com/png.latex?h_1(x_1)"> would mean that, we are feeding first row to the learner <img src="https://latex.codecogs.com/png.latex?h"> at iteration 1.
</p>
<p><em>Step 3: Evaluate Weak Learner</em></p>
<p>Predictions for the dataset: <img src="https://latex.codecogs.com/png.latex?%0Ah_1(x)%20=%20%5B1,%20-1,%20-1,%20-1%5D%0A"></p>
<p>But our true labels are <img src="https://latex.codecogs.com/png.latex?%5B1,1,-1,-1%5D">. So the error</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cepsilon_1%20=%20%5Cfrac%7B%5Csum_%7Bi=1%7D%5E%7B4%7Dw_i%5E1%20%5Cmathbb%7B1%7D(y_i%5Cne%20h_1(x_i))%7D%7B%5Csum_%7Bi=1%7D%5E%7B4%7Dw_i%5E1%7D%0A"></p>
<p>where, <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7B1%7D"> is an indicator function that equals 1 when the prediction is incorrect and 0 otherwise. Therefore, in iteration 1:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cepsilon_1%20=%20%5Cfrac%7B0.25(0+1+0+0)%7D%7B1%7D=0.25%0A"></p>
<p><em>Step 4: Calculate <img src="https://latex.codecogs.com/png.latex?%5Calpha_1"></em><br>
<img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_1%20=%20%5Cln%5Cleft(%5Cfrac%7B1%20-%20%5Cepsilon_1%7D%7B%5Cepsilon_1%7D%5Cright)%20=%201.0986%0A"></p>
<p><em>Step 5: Update Weights:</em></p>
<p>For each instance:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%20w_i%5E%7B(1)%7D%20=%20w_i%5E%7B(1)%7D%20%5Ccdot%20%5Cexp%5Cleft(%5Calpha_1%20%5Ccdot%20y_i%20%5Ccdot%20h_1(x_i)%5Cright)%0A"></p>
<p>Now you may wonder how and from where we came up with this updating rule? We will explain this update process in the next post, but for now let’s just focus on the update.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Aw_1%5E1%20&amp;%20=%20w_1%5E1e%5E%7B%5Calpha_1%5Cmathbb%7B1%7D(y_1%5Cne%20h_1(x_1))%7D%20=%200.25%20e%5E%7B1.0986%5Ctimes%200%7D%20=%200.25%20%5C%5C%0Aw_2%5E1%20&amp;%20=%20w_2%5E1e%5E%7B%5Calpha_1%5Cmathbb%7B1%7D(y_1%5Cne%20h_1(x_2))%7D%20=%200.25%20e%5E%7B1.0986%5Ctimes%201%7D%20=%200.75%20%5C%5C%0Aw_3%5E1%20&amp;%20=%20w_3%5E1e%5E%7B%5Calpha_1%5Cmathbb%7B1%7D(y_1%5Cne%20h_1(x_3))%7D%20=%200.25%20e%5E%7B1.0986%5Ctimes%200%7D%20=%200.25%20%5C%5C%0Aw_4%5E1%20&amp;%20=%20w_4%5E1e%5E%7B%5Calpha_1%5Cmathbb%7B1%7D(y_1%5Cne%20h_1(x_4))%7D%20=%200.25%20e%5E%7B1.0986%5Ctimes%200%7D%20=%200.25%20%5C%5C%0A%5Cend%7Balign*%7D"></p>
<p>Updated weights (before normalization): <img src="https://latex.codecogs.com/png.latex?%0A%5B0.25,%200.75,%200.25,%200.25%5D%0A"></p>
<p>Normalize to ensure the weights sum to 1:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%20w_i%5E%7B(1)%7D%20=%20%5Cfrac%7Bw_i%5E%7B(1)%7D%7D%7B%5Csum%20w_i%5E%7B(1)%7D%7D%0A"></p>
<p>Final normalized weights: <img src="https://latex.codecogs.com/png.latex?w%20=%20%5B0.17,%200.5,%200.17,%200.17%5D">. Notice that, for the incorrect prediction, the weight increased and for the correct prediction the weights decreased.</p>
</section>
<section id="iteration-2" class="level4">
<h4 class="anchored" data-anchor-id="iteration-2">Iteration 2</h4>
<p>Similarly, we proceed with second iteration with the following weak learner:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah_2(x)%20=%20%5Cbegin%7Bcases%7D+1%20&amp;%20%5Ctext%7Bif%7D%20x_2%5Cle%201.5%20%5C%5C%20-1%20&amp;%20%5Ctext%7Botherwise%7D%5Cend%7Bcases%7D%0A"></p>
<p>For this learner, the prediction</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah_2(x)=%20%5B-1,%201,%20-1,%20-1%5D%0A"></p>
<p>where as the actual labels are <img src="https://latex.codecogs.com/png.latex?%5B1,1,-1,1%5D">. So, the error</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cepsilon_2%20=%20%5Cfrac%7B0.17%5Ctimes%201%20+%200.5%5Ctimes%200+0.17%5Ctimes%200+0.17%5Ctimes%200%7D%7B1%7D%20=%200.17%0A"></p>
<p>and</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_2%20=%20%5Cln%5Cleft(%5Cfrac%7B0.756%7D%7B0.244%7D%5Cright)%20=%201.586%0A"></p>
<p>Next, we update the weights</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Aw_1%5E%7B2%7D%20&amp;=%20w_1%5E2%20e%5E%7B%5Calpha_2%5Cmathbb%7B1%7D(y_1%20%5Cne%20h_2(x_1))%7D%20=%200.17%20e%5E%7B1.586%5Ctimes%201%7D%20=%200.83%5C%5C%0Aw_2%5E%7B2%7D%20&amp;=%20w_2%5E2%20e%5E%7B%5Calpha_2%5Cmathbb%7B1%7D(y_1%20%5Cne%20h_2(x_2))%7D%20=%200.5%20e%5E%7B1.1308%5Ctimes%200%7D%20=%200.5%5C%5C%0Aw_3%5E%7B2%7D%20&amp;=%20w_3%5E2%20e%5E%7B%5Calpha_2%5Cmathbb%7B1%7D(y_1%20%5Cne%20h_2(x_1))%7D%20=%200.17%20e%5E%7B1.586%5Ctimes%200%7D%20=%200.17%5C%5C%0Aw_4%5E%7B2%7D%20&amp;=%20w_4%5E2%20e%5E%7B%5Calpha_2%5Cmathbb%7B1%7D(y_1%20%5Cne%20h_2(x_1))%7D%20=%200.17%20e%5E%7B1.586%5Ctimes%200%7D%20=%200.17%5C%5C%0A%5Cend%7Balign*%7D"></p>
<p>So, <img src="https://latex.codecogs.com/png.latex?w=%5B0.83,0.5,0.17,0.17%5D"> and after normalizing <img src="https://latex.codecogs.com/png.latex?w=%5B0.50,0.3,0.10,0.10%5D">. The final ensemble model combines the weak learners using their weights (<img src="https://latex.codecogs.com/png.latex?%5Calpha">):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF(x)%20=%20%5Ctext%7Bsign%7D%5Cleft(%5Calpha_1%20%5Ccdot%20h_1(x)%20+%20%5Calpha_2%20%5Ccdot%20h_2(x)%5Cright)%0A"></p>
<p>For the toy dataset:</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_1%20=%201.0986">, <img src="https://latex.codecogs.com/png.latex?h_1(x)%20=%20%5B1,%20-1,%20-1,%20-1%5D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_2%20=%201.586">, <img src="https://latex.codecogs.com/png.latex?h_2(x)%20=%20%5B-1,%201,%20-1,%20-1%5D"></li>
</ol>
<p>Weighted predictions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AF(x)%20&amp;=%20%5Cleft(%5Calpha_1%20%5Ccdot%20h_1(x)%20+%20%5Calpha_2%20%5Ccdot%20h_2(x)%5Cright)%5C%5C%0A&amp;%20=%20%5B1.0986-1.586,-1.0986+1.586,-1.0986-1.586,-1.0986-1.586%5D%5C%5C%0A&amp;%20=%20%5B-1,%201,%20-1,%20-1%5D%0A%5Cend%7Balign*%7D"></p>
<p>If we keep iterating this way, we will have</p>
<div id="c10a292f" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np </span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mywebstyle <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_style</span>
<span id="cb1-4">plot_style(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data points for visualization</span></span>
<span id="cb1-7">iterations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb1-8">errors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.167</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Errors from the two iterations</span></span>
<span id="cb1-9">alphas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0968</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.586</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Alpha values for the weak learners</span></span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Extend to further iterations</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulating error reduction and alpha calculation for a few more iterations</span></span>
<span id="cb1-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>):  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterations 3 to 5</span></span>
<span id="cb1-14">    new_error <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> errors[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simulating decreasing errors</span></span>
<span id="cb1-15">    errors.append(new_error)</span>
<span id="cb1-16">    alphas.append( np.log((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> new_error) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> new_error))</span>
<span id="cb1-17">    iterations.append(i)</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot weighted errors over iterations</span></span>
<span id="cb1-20">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-21">plt.plot(iterations, errors, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb1-22">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Weighted Error Reduction Over Iterations in AdaBoost"</span>)</span>
<span id="cb1-23">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Iteration"</span>)</span>
<span id="cb1-24">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Weighted Error"</span>)</span>
<span id="cb1-25">plt.grid()</span>
<span id="cb1-26">plt.show()</span>
<span id="cb1-27"></span>
<span id="cb1-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot alpha values (importance of weak learners)</span></span>
<span id="cb1-29">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-30">plt.plot(iterations, alphas, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>)</span>
<span id="cb1-31">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alpha Values Over Iterations in AdaBoost"</span>)</span>
<span id="cb1-32">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Iteration"</span>)</span>
<span id="cb1-33">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Alpha (Learner Weight)"</span>)</span>
<span id="cb1-34">plt.grid()</span>
<span id="cb1-35">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/adaboost/index_files/figure-html/cell-2-output-1.png" width="684" height="529" class="figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/adaboost/index_files/figure-html/cell-2-output-2.png" width="675" height="529" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="adaptive-boosting-adaboost-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="adaptive-boosting-adaboost-algorithm">Adaptive Boosting (AdaBoost) Algorithm</h2>
<p style="text-align: justify">
Now it’s time to write the formal algorithm for Adaptive Boosting or AdaBoost method. It is one of the earliest and most widely used boosting algorithms. It was introduced by Freund and Schapire in 1996. AdaBoost combines weak learners, typically decision stumps (single-level decision trees), to form a strong learner.
</p>
<table class="caption-top table">
<colgroup>
<col style="width: 100%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Algorithm:</strong> AdaBoost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Initialize the observation weights <img src="https://latex.codecogs.com/png.latex?w_i=%5Cfrac%7B1%7D%7BN%7D"> for <img src="https://latex.codecogs.com/png.latex?i=1,2,%5Ccdots,%20N"> <br> 2. For <img src="https://latex.codecogs.com/png.latex?m=1"> to <img src="https://latex.codecogs.com/png.latex?M">: <br> &nbsp; (a) Fit a classifier <img src="https://latex.codecogs.com/png.latex?G_m(x)"> to the training data using weights <img src="https://latex.codecogs.com/png.latex?w_i"> <br> &nbsp; (b) Compute <br>&nbsp;&nbsp;&nbsp; <img src="https://latex.codecogs.com/png.latex?err_m=%5Cfrac%7B%5Csum_%7Bi=1%7D%5E%7BN%7Dw_i%5Cmathbb%7B1%7D(y_i%5Cne%20G_m(x_i))%7D%7B%5Csum_%7Bi=1%7D%5E%7BN%7Dw_i%7D"><br> &nbsp; (c) Compute <img src="https://latex.codecogs.com/png.latex?%5Calpha_m%20=%20%5Clog%5Cleft(%5Cfrac%7B1-err_m%7D%7Berr_m%7D%5Cright)"><br>&nbsp; (d) Set <img src="https://latex.codecogs.com/png.latex?w_i%20%5Crightarrow%20w_i%5Ccdot%20%5Cexp%7B%5Cleft%5B%5Calpha_m%5Ccdot%5Cmathbb%7B1%7D(y_i%5Cne%20G_m(x_i))%5Cright%5D%7D,%5Chspace%7B2mm%7D%20i=1,2,%5Ccdots,%20N"><br> 3. Output <img src="https://latex.codecogs.com/png.latex?G(x)=%5Ctext%7Bsign%7D%5Cleft%5B%5Csum_%7Bm=1%7D%5E%7BM%7D%5Calpha_mG_m(x)%5Cright%5D"></td>
</tr>
</tbody>
</table>
<p>In the next posts, we will continue discussing on this algorithm, specially the loss function, optimization techniques, advantages and limitations of AdaBoost, and many other facts about this algorithm.</p>
<p>Thanks for reading this.</p>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<ul>
<li>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. “The elements of statistical learning: data mining, inference, and prediction.” (2017).</li>
</ul>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/adaboost/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/adaboost/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742011326859" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1729137600000" data-listing-file-modified-sort="1742010631607" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="27" data-listing-word-count-sort="5383">
<a href="../../posts/lda/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/lda/lda.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Linear Discriminant Analysis (LDA)
</h5>
<div class="listing-reading-time card-text text-muted">
27 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 17, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Boosting {Algorithm:} {Adaptive} {Boosting} {Method}
    {(AdaBoost)}},
  date = {2024-12-02},
  url = {https://mrislambd.github.io/posts/adaboost/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Boosting Algorithm: Adaptive Boosting Method
(AdaBoost).”</span> December 2, 2024. <a href="https://mrislambd.github.io/posts/adaboost/">https://mrislambd.github.io/posts/adaboost/</a>.
</div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Data Science</category>
  <category>Bayesian Inference</category>
  <category>Bayesian Statistics</category>
  <category>Statistics</category>
  <guid>https://mrislambd.github.io/posts/adaboost/</guid>
  <pubDate>Mon, 02 Dec 2024 05:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/adaboost/ada1.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Exploratory Data Analysis (EDA) and Data Visualization</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/eda/</link>
  <description><![CDATA[ 




<p>In this Exploratory Data Analysis and Visualization notebook, we want to explore the <a href="https://www.kaggle.com/datasets/mchirico/montcoalert" target="_blank" style="text-decoration:none">911 call data from Kaggle.com</a></p>
<section id="the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-dataset">The Dataset</h2>
<div id="c16eda6c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'911.csv'</span>)</span></code></pre></div>
</div>
</section>
<section id="discriptive-statistics" class="level2">
<h2 class="anchored" data-anchor-id="discriptive-statistics">Discriptive Statistics</h2>
<p>We first check the data information to see the number of observations, datatype, memory usages etc.</p>
<div id="103237d4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">df.info()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 105957 entries, 0 to 105956
Data columns (total 9 columns):
 #   Column     Non-Null Count   Dtype  
---  ------     --------------   -----  
 0   lat        105957 non-null  float64
 1   lng        105957 non-null  float64
 2   desc       105957 non-null  object 
 3   zip        92735 non-null   float64
 4   title      105957 non-null  object 
 5   timeStamp  105957 non-null  object 
 6   twp        105924 non-null  object 
 7   addr       105957 non-null  object 
 8   e          105957 non-null  int64  
dtypes: float64(3), int64(1), object(5)
memory usage: 7.3+ MB</code></pre>
</div>
</div>
<p>A first look of the data</p>
<div id="eb0354eb" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">lng</th>
<th data-quarto-table-cell-role="th">desc</th>
<th data-quarto-table-cell-role="th">zip</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">timeStamp</th>
<th data-quarto-table-cell-role="th">twp</th>
<th data-quarto-table-cell-role="th">addr</th>
<th data-quarto-table-cell-role="th">e</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>40.297876</td>
<td>-75.581294</td>
<td>REINDEER CT &amp; DEAD END; NEW HANOVER; Station ...</td>
<td>19525.0</td>
<td>EMS: BACK PAINS/INJURY</td>
<td>12/10/15 17:10</td>
<td>NEW HANOVER</td>
<td>REINDEER CT &amp; DEAD END</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>40.258061</td>
<td>-75.264680</td>
<td>BRIAR PATH &amp; WHITEMARSH LN; HATFIELD TOWNSHIP...</td>
<td>19446.0</td>
<td>EMS: DIABETIC EMERGENCY</td>
<td>12/10/15 17:29</td>
<td>HATFIELD TOWNSHIP</td>
<td>BRIAR PATH &amp; WHITEMARSH LN</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>40.121182</td>
<td>-75.351975</td>
<td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>
<td>19401.0</td>
<td>Fire: GAS-ODOR/LEAK</td>
<td>12/10/15 14:39</td>
<td>NORRISTOWN</td>
<td>HAWS AVE</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>40.116153</td>
<td>-75.343513</td>
<td>AIRY ST &amp; SWEDE ST; NORRISTOWN; Station 308A;...</td>
<td>19401.0</td>
<td>EMS: CARDIAC EMERGENCY</td>
<td>12/10/15 16:47</td>
<td>NORRISTOWN</td>
<td>AIRY ST &amp; SWEDE ST</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>40.251492</td>
<td>-75.603350</td>
<td>CHERRYWOOD CT &amp; DEAD END; LOWER POTTSGROVE; S...</td>
<td>NaN</td>
<td>EMS: DIZZINESS</td>
<td>12/10/15 16:56</td>
<td>LOWER POTTSGROVE</td>
<td>CHERRYWOOD CT &amp; DEAD END</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Some data related questions. For example,</p>
<ul>
<li><p>What are the top 10 zipcodes for 911 calls?</p>
<div id="25cb8d09" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>.value_counts().head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>zip
19401.0    7445
19464.0    7122
19403.0    5189
19446.0    5060
19406.0    3404
19002.0    3238
19468.0    3202
19454.0    2984
19090.0    2832
19046.0    2779
Name: count, dtype: int64</code></pre>
</div>
</div></li>
<li><p>What are the top 10 twonships for the 911 calls?</p>
<div id="f1d52bd1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">df.twp.value_counts().head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>twp
LOWER MERION        9069
ABINGTON            6403
NORRISTOWN          6265
UPPER MERION        5551
CHELTENHAM          4882
POTTSTOWN           4448
UPPER MORELAND      3658
LOWER PROVIDENCE    3435
PLYMOUTH            3371
HORSHAM             3142
Name: count, dtype: int64</code></pre>
</div>
</div></li>
</ul>
</section>
<section id="feature-engineering" class="level2">
<h2 class="anchored" data-anchor-id="feature-engineering">Feature Engineering</h2>
<p>Sometimes creating new features from the existing features helps understand the data better. For example, for this dataset, we can create a new column called <code>Reason</code> for emergency 911 call.</p>
<div id="e97f2b19" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.title.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> title: title.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">':'</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb9-2">df.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">lng</th>
<th data-quarto-table-cell-role="th">desc</th>
<th data-quarto-table-cell-role="th">zip</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">timeStamp</th>
<th data-quarto-table-cell-role="th">twp</th>
<th data-quarto-table-cell-role="th">addr</th>
<th data-quarto-table-cell-role="th">e</th>
<th data-quarto-table-cell-role="th">reason</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>40.297876</td>
<td>-75.581294</td>
<td>REINDEER CT &amp; DEAD END; NEW HANOVER; Station ...</td>
<td>19525.0</td>
<td>EMS: BACK PAINS/INJURY</td>
<td>12/10/15 17:10</td>
<td>NEW HANOVER</td>
<td>REINDEER CT &amp; DEAD END</td>
<td>1</td>
<td>EMS</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>40.258061</td>
<td>-75.264680</td>
<td>BRIAR PATH &amp; WHITEMARSH LN; HATFIELD TOWNSHIP...</td>
<td>19446.0</td>
<td>EMS: DIABETIC EMERGENCY</td>
<td>12/10/15 17:29</td>
<td>HATFIELD TOWNSHIP</td>
<td>BRIAR PATH &amp; WHITEMARSH LN</td>
<td>1</td>
<td>EMS</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>40.121182</td>
<td>-75.351975</td>
<td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>
<td>19401.0</td>
<td>Fire: GAS-ODOR/LEAK</td>
<td>12/10/15 14:39</td>
<td>NORRISTOWN</td>
<td>HAWS AVE</td>
<td>1</td>
<td>Fire</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>what are top reasons for the emergency calls?</p>
<div id="14b4b669" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">df.reason.value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>reason
EMS        52515
Traffic    37505
Fire       15937
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>visualization of the reason column</p>
<div id="82ddf841" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">sns.countplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.reason, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.reason, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/eda/index_files/figure-html/cell-9-output-1.png" width="610" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The <code>timeStamp</code> column contains time information year-month-day hour:minute:second format but in string value/object. So we can convert this column to obtain new features.</p>
<div id="0df6ec7b" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'timeStamp'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.to_datetime(df.timeStamp)</span>
<span id="cb13-2">time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.timeStamp.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/53/8y5n2fl55p3g3r5_pk9yfwk40000gn/T/ipykernel_51286/1994586768.py:1: UserWarning:

Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
</code></pre>
</div>
</div>
<p>Let’s create new features called <code>hour</code>, <code>month</code>, and <code>day</code> of the calls.</p>
<div id="ea03367b" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hour'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.timeStamp.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> time: time.hour)</span>
<span id="cb15-2">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'month'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.timeStamp.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> time: time.month)</span>
<span id="cb15-3">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'day'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.timeStamp.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> time: time.dayofweek)</span>
<span id="cb15-4">days <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb15-5">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Monday'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Tuesday'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Wednesday'</span>, </span>
<span id="cb15-6">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Thursday'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Friday'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Saturday'</span>,</span>
<span id="cb15-7">    <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Sunday'</span></span>
<span id="cb15-8">    }</span>
<span id="cb15-9">df.day <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.day.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(days)</span>
<span id="cb15-10">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[</span>
<span id="cb15-11">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lat'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lng'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'zip'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'twp'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'e'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>,</span>
<span id="cb15-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'month'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'day'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hour'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'title'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'timeStamp'</span>,</span>
<span id="cb15-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'desc'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'addr'</span>]</span>
<span id="cb15-14">    ]</span>
<span id="cb15-15">df.head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">lng</th>
<th data-quarto-table-cell-role="th">zip</th>
<th data-quarto-table-cell-role="th">twp</th>
<th data-quarto-table-cell-role="th">e</th>
<th data-quarto-table-cell-role="th">reason</th>
<th data-quarto-table-cell-role="th">month</th>
<th data-quarto-table-cell-role="th">day</th>
<th data-quarto-table-cell-role="th">hour</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">timeStamp</th>
<th data-quarto-table-cell-role="th">desc</th>
<th data-quarto-table-cell-role="th">addr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>40.297876</td>
<td>-75.581294</td>
<td>19525.0</td>
<td>NEW HANOVER</td>
<td>1</td>
<td>EMS</td>
<td>12</td>
<td>Thursday</td>
<td>17</td>
<td>EMS: BACK PAINS/INJURY</td>
<td>2015-12-10 17:10:00</td>
<td>REINDEER CT &amp; DEAD END; NEW HANOVER; Station ...</td>
<td>REINDEER CT &amp; DEAD END</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>40.258061</td>
<td>-75.264680</td>
<td>19446.0</td>
<td>HATFIELD TOWNSHIP</td>
<td>1</td>
<td>EMS</td>
<td>12</td>
<td>Thursday</td>
<td>17</td>
<td>EMS: DIABETIC EMERGENCY</td>
<td>2015-12-10 17:29:00</td>
<td>BRIAR PATH &amp; WHITEMARSH LN; HATFIELD TOWNSHIP...</td>
<td>BRIAR PATH &amp; WHITEMARSH LN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>40.121182</td>
<td>-75.351975</td>
<td>19401.0</td>
<td>NORRISTOWN</td>
<td>1</td>
<td>Fire</td>
<td>12</td>
<td>Thursday</td>
<td>14</td>
<td>Fire: GAS-ODOR/LEAK</td>
<td>2015-12-10 14:39:00</td>
<td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>
<td>HAWS AVE</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now that we have almost a clean dataset, we can analyze the reason column based on the days of the week or months of a year.</p>
<div id="9e6417ec" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">sns.countplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'day'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb16-2">plt.legend(bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, borderaxespad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-12-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/eda/index_files/figure-html/cell-12-output-1.png" width="716" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For the month column</p>
<div id="e6e3e5f8" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">sns.countplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'month'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb17-2">plt.legend(bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, borderaxespad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-13-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/eda/index_files/figure-html/cell-13-output-1.png" width="716" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>To create a time series data</p>
<div id="5da4c947" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'timeStamp'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> time: time.date())</span>
<span id="cb18-2">df.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>).count()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'twp'</span>].plot()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://mrislambd.github.io/posts/eda/index_files/figure-html/cell-14-output-1.png" width="575" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Now to see for each reason</p>
<div id="7c35c323" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">start_date <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.to_datetime(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2019-01-01'</span>)</span>
<span id="cb19-2"></span>
<span id="cb19-3"></span>
<span id="cb19-4">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.to_datetime(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>])</span>
<span id="cb19-5"></span>
<span id="cb19-6"></span>
<span id="cb19-7">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.9</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb19-8"></span>
<span id="cb19-9">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">311</span>)</span>
<span id="cb19-10">df[(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Traffic'</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> start_date)].groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>).count()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'twp'</span>].plot(ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax1)</span>
<span id="cb19-11"></span>
<span id="cb19-12">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">312</span>)</span>
<span id="cb19-13">df[(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Fire'</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> start_date)].groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>).count()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'twp'</span>].plot(ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax2)</span>
<span id="cb19-14"></span>
<span id="cb19-15">ax3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">313</span>)</span>
<span id="cb19-16">df[(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'reason'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'EMS'</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> start_date)].groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'date'</span>).count()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'twp'</span>].plot(ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax3)</span>
<span id="cb19-17"></span>
<span id="cb19-18">plt.tight_layout()</span>
<span id="cb19-19"></span>
<span id="cb19-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-15-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://mrislambd.github.io/posts/eda/index_files/figure-html/cell-15-output-1.png" width="749" height="566" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/eda/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/eda/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Exploratory {Data} {Analysis} {(EDA)} and {Data}
    {Visualization}},
  date = {2024-11-08},
  url = {https://mrislambd.github.io/posts/eda/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Exploratory Data Analysis (EDA) and Data
Visualization.”</span> November 8, 2024. <a href="https://mrislambd.github.io/posts/eda/">https://mrislambd.github.io/posts/eda/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/eda/</guid>
  <pubDate>Fri, 08 Nov 2024 05:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/eda/eda.png" medium="image" type="image/png" height="109" width="144"/>
</item>
<item>
  <title>Support Vector Machine (SVM) Algorithm</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/svm/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Support Vector Machines (SVM) is a powerful non-parametric supervised machine learning algorithm used for classification and, less commonly, regression tasks. Support Vector Machines are designed to find an optimal hyperplane that best separates data points into classes. The key idea behind SVMs is to maximize the margin between data points of different classes while minimizing classification errors. This leads to a robust decision boundary that generalizes well to unseen data.
</p>
</section>
<section id="the-mathematical-foundation-of-svm" class="level2">
<h2 class="anchored" data-anchor-id="the-mathematical-foundation-of-svm">The Mathematical Foundation of SVM</h2>
<p style="text-align:justify">
Consider a classification problem. Given a dataset <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_i,%20y_i)"> where <img src="https://latex.codecogs.com/png.latex?i%20=%201,%202,%20%5Cdots,%20N">, <img src="https://latex.codecogs.com/png.latex?x_i%5Cin%20%5Cmathbb%7BR%7D%5Ed"> represents the feature vector of the <img src="https://latex.codecogs.com/png.latex?i">-th sample, and <img src="https://latex.codecogs.com/png.latex?y_i%20%5Cin%20%5C%7B-1,%201%5C%7D"> represents the class label. The goal of SVM is to find a hyperplane that maximally separates the classes.
</p>
<section id="hyperplane-and-dicision-boundary" class="level3">
<h3 class="anchored" data-anchor-id="hyperplane-and-dicision-boundary">Hyperplane and Dicision Boundary</h3>
<dl>
<dt>Definition (Hyperplane)</dt>
<dd>
A hyperplane in an <img src="https://latex.codecogs.com/png.latex?n">-dimensional space is defined by: <img src="https://latex.codecogs.com/png.latex?%0Aw%5ET%20%5Cmathbf%7Bx%7D%20+%20b%20=%200%0A">
</dd>
</dl>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?w"> is the weight vector,</li>
<li><img src="https://latex.codecogs.com/png.latex?b"> is the bias term,</li>
<li><img src="https://latex.codecogs.com/png.latex?x"> is any point on the hyperplane.</li>
</ul>
<p>For a two-dimensional space, this hyperplane is simply a line. <img src="https://latex.codecogs.com/png.latex?%0Aw%5ET%5Cmathbf%7Bx%7D+b=0;%5Chspace%7B4mm%7D%5Cimplies%20w_0x+w_1y+b=0;%5Chspace%7B4mm%7D%5Cimplies%20y=%5Cfrac%7B-w_0x-b%7D%7Bw_1%7D%0A"></p>
<p>and for a three-dimensional space, this hyperplane is simply a 2D plane</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw%5ET%5Cmathbf%7Bx%7D+b=0;%5Chspace%7B4mm%7D%5Cimplies%20w_0x+w_1y+w_2z+b=0;%5Chspace%7B4mm%7D%5Cimplies%20z=%5Cfrac%7B-w_0x-w_1y-b%7D%7Bw_2%7D%0A"></p>
<div id="82f7e4dc" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mpl_toolkits.mplot3d <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Axes3D</span>
<span id="cb1-4"></span>
<span id="cb1-5">w_2d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb1-6">b_2d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">w_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb1-9">b_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decision_boundary_2d(x):</span>
<span id="cb1-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>w_2d[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>b_2d) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> w_2d[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> decision_boundary_3d(x, y):</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>w_3d[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>w_3d[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>b_3d) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> w_3d[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb1-16"></span>
<span id="cb1-17">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-18">class1x_2d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb1-19">class2x_2d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb1-20"></span>
<span id="cb1-21">class1x_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">90</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb1-22">class2x_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">90</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb1-23"></span>
<span id="cb1-24">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure( figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.9</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb1-25">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">121</span>)</span>
<span id="cb1-26">x_vals_2d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-27">plt.plot(</span>
<span id="cb1-28">    x_vals_2d, decision_boundary_2d(x_vals_2d),</span>
<span id="cb1-29">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k-'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Decision Boundary (Hyperplane)"</span></span>
<span id="cb1-30">    )</span>
<span id="cb1-31">ax1.scatter(</span>
<span id="cb1-32">    class1x_2d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], class1x_2d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>,</span>
<span id="cb1-33">    marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class +1'</span></span>
<span id="cb1-34">    )</span>
<span id="cb1-35">ax1.scatter(</span>
<span id="cb1-36">    class2x_2d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], class2x_2d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>,</span>
<span id="cb1-37">    marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class -1'</span></span>
<span id="cb1-38">    )</span>
<span id="cb1-39">ax1.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>)</span>
<span id="cb1-40">ax1.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb1-41">ax1.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hyperplane (a line) in 2D Space'</span>)</span>
<span id="cb1-42">ax1.axhline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'grey'</span>, lw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-43">ax1.axvline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'grey'</span>, lw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-44"></span>
<span id="cb1-45"></span>
<span id="cb1-46">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">122</span>, projection <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb1-47">x_vals_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb1-48">y_vals_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb1-49">X, Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(x_vals_3d, y_vals_3d)</span>
<span id="cb1-50">Z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decision_boundary_3d(X, Y)</span>
<span id="cb1-51"></span>
<span id="cb1-52">ax2.plot_surface(X, Y, Z, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, rstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, cstride<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>)</span>
<span id="cb1-53">ax2.scatter(class1x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], class1x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],class1x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class +1'</span>)</span>
<span id="cb1-54">ax2.scatter(class2x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], class2x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],class2x_3d[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], color <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class -1'</span>)</span>
<span id="cb1-55">ax2.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>)</span>
<span id="cb1-56">ax2.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Y'</span>)</span>
<span id="cb1-57">ax2.set_zlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Z'</span>)</span>
<span id="cb1-58">ax2.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Hyperplane (a 2D plate) in 3D Space'</span>)</span>
<span id="cb1-59"></span>
<span id="cb1-60">plt.tight_layout()</span>
<span id="cb1-61">axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [ax1,ax2]</span>
<span id="cb1-62"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axes:</span>
<span id="cb1-63">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-64">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-65">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-2-output-1.png" width="745" height="374" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="margin-and-the-optimal-hyperplane" class="level3">
<h3 class="anchored" data-anchor-id="margin-and-the-optimal-hyperplane">Margin and the Optimal Hyperplane</h3>
<dl>
<dt>Definition (Margin)</dt>
<dd>
The margin is the distance between the hyperplane and the nearest data points from either class. SVM aims to maximize this margin to achieve better separation, which makes the classifier more robust.
</dd>
</dl>
<p>To define the margin mathematically, we impose that for all points: <img src="https://latex.codecogs.com/png.latex?%0Ay_i%20(w%5ET%20%5Cmathbf%7Bx%7D_i%20+%20b)%20%5Cgeq%201%20%5Cquad%20%5Cforall%20i%0A"></p>
<p>For a data vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i"> with label <img src="https://latex.codecogs.com/png.latex?y_i">:</p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?y_i%20=%20+1">: we want <img src="https://latex.codecogs.com/png.latex?w%5ET%20%5Cmathbf%7Bx%7D_i%20+%20b%5Cge%201"> (to be on the correct side of the hyperplane)<br>
</li>
<li>If <img src="https://latex.codecogs.com/png.latex?y_i%20=%20-1">: we want <img src="https://latex.codecogs.com/png.latex?w%5ET%20%5Cmathbf%7Bx%7D_i%20+%20b%5Cle%201"> (to be on the correct side of the hyperplane)</li>
</ul>
<p style="text-align: justify">
These two conditions combaine the equation mention above. That is all points must be at least a unit distance from the hyperplane on the correct side. The data points that satisfy <img src="https://latex.codecogs.com/png.latex?y_i%20(w%5ET%20x_i%20+%20b)%20=%201"> or <img src="https://latex.codecogs.com/png.latex?y_i%20(w%5ET%20x_i%20+%20b)%20=%20-1"> lie on the “support vectors,” or the points closest to the hyperplane.
</p>
<p>We know from the elementary geometry that the distance between two parallel lines <img src="https://latex.codecogs.com/png.latex?ax+by+c_1=0"> and <img src="https://latex.codecogs.com/png.latex?ax+by+c_2=0"> is given by</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%7Cc_1-c_2%7C%7D%7B%5Csqrt%7Ba%5E2+b%5E2%7D%7D%0A"></p>
<p>and the distance between two 2D parallel planes <img src="https://latex.codecogs.com/png.latex?ax+by+cz+d_1=0"> and <img src="https://latex.codecogs.com/png.latex?ax+by+cz+d_2=0"> in 3D space is given as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%7Cd_1-d_2%7C%7D%7B%5Csqrt%7Ba%5E2+b%5E2+c%5E2%7D%7D%0A"></p>
<div id="f2015d6f" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.graph_objects <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> go</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plotly.io <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pio</span>
<span id="cb2-3">pio.renderers</span>
<span id="cb2-4"></span>
<span id="cb2-5">z1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([</span>
<span id="cb2-6">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.83</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.89</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.81</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.87</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.87</span>],</span>
<span id="cb2-7">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.89</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.94</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.85</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.94</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.96</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>],</span>
<span id="cb2-8">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.84</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.82</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.93</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.91</span>],</span>
<span id="cb2-9">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.79</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.85</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.79</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.94</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>],</span>
<span id="cb2-10">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.79</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.88</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.81</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.95</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>],</span>
<span id="cb2-11">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.8</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.82</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.78</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.91</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.94</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>],</span>
<span id="cb2-12">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.75</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.78</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.77</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.91</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.95</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>],</span>
<span id="cb2-13">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.8</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.8</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.77</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.91</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.95</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.94</span>],</span>
<span id="cb2-14">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.74</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.81</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.76</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.93</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.98</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.99</span>],</span>
<span id="cb2-15">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.89</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.99</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.92</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.13</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.11</span>],</span>
<span id="cb2-16">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.97</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.97</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.91</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.09</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.11</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.11</span>],</span>
<span id="cb2-17">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.04</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.08</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.05</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.25</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.28</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.27</span>],</span>
<span id="cb2-18">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.01</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.23</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.2</span>],</span>
<span id="cb2-19">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.99</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.99</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.98</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.18</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.19</span>],</span>
<span id="cb2-20">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.93</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.97</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.97</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.18</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.18</span>]</span>
<span id="cb2-21">])</span>
<span id="cb2-22"></span>
<span id="cb2-23">z2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-24">z3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> z1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb2-25"></span>
<span id="cb2-26">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> go.Figure(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb2-27">    go.Surface(z<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>z1),</span>
<span id="cb2-28">    go.Surface(z<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>z2, showscale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, opacity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>),</span>
<span id="cb2-29">    go.Surface(z<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>z3, showscale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, opacity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>)</span>
<span id="cb2-30"></span>
<span id="cb2-31">])</span>
<span id="cb2-32">fig.update_layout(</span>
<span id="cb2-33">    scene<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb2-34">        xaxis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(backgroundcolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>),</span>
<span id="cb2-35">        yaxis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(backgroundcolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>),</span>
<span id="cb2-36">        zaxis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(backgroundcolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb2-37">    ),</span>
<span id="cb2-38">    paper_bgcolor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>,</span>
<span id="cb2-39">    title <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hyperplanes in higher dimension"</span></span>
<span id="cb2-40">)</span>
<span id="cb2-41">fig.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="2ccb1b07-a7cd-41c7-97d9-b3877d46bf1f" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("2ccb1b07-a7cd-41c7-97d9-b3877d46bf1f")) {                    Plotly.newPlot(                        "2ccb1b07-a7cd-41c7-97d9-b3877d46bf1f",                        [{"z":[[8.83,8.89,8.81,8.87,8.9,8.87],[8.89,8.94,8.85,8.94,8.96,8.92],[8.84,8.9,8.82,8.92,8.93,8.91],[8.79,8.85,8.79,8.9,8.94,8.92],[8.79,8.88,8.81,8.9,8.95,8.92],[8.8,8.82,8.78,8.91,8.94,8.92],[8.75,8.78,8.77,8.91,8.95,8.92],[8.8,8.8,8.77,8.91,8.95,8.94],[8.74,8.81,8.76,8.93,8.98,8.99],[8.89,8.99,8.92,9.1,9.13,9.11],[8.97,8.97,8.91,9.09,9.11,9.11],[9.04,9.08,9.05,9.25,9.28,9.27],[9.0,9.01,9.0,9.2,9.23,9.2],[8.99,8.99,8.98,9.18,9.2,9.19],[8.93,8.97,8.97,9.18,9.2,9.18]],"type":"surface"},{"opacity":0.9,"showscale":false,"z":[[9.83,9.89,9.81,9.87,9.9,9.87],[9.89,9.94,9.85,9.94,9.96,9.92],[9.84,9.9,9.82,9.92,9.93,9.91],[9.79,9.85,9.79,9.9,9.94,9.92],[9.79,9.88,9.81,9.9,9.95,9.92],[9.8,9.82,9.78,9.91,9.94,9.92],[9.75,9.78,9.77,9.91,9.95,9.92],[9.8,9.8,9.77,9.91,9.95,9.94],[9.74,9.81,9.76,9.93,9.98,9.99],[9.89,9.99,9.92,10.1,10.13,10.11],[9.97,9.97,9.91,10.09,10.11,10.11],[10.04,10.08,10.05,10.25,10.28,10.27],[10.0,10.01,10.0,10.2,10.23,10.2],[9.99,9.99,9.98,10.18,10.2,10.19],[9.93,9.97,9.97,10.18,10.2,10.18]],"type":"surface"},{"opacity":0.9,"showscale":false,"z":[[7.83,7.890000000000001,7.8100000000000005,7.869999999999999,7.9,7.869999999999999],[7.890000000000001,7.9399999999999995,7.85,7.9399999999999995,7.960000000000001,7.92],[7.84,7.9,7.82,7.92,7.93,7.91],[7.789999999999999,7.85,7.789999999999999,7.9,7.9399999999999995,7.92],[7.789999999999999,7.880000000000001,7.8100000000000005,7.9,7.949999999999999,7.92],[7.800000000000001,7.82,7.779999999999999,7.91,7.9399999999999995,7.92],[7.75,7.779999999999999,7.77,7.91,7.949999999999999,7.92],[7.800000000000001,7.800000000000001,7.77,7.91,7.949999999999999,7.9399999999999995],[7.74,7.8100000000000005,7.76,7.93,7.98,7.99],[7.890000000000001,7.99,7.92,8.1,8.13,8.11],[7.970000000000001,7.970000000000001,7.91,8.09,8.11,8.11],[8.04,8.08,8.05,8.25,8.28,8.27],[8.0,8.01,8.0,8.2,8.23,8.2],[7.99,7.99,7.98,8.18,8.2,8.19],[7.93,7.970000000000001,7.970000000000001,8.18,8.2,8.18]],"type":"surface"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"scene":{"xaxis":{"backgroundcolor":"#f4f4f4"},"yaxis":{"backgroundcolor":"#f4f4f4"},"zaxis":{"backgroundcolor":"#f4f4f4"}},"paper_bgcolor":"#f4f4f4","title":{"text":"Hyperplanes in higher dimension"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('2ccb1b07-a7cd-41c7-97d9-b3877d46bf1f');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>For the hyperplanes in higher dimensions, the distance between two parallel hyperplanes <img src="https://latex.codecogs.com/png.latex?w%5ET%5Cmathbf%7Bx%7D+b=1"> and <img src="https://latex.codecogs.com/png.latex?w%5ET%5Cmathbf%7Bx%7D+b=-1"> is given as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BDistance:%20%7DM=%20%5Cfrac%7B%7C1-(-1)%7C%7D%7B%5C%7Cw%5C%7C%7D=%5Cfrac%7B2%7D%7B%5C%7Cw%5C%7C%7D%0A"></p>
<p>This distance, <img src="https://latex.codecogs.com/png.latex?M"> is the margin and our objective is to maximize <img src="https://latex.codecogs.com/png.latex?M">, or equivalently, minimize <img src="https://latex.codecogs.com/png.latex?%5C%7Cw%5C%7C"> subject to the constraints <img src="https://latex.codecogs.com/png.latex?y_i%20(w%5ET%20x_i%20+%20b)%20%5Cgeq%201">.</p>
</section>
<section id="optimization-of-the-svm" class="level3">
<h3 class="anchored" data-anchor-id="optimization-of-the-svm">Optimization of the SVM</h3>
<p>The optimization problem can be formulated as follows:</p>
<p><strong>Primal Form:</strong> <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bw,%20b%7D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%0A"></p>
<p>subject to: <img src="https://latex.codecogs.com/png.latex?%0Ay_i%20(w%5ET%20x_i%20+%20b)%20%5Cgeq%201,%20%5Cquad%20%5Cforall%20i%0A"></p>
<p>This is a convex optimization problem because the objective function <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2"> is convex, and the constraints are linear.</p>
</section>
<section id="the-dual-form-of-svm" class="level3">
<h3 class="anchored" data-anchor-id="the-dual-form-of-svm">The Dual Form of SVM</h3>
<p>To solve the optimization problem, it is often more efficient to use the dual form. By introducing Lagrange multipliers <img src="https://latex.codecogs.com/png.latex?%5Calpha_i%20%5Cgeq%200">, we can construct the Lagrangian:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(w,%20b,%20%5Calpha)%20=%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%20-%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20%5Cleft(%20y_i%20(w%5ET%20x_i%20+%20b)%20-%201%20%5Cright)%0A"></p>
<p>Taking the partial derivatives of <img src="https://latex.codecogs.com/png.latex?L"> with respect to <img src="https://latex.codecogs.com/png.latex?w"> and <img src="https://latex.codecogs.com/png.latex?b"> and setting them to zero yields:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w%7D%20&amp;=%20w%20-%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20x_i%20=%200%5C%5C%0A%5Cimplies%20w%20&amp;=%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20x_i%5C%5C%0A%5Ctext%7B%20and%20%7D%20&amp;%5C%5C%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20b%7D%20&amp;=%20-%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20=%200%5C%5C%0A%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20&amp;=%200%0A%5Cend%7Balign*%7D"></p>
<p>This tells us that <img src="https://latex.codecogs.com/png.latex?w"> can be expressed as a linear combination of the training points <img src="https://latex.codecogs.com/png.latex?x_i"> with weights given by <img src="https://latex.codecogs.com/png.latex?%5Calpha_i%20y_i"> and the sum of the weighted labels is zero.</p>
<p>Now we substitute <img src="https://latex.codecogs.com/png.latex?w%20=%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20x_i"> back into the Lagrangian <img src="https://latex.codecogs.com/png.latex?L(w,%20b,%20%5Calpha)">. The primal objective function <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2"> becomes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%20&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20x_i%20%5Cright)%5ET%20%5Cleft(%20%5Csum_%7Bj=1%7D%5En%20%5Calpha_j%20y_j%20x_j%20%5Cright)%5C%5C%0A&amp;=%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5En%20%5Csum_%7Bj=1%7D%5En%20%5Calpha_i%20%5Calpha_j%20y_i%20y_j%20x_i%5ET%20x_j%0A%5Cend%7Balign*%7D"></p>
<p>Substituting back into the Lagrangian,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(w,%20b,%20%5Calpha)%20=%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%20-%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20%20y_i%20(w%5ET%20x_i%20+%20b)%20+%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%0A"></p>
<p>we get the dual form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7B%5Calpha%7D%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5En%20%5Csum_%7Bj=1%7D%5En%20%5Calpha_i%20%5Calpha_j%20y_i%20y_j%20x_i%5ET%20x_j%0A"></p>
<p>subject to:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_i%20%5Cgeq%200%20%5Cquad%20%5Cforall%20i,%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20=%200%0A"></p>
<p>The solution to the dual form gives the values of <img src="https://latex.codecogs.com/png.latex?%5Calpha_i">, which are used to construct the optimal hyperplane. The final decision boundary is then:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20=%20%5Ctext%7Bsign%7D%20%5Cleft(%20%5Csum_%7Bi=1%7D%5EN%20%5Calpha_i%20y_i%20x_i%5ET%20x%20+%20b%20%5Cright)%0A"></p>
</section>
</section>
<section id="nonlinear-support-vector-machines" class="level2">
<h2 class="anchored" data-anchor-id="nonlinear-support-vector-machines">Nonlinear Support Vector Machines</h2>
<p>Imagine we have a dataset that looks like this.</p>
<div id="872d08a6" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_moons</span>
<span id="cb3-2">X,y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_moons(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-3">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb3-4">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 0'</span>)</span>
<span id="cb3-5">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 1'</span>)</span>
<span id="cb3-6">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 1'</span>)</span>
<span id="cb3-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 2'</span>)</span>
<span id="cb3-8">plt.legend()</span>
<span id="cb3-9">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-10">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-11">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-4-output-1.png" width="674" height="503" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p style="text-align: justify">
There is now way that a linear hyperplane seperates the data. Therefore, when the data is not linearly separable, SVMs use the <strong>kernel trick</strong> to map the data into a higher-dimensional space where a linear separation is possible. The idea is to map the original data points <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> from the input space to a higher-dimensional feature space using a *feature transformation function <img src="https://latex.codecogs.com/png.latex?%5Cphi(x)">.
</p>
<p>For example,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cphi:%20%5Cmathbb%7BR%7D%5En%5Cmapsto%20%5Cmathbb%7BR%7D%5Em,%20%5Chspace%7B4mm%7D%20%5Ctext%7Bwhere%20%7D%20m%3En%0A"></p>
<p style="text-align: justify">
In the higher-dimensional space, it’s often easier to find a hyperplane that separates the two classes linearly.<br> <br> However, explicitly calculating and working with this higher-dimensional transformation <img src="https://latex.codecogs.com/png.latex?%5Cphi(x)"> can be computationally expensive, especially when the dimensionality <img src="https://latex.codecogs.com/png.latex?m"> is very high or infinite. This is where the <strong>kernel trick</strong> comes in.
</p>
<section id="the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="the-kernel-trick">The Kernel Trick</h3>
<p style="text-align: justify">
The <strong>kernel trick</strong> is a method that allows us to compute the inner product between two transformed data points <img src="https://latex.codecogs.com/png.latex?%5Cphi(x_i)"> and <img src="https://latex.codecogs.com/png.latex?%5Cphi(x_j)"> in the higher-dimensional space <strong>without</strong> explicitly computing the transformation <img src="https://latex.codecogs.com/png.latex?%5Cphi(x)">.<br> <br> Instead of computing <img src="https://latex.codecogs.com/png.latex?%5Cphi(x_i)"> and <img src="https://latex.codecogs.com/png.latex?%5Cphi(x_j)"> separately and then taking their inner product, we define a <strong>kernel function</strong> <img src="https://latex.codecogs.com/png.latex?K(x_i,%20x_j)"> that directly computes this inner product in the higher-dimensional space:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x_i,%20x_j)%20=%20%5Cphi(x_i)%5ET%20%5Cphi(x_j)%0A"></p>
<p style="text-align: justify">
By substituting this kernel function into the SVM optimization problem, we can work in the higher-dimensional space implicitly, without ever explicitly mapping the data points to that space. This allows us to handle complex, nonlinear decision boundaries with a more computationally efficient approach.
</p>
<section id="polynomial-kernel" class="level4">
<h4 class="anchored" data-anchor-id="polynomial-kernel">Polynomial Kernel</h4>
<p>The polynomial kernel allows us to model nonlinear decision boundaries using polynomial functions. It is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x_i,%20x_j)%20=%20(x_i%5ET%20x_j%20+%20c)%5Ed%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?c"> is a constant that controls the influence of higher-order terms.</li>
<li><img src="https://latex.codecogs.com/png.latex?d"> is the degree of the polynomial.</li>
</ul>
<p style="text-align: justify">
The polynomial kernel creates a feature space that corresponds to all monomials up to degree <img src="https://latex.codecogs.com/png.latex?d">. It can model interactions between features, allowing the SVM to classify data with polynomial decision boundaries.
</p>
<p>For example, when we have 1-D data and it is linearly inseperable, we can use polynomial kernel with degree 2 or higher. Say <img src="https://latex.codecogs.com/png.latex?c=1/2"> and <img src="https://latex.codecogs.com/png.latex?d=2">,</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AK(x_1,x_2)&amp;%20=%20%5Cleft(x_1x_2+%5Cfrac%7B1%7D%7B2%7D%5Cright)%5E2%5C%5C%0A&amp;%20=%20%5Cleft(x_1x_2+%5Cfrac%7B1%7D%7B2%7D%5Cright)%5Cleft(x_1x_2+%5Cfrac%7B1%7D%7B2%7D%5Cright)%5C%5C%0A&amp;%20=%20x_1%5E2x_2%5E2+%5Cfrac%7B1%7D%7B2%7Dx_1x_2+%5Cfrac%7B1%7D%7B4%7D%5C%5C%0A&amp;%20=%20x_1x_2+x_1%5E2x_2%5E2+%5Cfrac%7B1%7D%7B4%7D%5C%5C%0A&amp;%20=%20(x_1,x_1%5E2,%5Cfrac%7B1%7D%7B2%7D)%5Ccdot%20(x_2,x_2%5E2,%5Cfrac%7B1%7D%7B2%7D)%0A%5Cend%7Balign*%7D"></p>
<div id="51446110" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>))</span>
<span id="cb4-2">x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>))</span>
<span id="cb4-3">x3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">27</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">37</span>))</span>
<span id="cb4-4">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [j <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> sub <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [x1,x2,x3] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> sub]</span>
<span id="cb4-5">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span></span>
<span id="cb4-6">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb4-7">y_squared <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> x]</span>
<span id="cb4-8">slope <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">197</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">529.5</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">23</span>)</span>
<span id="cb4-9">line_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-10">line_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> slope<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (line_x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">197</span></span>
<span id="cb4-11"></span>
<span id="cb4-12">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.9</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb4-13">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">121</span>)</span>
<span id="cb4-14">ax1.scatter(x,y, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual Data in 1D'</span>)</span>
<span id="cb4-15">ax1.set_xlabel(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$feature$'</span>)</span>
<span id="cb4-16">ax1.set_xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>)</span>
<span id="cb4-17">ax1.set_ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb4-18"></span>
<span id="cb4-19">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">122</span>)</span>
<span id="cb4-20">ax2.scatter(x,y, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual Data in 1D'</span>)</span>
<span id="cb4-21">ax2.scatter(x,y_squared, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> colors, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Transformed Data in 2D'</span>)</span>
<span id="cb4-22">ax2.plot(line_x,line_y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>,label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'1D Hyperplane'</span>)</span>
<span id="cb4-23">ax2.set_xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>)</span>
<span id="cb4-24">ax2.set_ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1400</span>)</span>
<span id="cb4-25">ax2.set_xlabel(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$feature$'</span>)</span>
<span id="cb4-26">ax2.set_ylabel(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'$feature^2$'</span>)</span>
<span id="cb4-27">ax2.legend()</span>
<span id="cb4-28"></span>
<span id="cb4-29">plt.tight_layout()</span>
<span id="cb4-30">axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [ax1,ax2]</span>
<span id="cb4-31"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axes:</span>
<span id="cb4-32">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb4-33">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb4-34">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-5-output-1.png" width="748" height="373" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>or for a 2D data to 3D transformation along with 2D hyperplane</p>
<div id="62de5737" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_circles</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mpl_toolkits.mplot3d <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Axes3D</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate a dataset that is not linearly separable</span></span>
<span id="cb5-5">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_circles(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the original dataset</span></span>
<span id="cb5-8">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb5-9">ax1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">121</span>)</span>
<span id="cb5-10">ax1.scatter(X[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 0'</span>)</span>
<span id="cb5-11">ax1.scatter(X[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 1'</span>)</span>
<span id="cb5-12">ax1.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Data'</span>)</span>
<span id="cb5-13">ax1.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'feature 1'</span>)</span>
<span id="cb5-14">ax1.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'feature 2'</span>)</span>
<span id="cb5-15">ax1.legend()</span>
<span id="cb5-16"></span>
<span id="cb5-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply polynomial kernel transformation</span></span>
<span id="cb5-18">X_transformed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack((X, (X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)))</span>
<span id="cb5-19"></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the transformed dataset in 3D</span></span>
<span id="cb5-21">ax2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">122</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb5-22">ax2.scatter(X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 0'</span>)</span>
<span id="cb5-23">ax2.scatter(X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], X_transformed[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Class 1'</span>)</span>
<span id="cb5-24">ax2.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2D to 3D transformed'</span>)</span>
<span id="cb5-25">ax2.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 1'</span>)</span>
<span id="cb5-26">ax2.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature 2'</span>)</span>
<span id="cb5-27">ax2.set_zlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Poly Feature'</span>)</span>
<span id="cb5-28">ax2.legend()</span>
<span id="cb5-29"></span>
<span id="cb5-30">axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [ax1, ax2]</span>
<span id="cb5-31"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axes:</span>
<span id="cb5-32">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-33">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-34">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-6-output-1.png" width="690" height="376" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="radial-basis-function-rbf-kernel-gaussian-kernel" class="level4">
<h4 class="anchored" data-anchor-id="radial-basis-function-rbf-kernel-gaussian-kernel">Radial Basis Function (RBF) Kernel (Gaussian Kernel)</h4>
<p style="text-align: justify">
The RBF kernel, also known as the Gaussian kernel, is one of the most popular kernels because it can map the data to an infinite-dimensional space, allowing the model to capture highly complex relationships. It’s defined as:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x_i,%20x_j)%20=%20%5Cexp%5Cleft(-%5Cfrac%7B%5C%7Cx_i%20-%20x_j%5C%7C%5E2%7D%7B2%5Csigma%5E2%7D%5Cright)%0A"></p>
<p>or equivalently:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x_i,%20x_j)%20=%20%5Cexp%5Cleft(-%5Cgamma%20%5C%7Cx_i%20-%20x_j%5C%7C%5E2%5Cright)%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5C%7Cx_i%20-%20x_j%5C%7C%5E2"> is the squared Euclidean distance between the points <img src="https://latex.codecogs.com/png.latex?x_i"> and <img src="https://latex.codecogs.com/png.latex?x_j">.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csigma"> (or <img src="https://latex.codecogs.com/png.latex?%5Cgamma%20=%20%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D">) controls the width of the Gaussian function and, thus, the influence of each training example.</li>
</ul>
<p style="text-align: justify">
The RBF kernel is particularly effective when the relationship between classes is highly nonlinear. It maps each data point to an infinite-dimensional space, allowing the SVM to capture fine-grained patterns.
</p>
</section>
<section id="sigmoid-kernel" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid-kernel">Sigmoid Kernel</h4>
<p>The sigmoid kernel is related to neural networks and is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AK(x_i,%20x_j)%20=%20%5Ctanh(%5Ckappa%20x_i%5ET%20x_j%20+%20%5Ctheta)%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ckappa"> and <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> are parameters that control the shape of the kernel.</li>
</ul>
<p>This kernel can be interpreted as simulating a neural network with a single hidden layer, where <img src="https://latex.codecogs.com/png.latex?%5Ctanh"> serves as the activation function.</p>
</section>
</section>
<section id="dual-formulation-with-the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="dual-formulation-with-the-kernel-trick">Dual Formulation with the Kernel Trick</h3>
<p style="text-align: justify">
In the dual form of the SVM optimization problem, we only require the inner products <img src="https://latex.codecogs.com/png.latex?x_i%5ET%20x_j"> between data points. By replacing these inner products with <img src="https://latex.codecogs.com/png.latex?K(x_i,%20x_j)%20=%20%5Cphi(x_i)%5ET%20%5Cphi(x_j)">, we obtain the dual form of the optimization problem for a kernelized SVM:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7B%5Calpha%7D%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5En%20%5Csum_%7Bj=1%7D%5En%20%5Calpha_i%20%5Calpha_j%20y_i%20y_j%20K(x_i,%20x_j)%0A"></p>
<p>subject to:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_i%20%5Cgeq%200%20%5Cquad%20%5Cforall%20i,%20%5Cquad%20%5Ctext%7Band%7D%20%5Cquad%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20=%200%0A"></p>
<p>Using the kernel function <img src="https://latex.codecogs.com/png.latex?K(x_i,%20x_j)">, we can compute the decision boundary in the original space without explicitly mapping to the higher-dimensional space.</p>
</section>
<section id="decision-function-with-the-kernel-trick" class="level3">
<h3 class="anchored" data-anchor-id="decision-function-with-the-kernel-trick">Decision Function with the Kernel Trick</h3>
<p>Once we solve for <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and determine the support vectors, the decision function for a new point <img src="https://latex.codecogs.com/png.latex?x"> becomes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20=%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20K(x_i,%20x)%20+%20b%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha_i"> are the Lagrange multipliers found from the optimization.</li>
<li><img src="https://latex.codecogs.com/png.latex?y_i"> are the labels of the support vectors.</li>
<li><img src="https://latex.codecogs.com/png.latex?K(x_i,%20x)"> is the kernel function that calculates the inner product between the support vector <img src="https://latex.codecogs.com/png.latex?x_i"> and the new data point <img src="https://latex.codecogs.com/png.latex?x">.</li>
</ul>
<p>This decision function allows us to classify new data points by evaluating their relationship with the support vectors in the original input space, using the kernel to measure similarity.</p>
</section>
<section id="soft-margin-svm" class="level3">
<h3 class="anchored" data-anchor-id="soft-margin-svm">Soft Margin SVM</h3>
<p style="text-align: justify">
The concept of <strong>soft margin SVM</strong> extends the hard margin SVM approach to handle cases where data is not perfectly separable. In real-world datasets, it’s often impossible to perfectly separate classes without allowing some misclassification or overlap. Soft margin SVM addresses this by introducing a <strong>margin of tolerance</strong>—it allows some data points to lie within the margin or even on the wrong side of the decision boundary.
</p>
<p>In hard margin SVM, we strictly enforced that: <img src="https://latex.codecogs.com/png.latex?%0Ay_i%20(w%5ET%20x_i%20+%20b)%20%5Cge%201,%20%5Cquad%20%5Cforall%20i%0A"></p>
<p>which means that each point is correctly classified and outside the margin.</p>
<p>In soft margin SVM, we introduce <strong>slack variables</strong> <img src="https://latex.codecogs.com/png.latex?%5Cxi_i">, which allow some points to violate this constraint. The constraints become: <img src="https://latex.codecogs.com/png.latex?%0Ay_i%20(w%5ET%20x_i%20+%20b)%20%5Cge%201%20-%20%5Cxi_i,%20%5Cquad%20%5Cxi_i%20%5Cge%200%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cxi_i"> measures the degree of misclassification for each data point <img src="https://latex.codecogs.com/png.latex?x_i">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?%5Cxi_i%20=%200">, then <img src="https://latex.codecogs.com/png.latex?x_i"> lies on or outside the margin (correct classification).</li>
<li>If <img src="https://latex.codecogs.com/png.latex?0%20%3C%20%5Cxi_i%20%5Cle%201">, then <img src="https://latex.codecogs.com/png.latex?x_i"> lies within the margin but is still correctly classified.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?%5Cxi_i%20%3E%201">, then <img src="https://latex.codecogs.com/png.latex?x_i"> is misclassified.</li>
</ul>
<p style="text-align: justify">
To find the optimal hyperplane with a soft margin, we modify the objective function to include a <strong>penalty</strong> for misclassifications. The goal is to balance maximizing the margin and minimizing the misclassification error. The objective function becomes:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bw,%20b,%20%5Cxi%7D%20%5Cquad%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%20+%20C%20%5Csum_%7Bi=1%7D%5En%20%5Cxi_i%0A"></p>
<p>where:</p>
<ul>
<li>The term <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2"> encourages a large margin, just as in hard margin SVM.</li>
<li>The term <img src="https://latex.codecogs.com/png.latex?C%20%5Csum_%7Bi=1%7D%5En%20%5Cxi_i"> penalizes misclassified points, where <img src="https://latex.codecogs.com/png.latex?C"> is a <strong>regularization parameter</strong> that controls the trade-off between maximizing the margin and minimizing the classification error.</li>
</ul>
<p>The <strong>parameter <img src="https://latex.codecogs.com/png.latex?C"></strong>:</p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?C"> is large, the optimization emphasizes minimizing misclassifications (more sensitive to individual data points), which leads to a narrower margin with fewer violations.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?C"> is small, the optimization focuses more on maximizing the margin, allowing more misclassifications.</li>
</ul>
<p>The optimization problem for soft margin SVM can be written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bw,%20b,%20%5Cxi%7D%20%5Cquad%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7Cw%5C%7C%5E2%20+%20C%20%5Csum_%7Bi=1%7D%5En%20%5Cxi_i%0A"> subject to: <img src="https://latex.codecogs.com/png.latex?%0Ay_i%20(w%5ET%20x_i%20+%20b)%20%5Cge%201%20-%20%5Cxi_i,%20%5Cquad%20%5Cxi_i%20%5Cge%200%20%5Cquad%20%5Cforall%20i%0A"></p>
<p>This problem is still convex and can be solved using Lagrange multipliers, though it becomes slightly more complex due to the introduction of slack variables <img src="https://latex.codecogs.com/png.latex?%5Cxi_i">.</p>
<p>The dual form of the soft margin SVM, similar to the hard margin case, can be derived using Lagrange multipliers. The dual problem becomes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7B%5Calpha%7D%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5En%20%5Csum_%7Bj=1%7D%5En%20%5Calpha_i%20%5Calpha_j%20y_i%20y_j%20K(x_i,%20x_j)%0A"> subject to: <img src="https://latex.codecogs.com/png.latex?%0A0%20%5Cleq%20%5Calpha_i%20%5Cleq%20C,%20%5Cquad%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20y_i%20=%200%0A"></p>
<p>The main difference here is that each <img src="https://latex.codecogs.com/png.latex?%5Calpha_i"> is now bounded by <img src="https://latex.codecogs.com/png.latex?C"> instead of being unrestricted, which introduces a balance between the margin maximization and error tolerance.</p>
<p style="text-align: justify">
In soft margin SVM, the margin is not strict. Some points are allowed to lie within the margin or even be misclassified. Points that lie on the wrong side of the margin are called <strong>support vectors</strong> with non-zero slack values <img src="https://latex.codecogs.com/png.latex?%5Cxi_i">.
</p>
<ul>
<li><strong>High <img src="https://latex.codecogs.com/png.latex?C"></strong>: A larger <img src="https://latex.codecogs.com/png.latex?C"> results in a narrower margin with fewer violations, meaning fewer points within the margin or misclassified. This leads to a more complex model that might overfit if <img src="https://latex.codecogs.com/png.latex?C"> is too high.</li>
<li><strong>Low <img src="https://latex.codecogs.com/png.latex?C"></strong>: A smaller <img src="https://latex.codecogs.com/png.latex?C"> results in a wider margin with more allowed violations, meaning more tolerance to misclassifications. This generally leads to a simpler, more robust model that might underfit if <img src="https://latex.codecogs.com/png.latex?C"> is too low.</li>
</ul>
<p style="text-align: justify">
The regularization parameter <img src="https://latex.codecogs.com/png.latex?C"> controls the trade-off between margin width and classification accuracy. <strong>Cross-validation</strong> is commonly used to select the optimal value of <img src="https://latex.codecogs.com/png.latex?C"> by evaluating the model’s performance across different values of <img src="https://latex.codecogs.com/png.latex?C"> and choosing the one that generalizes best to unseen data.
</p>
<div id="7e025ead" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb6-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> svm</span>
<span id="cb6-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_blobs</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic dataset</span></span>
<span id="cb6-7">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_blobs(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb6-8">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.where(y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Transform labels to -1 and +1 for SVM</span></span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Different values of C for comparison</span></span>
<span id="cb6-11">C_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>]</span>
<span id="cb6-12"></span>
<span id="cb6-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting</span></span>
<span id="cb6-14">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust figure size for vertical layout</span></span>
<span id="cb6-15">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set background color for the figure</span></span>
<span id="cb6-16"></span>
<span id="cb6-17"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, C <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(C_values):</span>
<span id="cb6-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit SVM model with the given C value</span></span>
<span id="cb6-19">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svm.SVC(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'linear'</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>C)</span>
<span id="cb6-20">    model.fit(X, y)</span>
<span id="cb6-21">    </span>
<span id="cb6-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mesh to plot decision boundaries</span></span>
<span id="cb6-23">    x_min, x_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-24">    y_min, y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-25">    xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>), np.linspace(y_min, y_max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>))</span>
<span id="cb6-26">    </span>
<span id="cb6-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot decision boundary and margin</span></span>
<span id="cb6-28">    Z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb6-29">    Z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Z.reshape(xx.shape)</span>
<span id="cb6-30">    </span>
<span id="cb6-31">    ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(C_values), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust to create vertical subplots</span></span>
<span id="cb6-32">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set background color for the plot area</span></span>
<span id="cb6-33">    plt.contourf(xx, yy, Z, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#FFAAAA'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb6-34">    plt.contour(xx, yy, Z, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb6-35">    </span>
<span id="cb6-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot training points</span></span>
<span id="cb6-37">    plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.bwr, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb6-38">    plt.title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"SVM with Soft Margin (C=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>C<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>)</span>
<span id="cb6-39">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 1"</span>)</span>
<span id="cb6-40">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 2"</span>)</span>
<span id="cb6-41">    </span>
<span id="cb6-42">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mark support vectors</span></span>
<span id="cb6-43">    plt.scatter(model.support_vectors_[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], model.support_vectors_[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, facecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb6-44"></span>
<span id="cb6-45">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Effect of Regularization Parameter C on Soft Margin SVM"</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.96</span>)</span>
<span id="cb6-46">plt.tight_layout(rect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>])</span>
<span id="cb6-47">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-7-output-1.png" width="566" height="1387" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="python-implementation-of-svm" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-of-svm">Python Implementation of SVM</h2>
<section id="linearsvc" class="level3">
<h3 class="anchored" data-anchor-id="linearsvc">LinearSVC</h3>
<p>Let’s first create the data</p>
<div id="d5d741d6" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb7-2">n_rows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb7-3">diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb7-4">X1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.random((n_rows,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb7-5">X_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X1[(X1[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X1[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>diff,:]</span>
<span id="cb7-6">X_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X1[(X1[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X1[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> diff,:]</span>
<span id="cb7-7"></span>
<span id="cb7-8">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.append(X_1, X_2, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb7-9">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.empty(np.shape(X)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb7-10">y[(X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>diff] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-11">y[(X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> diff] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-12">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-13">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-14">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x_1$'</span>)</span>
<span id="cb7-15">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x_2$'</span>)</span>
<span id="cb7-16">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-17">plt.legend()</span>
<span id="cb7-18">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb7-19">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb7-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-8-output-1.png" width="589" height="429" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Now we apply linear SVM classifier</p>
<div id="be458132" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearSVC</span>
<span id="cb8-2"></span>
<span id="cb8-3">maximum_margin_SVC <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearSVC(C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, max_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, dual<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auto"</span>)</span>
<span id="cb8-4">maximum_margin_SVC.fit(X,y)</span>
<span id="cb8-5">x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb8-6">x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb8-7"></span>
<span id="cb8-8">x1,x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(x1,x2)</span>
<span id="cb8-9">x1x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.vstack([x1.ravel(),x2.ravel()]).T</span>
<span id="cb8-10">z <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> maximum_margin_SVC.decision_function(x1x2).reshape(x1.shape)</span>
<span id="cb8-11"></span>
<span id="cb8-12">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training -1'</span>)</span>
<span id="cb8-13">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training 1'</span>)</span>
<span id="cb8-14">plt.contour(x1,x2,z, colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>,levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>])</span>
<span id="cb8-15">plt.legend()</span>
<span id="cb8-16">plt.xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-17">plt.ylim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-18">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x_1$'</span>)</span>
<span id="cb8-19">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$x_2$'</span>)</span>
<span id="cb8-20">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb8-21">plt.legend()</span>
<span id="cb8-22">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb8-23">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb8-24">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-9-output-1.png" width="599" height="434" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The data that we used to explain the polynomial kernels</p>
<div id="b79814bb" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SVC</span>
<span id="cb9-2">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.random.random(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb9-3">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(X))</span>
<span id="cb9-4">y[(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> (X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb9-5"></span>
<span id="cb9-6">svc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SVC(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'poly'</span>, degree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb9-7">svc.fit(X.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),y)</span>
<span id="cb9-8">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],np.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>,label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class -1'</span>)</span>
<span id="cb9-9">plt.scatter(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],np.ones(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>,label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class 1'</span>)</span>
<span id="cb9-10">dcsns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svc.decision_function(np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-11">plt.scatter(</span>
<span id="cb9-12">    np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>)[dcsns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb9-13">    np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>)[dcsns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb9-14">    marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'|'</span>,</span>
<span id="cb9-15">    s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>,</span>
<span id="cb9-16">    c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>,</span>
<span id="cb9-17">    label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Decision Boundary'</span></span>
<span id="cb9-18">    )</span>
<span id="cb9-19">plt.legend()</span>
<span id="cb9-20">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb9-21">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb9-22">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-10-output-1.png" width="579" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For the higher dimensions</p>
<div id="abd49387" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-overflow-wrap code-with-copy"><code class="sourceCode python"><span id="cb10-1">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_circles(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, factor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create SVM models with polynomial and RBF kernels</span></span>
<span id="cb10-4">model_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svm.SVC(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'poly'</span>, degree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb10-5">model_rbf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> svm.SVC(kernel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rbf'</span>, gamma<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, C<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb10-6"></span>
<span id="cb10-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit the models</span></span>
<span id="cb10-8">model_poly.fit(X, y)</span>
<span id="cb10-9">model_rbf.fit(X, y)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a mesh to plot decision boundaries</span></span>
<span id="cb10-12">x_min, x_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb10-13">y_min, y_max <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb10-14">xx, yy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.meshgrid(np.linspace(x_min, x_max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>), np.linspace(y_min, y_max, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>))</span>
<span id="cb10-15"></span>
<span id="cb10-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plotting</span></span>
<span id="cb10-17">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb10-18"></span>
<span id="cb10-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Polynomial Kernel</span></span>
<span id="cb10-20">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-21">Z_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_poly.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb10-22">Z_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Z_poly.reshape(xx.shape)</span>
<span id="cb10-23">plt.contourf(xx, yy, Z_poly, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#FFAAAA'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb10-24">plt.contour(xx, yy, Z_poly, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb10-25">plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.bwr, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb10-26">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SVM with Polynomial Kernel"</span>)</span>
<span id="cb10-27">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 1"</span>)</span>
<span id="cb10-28">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 2"</span>)</span>
<span id="cb10-29">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb10-30"></span>
<span id="cb10-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># RBF Kernel</span></span>
<span id="cb10-32">plt.subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb10-33">Z_rbf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_rbf.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb10-34">Z_rbf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Z_rbf.reshape(xx.shape)</span>
<span id="cb10-35">plt.contourf(xx, yy, Z_rbf, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#FFAAAA'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#AAAAFF'</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb10-36">plt.contour(xx, yy, Z_rbf, levels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], linestyles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>], colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb10-37">plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>plt.cm.bwr, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>)</span>
<span id="cb10-38">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SVM with RBF Kernel"</span>)</span>
<span id="cb10-39">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 1"</span>)</span>
<span id="cb10-40">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature 2"</span>)</span>
<span id="cb10-41">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb10-42"></span>
<span id="cb10-43">plt.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Polynomial and RBF Kernels on Nonlinear Data"</span>)</span>
<span id="cb10-44">plt.tight_layout(rect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.96</span>])</span>
<span id="cb10-45">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb10-46">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb10-47">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://mrislambd.github.io/posts/svm/index_files/figure-html/cell-11-output-1.png" width="748" height="381" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<section id="books" class="level3">
<h3 class="anchored" data-anchor-id="books">Books</h3>
<ul>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd Edition. Springer.<br>
</li>
<li>Boyd, S., &amp; Vandenberghe, L. (2004). <em>Convex Optimization</em>. Cambridge University Press.<br>
</li>
<li>Schölkopf, B., &amp; Smola, A. J. (2002). <em>Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</em>. MIT Press.<br>
</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.<br>
</li>
<li>Vapnik, V. (1998). <em>Statistical Learning Theory</em>. Wiley-Interscience.</li>
</ul>
</section>
<section id="lecture-notes" class="level3">
<h3 class="anchored" data-anchor-id="lecture-notes">Lecture Notes</h3>
<ul>
<li>Andrew Ng’s <em>Machine Learning</em> course on Coursera, particularly the lectures on Support Vector Machines, covering linear SVMs, geometric interpretation, and constraints.<br>
</li>
<li>StatQuest with Josh Starmer</li>
<li>Data Science Bootcamp by <em>The Erdos Institute</em></li>
</ul>
</section>
<section id="journals-and-articles" class="level3">
<h3 class="anchored" data-anchor-id="journals-and-articles">Journals and Articles</h3>
<ul>
<li>Cortes, C., &amp; Vapnik, V. (1995). “Support-vector networks.” <em>Machine Learning</em>, 20(3), 273-297.<br>
</li>
<li>Aizerman, M. A., Braverman, E. M., &amp; Rozonoer, L. I. (1964). “Theoretical foundations of the potential function method in pattern recognition learning.” <em>Automation and Remote Control</em>, 25, 821-837.</li>
</ul>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/svm/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/svm/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742008464950" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Support {Vector} {Machine} {(SVM)} {Algorithm}},
  date = {2024-11-05},
  url = {https://mrislambd.github.io/posts/svm/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Support Vector Machine (SVM)
Algorithm.”</span> November 5, 2024. <a href="https://mrislambd.github.io/posts/svm/">https://mrislambd.github.io/posts/svm/</a>.
</div></div></section></div> ]]></description>
  <category>Statistics</category>
  <category>Data Science</category>
  <category>Data Engineering</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/svm/</guid>
  <pubDate>Tue, 05 Nov 2024 05:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/svm/svm.png" medium="image" type="image/png" height="73" width="144"/>
</item>
<item>
  <title>Bayesian Probabilistic Models for Classification</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/bayesianclassification/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<div style="text-align: justify;">
<p>Bayesian inference is a powerful statistical method that applies the principles of Bayes’s theorem to update the probability of a hypothesis as more evidence or information becomes available. It is widely used in various fields including machine learning, to make predictions and decisions under uncertainty.</p>
<p>Bayes’s theorem is based on the definition of conditional probability. For two events <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?B"> with <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(B)%20%5Cneq%200">, we define the conditional probability of occurring <img src="https://latex.codecogs.com/png.latex?A"> given that <img src="https://latex.codecogs.com/png.latex?B"> has already occurred.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/bayesianclassification/index_files/figure-html/cell-2-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="413" height="316"></a></p>
</figure>
</div>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(A%7CB)=%5Cfrac%7B%5Cmathbb%7BP%7D(A%5Ccap%20B)%7D%7B%5Cmathbb%7BP%7D(B)%7D"></p>
<p>Similarly, the conditional probability of occuring <img src="https://latex.codecogs.com/png.latex?B"> given that <img src="https://latex.codecogs.com/png.latex?A"> has already occured with <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(A)%20%5Cne%200"> is<br>
<img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(B%7CA)=%5Cfrac%7B%5Cmathbb%7BP%7D(A%5Ccap%20B)%7D%7B%5Cmathbb%7BP%7D(A)%7D%0A"></p>
<p>From this equation, we can derive that the joint probability of <img src="https://latex.codecogs.com/png.latex?A%5Ccap%20B"> is <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(A%5Ccap%20B)%20=%20%5Cmathbb%7BP%7D(B%20%7C%20A)%20%5Cmathbb%7BP%7D%20(A)%20=%20%5Cmathbb%7BP%7D(A%20%7C%20B)%20%5Cmathbb%7BP%7D%20(B)%0A"></p>
</section>
<section id="bayess-theorem" class="level2">
<h2 class="anchored" data-anchor-id="bayess-theorem">Bayes’s Theorem</h2>
<section id="for-two-events-or-random-variables" class="level3">
<h3 class="anchored" data-anchor-id="for-two-events-or-random-variables">For Two Events or Random Variables</h3>
<p>Bayes’s theorem is based on these conditional probabilities. It states that the likelihood of occuring the event <img src="https://latex.codecogs.com/png.latex?A"> given that the event <img src="https://latex.codecogs.com/png.latex?B"> has occured is given as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(A%20%7C%20B)%20=%20%5Cfrac%7B%5Cmathbb%7BP%7D(B%20%7C%20A)%5Cmathbb%7BP%7D(A)%7D%7B%5Cmathbb%7BP%7D(B)%7D%20=%20%5Cfrac%7B%5Cmathbb%7BP%7D(B%20%7C%20A)%5Cmathbb%7BP%7D(A)%7D%7B%5Cmathbb%7BP%7D(B%5Ccap%20A)+%5Cmathbb%7BP%7D(B%5Ccap%20A%5Ec)%7D%20=%20%5Cfrac%7B%5Cmathbb%7BP%7D(B%20%7C%20A)%5Cmathbb%7BP%7D(A)%7D%7B%5Cmathbb%7BP%7D(B%20%7C%20A)%5Cmathbb%7BP%7D(A)+%5Cmathbb%7BP%7D(A%20%7C%20B)%5Cmathbb%7BP%7D(B)%7D%0A"></p>
<p>where, in Bayesin terminology,</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(A%7CB)"> is called <em><span style="color: red">posterior probability</span></em> of <img src="https://latex.codecogs.com/png.latex?A"> given the event <img src="https://latex.codecogs.com/png.latex?B"> or simply, <em><span style="color: red">posterior distribution.</span></em><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(B%7CA)"> is the likelihood: the probability of evidence <img src="https://latex.codecogs.com/png.latex?B"> given that <img src="https://latex.codecogs.com/png.latex?A"> is true.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(A)"> or <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(B)"> are the probabilities of occuring <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?B"> respectively, without any dependence on each other.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(A)"> is called the <em>prior</em> probability or prior distribution and <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BP%7D(B)"> is called the marginal likelihood or marginal probabilities.</li>
</ul>
<p>For two continuous random variable <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?Y">, the conditional probability density function of <img src="https://latex.codecogs.com/png.latex?X"> given the occurence of the value <img src="https://latex.codecogs.com/png.latex?y"> of <img src="https://latex.codecogs.com/png.latex?Y"> can be given as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_%7BX%7CY%7D%20(x%20%7C%20y)%20=%5Cfrac%7Bf_%7BX,Y%7D(x,y)%7D%7Bf_Y(y)%7D%0A"></p>
<p>or the otherway around,<br>
<img src="https://latex.codecogs.com/png.latex?%0Af_%7BY%7CX%7D%20(y%20%7C%20x)%20=%5Cfrac%7Bf_%7BX,Y%7D(x,y)%7D%7Bf_X(x)%7D%0A"></p>
<p>Therefore, the continuous version of Bayes’s theorem is given as follows</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_%7BY%7CX%7D(y)%20=%20%5Cfrac%7Bf_%7BX%7CY%7D(x)f_Y(y)%7D%7Bf_X(x)%7D%0A"></p>
</section>
<section id="generalization-of-bayess-theorem" class="level3">
<h3 class="anchored" data-anchor-id="generalization-of-bayess-theorem">Generalization of Bayes’s Theorem</h3>
<p>For <img src="https://latex.codecogs.com/png.latex?n"> disjoint set of discrete events <img src="https://latex.codecogs.com/png.latex?B_1,B_2%5Cdots,%20B_n"> where <img src="https://latex.codecogs.com/png.latex?%5COmega%20=%20%5Ccup_%7Bi%7D%5E%7Bn%7DB_i"> and for any event <img src="https://latex.codecogs.com/png.latex?A%5Cin%20%5COmega">, we will have<br>
<img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(A)%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cmathbb%7BP%7D(A%5Ccap%20B_i)%0A"></p>
<p>and this is true by the <a href="https://en.wikipedia.org/wiki/Law_of_total_probability" style="text-decoration:none">law of total probability</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/bayesianclassification/index_files/figure-html/cell-3-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="540" height="319"></a></p>
</figure>
</div>
<p>Then the Bayes’s rule extends to the following</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(B_i%7CA)%20=%20%5Cfrac%7B%5Cmathbb%7BP%7D(A%7CB_i)%5Cmathbb%7BP%7D(B_i)%7D%7B%5Cmathbb%7BP%7D(A)%7D=%5Cfrac%7B%5Cmathbb%7BP%7D(A%7CB_i)%5Cmathbb%7BP%7D(B_i)%7D%7B%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cmathbb%7BP%7D(A%7CB_i)%5Cmathbb%7BP%7D(B_i)%7D%0A"></p>
<p>The continuous version would be <img src="https://latex.codecogs.com/png.latex?%0Af_%7BY=y%7CX=x%7D(y%7Cx)%20=%20%5Cfrac%7Bf_%7BX%7CY=y%7D(x)f_Y(y)%7D%7B%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Df_%7BX%7CY=y%7D(x%7Cu)f_%7BY%7D(u)du%7D%0A"></p>
</section>
</section>
<section id="probabilistic-models" class="level2">
<h2 class="anchored" data-anchor-id="probabilistic-models">Probabilistic Models</h2>
<p style="text-align: justify">
Bayes’s theorem gets us the posterior probability given the data with a prior. Therefore, for classification tasks in machine learning, we can use Bayesin style models for classification by maximizing the numerator and minimizing the denominator in the previous equation, for any given class. For instance, say we have a <img src="https://latex.codecogs.com/png.latex?d-"> dimensional data collected as a random matrix <img src="https://latex.codecogs.com/png.latex?X"> and the response variable <img src="https://latex.codecogs.com/png.latex?y"> is a categorical one with <img src="https://latex.codecogs.com/png.latex?c"> categories. Then for a given data vector <img src="https://latex.codecogs.com/png.latex?X'">, the posterior distibution that it falls for category <img src="https://latex.codecogs.com/png.latex?j"> is given as
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BP%7D(y=j%7CX=X')=%5Cfrac%7B%5Cpi_j%20f_j(X')%7D%7B%5Csum_%7Bi=1%7D%5E%7Bc%7D%5Cpi_i%20f_i(X')%7D%0A"></p>
<p>where,</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f_i(X)"> is the probability density function of the features conditioned on <img src="https://latex.codecogs.com/png.latex?y"> being class <img src="https://latex.codecogs.com/png.latex?i"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_i%20=%5Cmathbb%7BP%7D(y=i)"></li>
</ul>
<p>We can estimate <img src="https://latex.codecogs.com/png.latex?%5Cpi_i"> as the fraction of observations which belong to class <img src="https://latex.codecogs.com/png.latex?i">.</p>
<section id="linear-discriminant-analysis-lda" class="level3">
<h3 class="anchored" data-anchor-id="linear-discriminant-analysis-lda">Linear Discriminant Analysis (LDA)</h3>
<p style="text-align: justify">
To connect Linear Discriminant Analysis (LDA) with the Bayesian probabilistic classification, we start by considering the Bayes Theorem and the assumptions made in LDA. We adapt the Bayes theorem for classification as follows
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(C_k%20%7C%20%5Cmathbf%7Bx%7D)%20=%20%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20P(C_k)%7D%7BP(%5Cmathbf%7Bx%7D)%7D%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(C_k%20%7C%20%5Cmathbf%7Bx%7D)"> is the posterior probability that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> belongs to class <img src="https://latex.codecogs.com/png.latex?C_k">,</li>
<li><img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D%20%7C%20C_k)"> is the likelihood (the probability of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> given class <img src="https://latex.codecogs.com/png.latex?C_k">),</li>
<li><img src="https://latex.codecogs.com/png.latex?P(C_k)"> is the prior probability of class <img src="https://latex.codecogs.com/png.latex?C_k">,</li>
<li><img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D)"> is the marginal likelihood (normalizing constant).</li>
</ul>
<section id="gaussian-assumption-in-lda" class="level4">
<h4 class="anchored" data-anchor-id="gaussian-assumption-in-lda">Gaussian Assumption in LDA</h4>
<p>LDA assumes that:</p>
<ul>
<li>The likelihood for each class follows a Gaussian distribution with a common covariance matrix <img src="https://latex.codecogs.com/png.latex?%5CSigma">, i.e.,</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20=%20%5Cfrac%7B1%7D%7B(2%5Cpi)%5E%7Bd/2%7D%20%7C%5CSigma%7C%5E%7B1/2%7D%7D%20%5Cexp%5Cleft(-%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5Cright)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cmu%7D_k"> is the mean of class <img src="https://latex.codecogs.com/png.latex?C_k"> and <img src="https://latex.codecogs.com/png.latex?%5CSigma"> is the shared covariance matrix. Now let’s talk about <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cmu%7D_k"> and <img src="https://latex.codecogs.com/png.latex?%5CSigma">.</p>
<p><strong>One feature or dimension</strong><br>
For a single feature <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?N_k"> samples <img src="https://latex.codecogs.com/png.latex?x_%7Bk,1%7D,x_%7Bk,2%7D,%5Cdots,%20x_%7Bk,N%7D"> for class <img src="https://latex.codecogs.com/png.latex?C_k">, the mean <img src="https://latex.codecogs.com/png.latex?%5Cmu_k">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_k%20=%20%5Cfrac%7B1%7D%7BN_k%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D%20x_%7Bk,i%7D%0A"></p>
<p>and variance <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> is calculated as the variance within-class variance <img src="https://latex.codecogs.com/png.latex?%5Csigma_k%5E2"> for each class</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma_k%5E2%20=%20%5Cfrac%7B1%7D%7BN_k-1%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D(x_%7Bk,i%7D-%5Cmu_k)%5E2%0A"></p>
<p>and then the pooled variance <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> is calculated by averaging these variances, weighted by the degrees of freedom in each class:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma%5E2%20=%20%5Cfrac%7B1%7D%7Bn-%5Cmathcal%7BC%7D%7D%5Csum_%7Bk=1%7D%5E%7B%5Cmathcal%7BC%7D%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D(x_%7Bk,i%7D-%5Cmu_k)%5E2%0A"></p>
<p>where, <img src="https://latex.codecogs.com/png.latex?n"> is the total number of samples accross all classes, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D"> is the number of classes, and <img src="https://latex.codecogs.com/png.latex?x_%7Bk,i%7D"> are samples from each class <img src="https://latex.codecogs.com/png.latex?C_k">.</p>
<p><strong>For multi-dimensional data</strong></p>
<p>If we have <img src="https://latex.codecogs.com/png.latex?d"> features (e.g., if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a <img src="https://latex.codecogs.com/png.latex?d-">dimensional vector), we calculate the mean vector <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cmu%7D_k"> for each feature across the <img src="https://latex.codecogs.com/png.latex?N_k"> samples in class <img src="https://latex.codecogs.com/png.latex?C_k"> as follows</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cboldsymbol%7B%5Cmu%7D_k%20=%20%5Cfrac%7B1%7D%7BN_k%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D%5Cmathbf%7Bx%7D_%7Bk,i%7D%0A"></p>
<p>and the covariance matrix for each class <img src="https://latex.codecogs.com/png.latex?C_k">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CSigma_k%20=%20%5Cfrac%7B1%7D%7BN_k%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D%20(%5Cmathbf%7Bx%7D_%7Bk,i%7D-%5Cboldsymbol%7B%5Cmu%7D_k)(%5Cmathbf%7Bx%7D_%7Bk,i%7D-%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%0A"></p>
<p>Therefore, the pooled variance</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CSigma%20=%20%5Cfrac%7B1%7D%7Bn-%5Cmathcal%7BC%7D%7D%5Csum_%7Bk=1%7D%5E%7B%5Cmathcal%7BC%7D%7D%5Csum_%7Bi=1%7D%5E%7BN_k%7D%20(%5Cmathbf%7Bx%7D_%7Bk,i%7D-%5Cboldsymbol%7B%5Cmu%7D_k)(%5Cmathbf%7Bx%7D_%7Bk,i%7D-%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%0A"></p>
</section>
<section id="log-likelihood-ratio" class="level4">
<h4 class="anchored" data-anchor-id="log-likelihood-ratio">Log Likelihood Ratio</h4>
<p style="text-align: justify">
For simplicity, let’s say we have only two classes <img src="https://latex.codecogs.com/png.latex?C_1"> and <img src="https://latex.codecogs.com/png.latex?C_2">. To derive a decision boundary, we take the ratio of the posterior probabilities for two classes <img src="https://latex.codecogs.com/png.latex?C_1"> and <img src="https://latex.codecogs.com/png.latex?C_2">, and then take the logarithm. The rationality behind this approach is when we divide a relatively bigger number by a smaller number we get a larger number and smaller number if we reverse the divison. Since we are working with the probabilities, therefore, we take logarithm.
</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Clog%5Cleft(%5Cfrac%7BP(C_1%20%7C%20%5Cmathbf%7Bx%7D)%7D%7BP(C_2%20%7C%20%5Cmathbf%7Bx%7D)%7D%5Cright)%20&amp;=%20%5Clog%5Cleft(%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_1)%20P(C_1)%7D%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_2)%20P(C_2)%7D%5Cright)%5C%5C%0A&amp;%20=%5Clog%5Cleft(%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_1)%7D%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_2)%7D%5Cright)%20+%20%5Clog%5Cleft(%5Cfrac%7BP(C_1)%7D%7BP(C_2)%7D%5Cright)%0A%5Cend%7Balign*%7D"></p>
<p>Using the Gaussian likelihood assumption, we expand the terms <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D%20%7C%20C_1)"> and <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D%20%7C%20C_2)">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Clog%5Cleft(%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_1)%7D%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_2)%7D%5Cright)%20&amp;=%5Clog%7B%5Cleft(%5Cfrac%7B%5Cfrac%7B1%7D%7B(2%5Cpi)%5E%7B%5Cfrac%7Bd%7D%7B2%7D%7D%5Csqrt%7B%7C%5CSigma%7C%7D%7De%5E%7B-%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7Bx%7D-%5Cboldsymbol%7B%5Cmu%7D_1)%5ET%5CSigma%5E%7B-1%7D(%5Cmathbf%7Bx%7D-%5Cboldsymbol%7B%5Cmu%7D_1)%7D%7D%7B%5Cfrac%7B1%7D%7B(2%5Cpi)%5E%7B%5Cfrac%7Bd%7D%7B2%7D%7D%5Csqrt%7B%7C%5CSigma%7C%7D%7De%5E%7B-%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7Bx%7D-%5Cboldsymbol%7B%5Cmu%7D_2)%5ET%5CSigma%5E%7B-1%7D(%5Cmathbf%7Bx%7D-%5Cboldsymbol%7B%5Cmu%7D_2)%7D%7D%5Cright)%7D%5C%5C%0A&amp;=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%5B%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_1)%5ET%20%5CSigma%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_1)%20-%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)%5ET%20%5CSigma%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)%20%5Cright%5D%5C%5C%0A&amp;%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%5B%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cmathbf%7Bx%7D%20-%202%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_1%20+%20%5Cboldsymbol%7B%5Cmu%7D_1%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu_1%7D%20-%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cmathbf%7Bx%7D%20+%202%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_2%20-%20%5Cboldsymbol%7B%5Cmu%7D_2%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu_2%7D%5Cright%5D%5C%5C%0A&amp;%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft%5B%20-%202%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_1%20+%20%5Cboldsymbol%7B%5Cmu%7D_1%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu_1%7D%20%20+%202%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_2%20-%20%5Cboldsymbol%7B%5Cmu%7D_2%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu_2%7D%5Cright%5D%5C%5C%0A&amp;%20=%20%5Cmathbf%7Bx%7D%5ET%5CSigma%5E%7B-1%7D(%5Cboldsymbol%7B%5Cmu%7D_1-%5Cboldsymbol%7B%5Cmu%7D_2)-%5Cfrac%7B1%7D%7B2%7D(%5Cboldsymbol%7B%5Cmu%7D_1%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_1+%5Cboldsymbol%7B%5Cmu%7D_2%5ET%5CSigma%5E%7B-1%7D%5Cboldsymbol%7B%5Cmu%7D_2)%5C%5C%0A&amp;%20=%20%5Cmathbf%7Bx%7D%5ET%5Cmathbf%7Bw%7D+%5Ctext%7Bconstant%7D;%5Chspace%7B4mm%7D%5Ctext%7Bwhere,%20%7D%5Chspace%7B4mm%7D%5Cmathbf%7Bw%7D%20=%20%5CSigma%5E%7B-1%7D%20(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)%5C%5C%0A%5Cend%7Balign*%7D"></p>
<p>Therefore, we can write</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%5Cleft(%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_1)%7D%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_2)%7D%5Cright)%20=%20%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D+%5Ctext%7Bconstant%7D%0A"></p>
<p>since <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D=%5Cmathbf%7Bx%7D%5ET%5Cmathbf%7Bw%7D">, as inner product is commutative. This is the linear projection vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> that LDA uses.</p>
</section>
<section id="fishers-discriminant-ratio" class="level4">
<h4 class="anchored" data-anchor-id="fishers-discriminant-ratio">Fisher’s Discriminant Ratio</h4>
<p style="text-align:justify">
Now, we derive the Fisher’s Discriminant Ratio. The goal is to find a projection <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> that maximizes the separation between classes (between-class variance) and minimizes the spread within each class (within-class variance).
</p>
<ul>
<li><strong>Between-class scatter</strong> <img src="https://latex.codecogs.com/png.latex?S_B"> is defined as:</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_B%20=%20(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)%5ET%0A"></p>
<ul>
<li><strong>Within-class scatter</strong> <img src="https://latex.codecogs.com/png.latex?S_W"> is the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5CSigma">, assuming equal covariance for both classes.</li>
</ul>
<p>The Fisher’s discriminant ratio is the objective function to maximize:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Cmathbf%7Bw%7D)%20=%20%5Cfrac%7B%5Cmathbf%7Bw%7D%5ET%20S_B%20%5Cmathbf%7Bw%7D%7D%7B%5Cmathbf%7Bw%7D%5ET%20S_W%20%5Cmathbf%7Bw%7D%7D%0A"></p>
<p>Substituting <img src="https://latex.codecogs.com/png.latex?S_B"> and <img src="https://latex.codecogs.com/png.latex?S_W"> into this expression, we get:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Cmathbf%7Bw%7D)%20=%20%5Cfrac%7B%5Cmathbf%7Bw%7D%5ET%20(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)%5ET%20%5Cmathbf%7Bw%7D%7D%7B%5Cmathbf%7Bw%7D%5ET%20%5CSigma%20%5Cmathbf%7Bw%7D%7D%0A"></p>
<p>Thus, maximizing this ratio gives the direction <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%20=%20%5CSigma%5E%7B-1%7D%20(%5Cboldsymbol%7B%5Cmu%7D_1%20-%20%5Cboldsymbol%7B%5Cmu%7D_2)">, which is the same as the result from the Bayesian classification.</p>
</section>
<section id="summary" class="level4">
<h4 class="anchored" data-anchor-id="summary">Summary</h4>
<p>The Fisher’s Discriminant Ratio arises as a byproduct of maximizing the posterior probability ratios between two classes under Gaussian assumptions. It captures the optimal linear projection to maximize the separation between classes (via between-class scatter) and minimize the spread within classes (via within-class scatter).</p>
</section>
</section>
<section id="quadratic-discriminant-analysis-qda" class="level3">
<h3 class="anchored" data-anchor-id="quadratic-discriminant-analysis-qda">Quadratic Discriminant Analysis (QDA)</h3>
<p style="text-align: justify">
Unlike LDA, we allow each class <img src="https://latex.codecogs.com/png.latex?C_k"> to have its own covariance matrix <img src="https://latex.codecogs.com/png.latex?%5CSigma_k">, leading to a more flexible model capable of handling classes with different shapes and orientations in feature space. Here’s how we can derive the discriminant function for QDA.
</p>
<section id="discriminant-function-for-qda" class="level4">
<h4 class="anchored" data-anchor-id="discriminant-function-for-qda">Discriminant Function for QDA</h4>
<p>In QDA, we aim to classify a sample <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> based on the probability that it belongs to class <img src="https://latex.codecogs.com/png.latex?C_k">, given by <img src="https://latex.codecogs.com/png.latex?P(C_k%7C%5Cmathbf%7Bx%7D)">. Using Bayes’ theorem, we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(C_k%20%7C%20%5Cmathbf%7Bx%7D)%20=%20%5Cfrac%7BP(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20P(C_k)%7D%7BP(%5Cmathbf%7Bx%7D)%7D%0A"></p>
<p>Since we’re primarily interested in maximizing this value to classify <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, we can focus on maximizing the posterior probability <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20P(C_k)">.</p>
</section>
<section id="likelihood-of-mathbfx-in-class-c_k" class="level4">
<h4 class="anchored" data-anchor-id="likelihood-of-mathbfx-in-class-c_k">Likelihood of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> in Class <img src="https://latex.codecogs.com/png.latex?C_k"></h4>
<p>Assuming that the feature vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> follows a Gaussian distribution within each class <img src="https://latex.codecogs.com/png.latex?C_k">, the likelihood <img src="https://latex.codecogs.com/png.latex?P(%5Cmathbf%7Bx%7D%20%7C%20C_k)"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20=%20%5Cfrac%7B1%7D%7B(2%20%5Cpi)%5E%7Bd/2%7D%20%7C%5CSigma_k%7C%5E%7B1/2%7D%7D%20%5Cexp%20%5Cleft(%20-%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma_k%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%20%5Cright)%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cmu%7D_k"> is the mean vector for class <img src="https://latex.codecogs.com/png.latex?C_k">,</li>
<li><img src="https://latex.codecogs.com/png.latex?%5CSigma_k"> is the covariance matrix for class <img src="https://latex.codecogs.com/png.latex?C_k">,</li>
<li><img src="https://latex.codecogs.com/png.latex?d"> is the dimensionality of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</li>
</ul>
</section>
<section id="log-of-the-posterior-quadratic-discriminant" class="level4">
<h4 class="anchored" data-anchor-id="log-of-the-posterior-quadratic-discriminant">Log of the Posterior (Quadratic Discriminant)</h4>
<p>To simplify the computation, we take the logarithm of the posterior probability. Ignoring constant terms that do not depend on <img src="https://latex.codecogs.com/png.latex?k">, we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cln%20P(%5Cmathbf%7Bx%7D%20%7C%20C_k)%20P(C_k)%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma_k%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%20+%20%5Cln%20%7C%5CSigma_k%7C%20%5Cright)%20+%20%5Cln%20P(C_k)%0A"></p>
<p>The discriminant function for QDA can then be expressed as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta_k(%5Cmathbf%7Bx%7D)%20=%20-%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma_k%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%7C%5CSigma_k%7C%20+%20%5Cln%20P(C_k)%0A"></p>
</section>
<section id="expanding-the-quadratic-term" class="level4">
<h4 class="anchored" data-anchor-id="expanding-the-quadratic-term">Expanding the Quadratic Term</h4>
<p>Let’s expand the quadratic term:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma_k%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%0A"></p>
<p>Expanding this gives:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%5ET%20%5CSigma_k%5E%7B-1%7D%20(%5Cmathbf%7Bx%7D%20-%20%5Cboldsymbol%7B%5Cmu%7D_k)%20=%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cmathbf%7Bx%7D%20-%202%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20+%20%5Cboldsymbol%7B%5Cmu%7D_k%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%0A"></p>
<p>Substituting this expansion into the discriminant function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta_k(%5Cmathbf%7Bx%7D)%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cmathbf%7Bx%7D%20-%202%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20+%20%5Cboldsymbol%7B%5Cmu%7D_k%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20%5Cright)%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%7C%5CSigma_k%7C%20+%20%5Cln%20P(C_k)%0A"></p>
</section>
<section id="final-form-of-the-qda-discriminant-function" class="level4">
<h4 class="anchored" data-anchor-id="final-form-of-the-qda-discriminant-function">Final Form of the QDA Discriminant Function</h4>
<p>Rearranging terms, we get:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta_k(%5Cmathbf%7Bx%7D)%20=%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cmathbf%7Bx%7D%20+%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%7C%5CSigma_k%7C%20+%20%5Cln%20P(C_k)%0A"></p>
</section>
<section id="key-points-in-qda" class="level4">
<h4 class="anchored" data-anchor-id="key-points-in-qda">Key Points in QDA</h4>
<ul>
<li><strong>Quadratic term</strong>: Unlike LDA, QDA includes a quadratic term in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, <img src="https://latex.codecogs.com/png.latex?-%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cmathbf%7Bx%7D">, which allows QDA to model classes with different covariances.</li>
<li><strong>Linear term</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k"> is a linear term in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</li>
<li><strong>Constant term</strong>: The remaining terms <img src="https://latex.codecogs.com/png.latex?-%5Cfrac%7B1%7D%7B2%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%5ET%20%5CSigma_k%5E%7B-1%7D%20%5Cboldsymbol%7B%5Cmu%7D_k%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Cln%20%7C%5CSigma_k%7C%20+%20%5Cln%20P(C_k)"> are independent of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</li>
</ul>
<p>Because of the quadratic term, the decision boundaries in QDA are generally <strong>quadratic surfaces</strong>, allowing it to handle more complex class separations than LDA, which has linear boundaries.</p>
</section>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>“The Elements of Statistical Learning” by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</strong>
<ul>
<li>This book is an excellent resource for both Linear and Quadratic Discriminant Analysis, including mathematical derivations, explanations of Gaussian discriminant analysis, and the context for using LDA and QDA.</li>
<li>See Chapter 4: Linear Methods for Classification.</li>
</ul></li>
<li><strong>“Pattern Recognition and Machine Learning” by Christopher M. Bishop</strong>
<ul>
<li>Bishop’s book offers a clear introduction to probabilistic classification, Bayes theorem, and discriminant analysis.</li>
<li>See Chapter 4: Linear Models for Classification.</li>
</ul></li>
<li><strong>“Machine Learning: A Probabilistic Perspective” by Kevin P. Murphy</strong>
<ul>
<li>This text provides derivations and explanations of LDA and QDA from a probabilistic and Bayesian perspective.</li>
<li>See Chapter 7: Linear Discriminant Analysis.</li>
</ul></li>
<li><strong>“Applied Multivariate Statistical Analysis” by Richard A. Johnson and Dean W. Wichern</strong>
<ul>
<li>This book goes deeper into the statistical foundation behind discriminant analysis, including pooled variance, unbiased estimators, and the assumptions behind LDA and QDA.</li>
<li>See Chapter 11: Discrimination and Classification.</li>
</ul></li>
<li><strong>“Introduction to the Theory of Statistics” by Alexander M. Mood, Franklin A. Graybill, and Duane C. Boes</strong>
<ul>
<li>This text provides a theoretical foundation on statistical concepts, including unbiased estimators and quadratic forms, which underlie LDA and QDA derivations.</li>
<li>Relevant for concepts of unbiased estimation and quadratic forms.</li>
</ul></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/bayesianclassification/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/bayesianclassification/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1729137600000" data-listing-file-modified-sort="1742010631607" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="27" data-listing-word-count-sort="5383">
<a href="../../posts/lda/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/lda/lda.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Linear Discriminant Analysis (LDA)
</h5>
<div class="listing-reading-time card-text text-muted">
27 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 17, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Bayesian {Probabilistic} {Models} for {Classification}},
  date = {2024-10-22},
  url = {https://mrislambd.github.io/posts/bayesianclassification/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Bayesian Probabilistic Models for
Classification.”</span> October 22, 2024. <a href="https://mrislambd.github.io/posts/bayesianclassification/">https://mrislambd.github.io/posts/bayesianclassification/</a>.
</div></div></section></div> ]]></description>
  <category>Machine Learning</category>
  <category>Data Science</category>
  <category>Bayesian Inference</category>
  <category>Bayesian Statistics</category>
  <category>Statistics</category>
  <guid>https://mrislambd.github.io/posts/bayesianclassification/</guid>
  <pubDate>Tue, 22 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Classification: Linear Discriminant Analysis (LDA)</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/lda/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Linear Discriminant Analysis (LDA) is a supervised machine learning algorithm commonly used for classification tasks. It is widely applied when dealing with datasets where the number of predictors (features) exceeds the number of observations, or when multicollinearity is a concern. LDA works by projecting data onto a lower-dimensional space, maximizing the separation between classes.
</p>
</section>
<section id="mathematical-foundation-of-lda" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-foundation-of-lda">Mathematical Foundation of LDA</h2>
<p style="text-align: justify">
Let’s assume we have a dataset <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20p%7D"> consisting of <img src="https://latex.codecogs.com/png.latex?n"> data points and <img src="https://latex.codecogs.com/png.latex?p"> features, and each data point belongs to one of <img src="https://latex.codecogs.com/png.latex?K"> distinct classes. The goal of LDA is to find a new space (called a discriminant space) in which the classes are maximally separated, i.e.&nbsp;we want to <strong>maximize the separability between classes</strong> while <strong>minimizing the variation within each class</strong>. This can be mathematically expressed as finding a projection that maximizes the ratio of between-class variance to within-class variance.
</p>
<p>For each class <img src="https://latex.codecogs.com/png.latex?C_k"> (where <img src="https://latex.codecogs.com/png.latex?k%20%5Cin%20%5C%7B1,%202,%20%5Cdots,%20K%5C%7D">):</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> is the <strong>mean vector</strong> of class <img src="https://latex.codecogs.com/png.latex?C_k">.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu"> is the <strong>overall mean</strong> of the entire dataset.</li>
</ul>
<p><strong>Class Mean</strong>: For each class <img src="https://latex.codecogs.com/png.latex?C_k">, the mean is calculated as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_k%20=%20%5Cfrac%7B1%7D%7BN_k%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20x_i%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?N_k"> is the number of data points in class <img src="https://latex.codecogs.com/png.latex?C_k">, and <img src="https://latex.codecogs.com/png.latex?x_i"> represents individual data points.</p>
<p><strong>Overall Mean</strong>: The mean of the entire dataset is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i%0A"></p>
<p>To understand how well classes are separated, we need two key measures:</p>
<ol type="1">
<li><p><strong>Within-Class Scatter Matrix <img src="https://latex.codecogs.com/png.latex?S_W"></strong><br>
The within-class scatter matrix measures how the data points of each class deviate from the class mean. It captures the <strong>spread of data points within each class</strong>. For class <img src="https://latex.codecogs.com/png.latex?C_k">, the scatter matrix is calculated as:<br>
<img src="https://latex.codecogs.com/png.latex?%0AS_W%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20(x_i%20-%20%5Cmu_k)(x_i%20-%20%5Cmu_k)%5ET%0A"></p>
<p>This formula is saying that for each class <img src="https://latex.codecogs.com/png.latex?C_k">, we calculate the distance of every point <img src="https://latex.codecogs.com/png.latex?x_i"> from the mean of its class <img src="https://latex.codecogs.com/png.latex?%5Cmu_k">, and then sum these squared distances across all classes.</p></li>
<li><p><strong>Between-Class Scatter Matrix <img src="https://latex.codecogs.com/png.latex?S_B"></strong><br>
The between-class scatter matrix measures how the <strong>class means deviate from the overall mean</strong>. It captures how well-separated the classes are.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_B%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20N_k%20(%5Cmu_k%20-%20%5Cmu)(%5Cmu_k%20-%20%5Cmu)%5ET%0A"></p>
<p>In this case, for each class <img src="https://latex.codecogs.com/png.latex?C_k">, we calculate the distance between the mean of class <img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> and the overall mean <img src="https://latex.codecogs.com/png.latex?%5Cmu">, then scale this by the number of points in class <img src="https://latex.codecogs.com/png.latex?C_k">.</p></li>
</ol>
<hr>
<p style="text-align: justify">
LDA aims to find a transformation that maximizes the separation between classes. This is done by finding a linear projection <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> such that the <strong>between-class scatter is maximized</strong> and the <strong>within-class scatter is minimized</strong>. Mathematically, the optimization problem becomes:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Cmathbf%7Bw%7D)%20=%20%5Cfrac%7B%5Cmathbf%7Bw%7D%5ET%20S_B%20%5Cmathbf%7Bw%7D%7D%7B%5Cmathbf%7Bw%7D%5ET%20S_W%20%5Cmathbf%7Bw%7D%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?S_B%20%5Cmathbf%7Bw%7D"> captures the between-class variance (how well-separated the classes are in the new projection).<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?S_W%20%5Cmathbf%7Bw%7D"> captures the within-class variance (how tightly packed the points of the same class are in the new projection).</li>
</ul>
<p>This ratio <img src="https://latex.codecogs.com/png.latex?J(%5Cmathbf%7Bw%7D)"> is known as the <strong>Fisher’s discriminant ratio</strong>. The goal is to find <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> that maximizes this ratio. To maximize the Fisher’s discriminant ratio, we need to solve the following generalized eigenvalue problem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_W%5E%7B-1%7D%20S_B%20%5Cmathbf%7Bw%7D%20=%20%5Clambda%20%5Cmathbf%7Bw%7D%0A"></p>
<p>Here, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> is the vector that defines the linear combination of features that maximizes class separation, and <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is an eigenvalue that represents how much variance is explained by that direction.</p>
<p>The solution to this equation gives us the eigenvectors (directions) and eigenvalues (variances) of the transformed space. We select the top eigenvectors corresponding to the largest eigenvalues to form the projection matrix <img src="https://latex.codecogs.com/png.latex?W">.</p>
<hr>
</section>
<section id="dimensionality-reduction" class="level2">
<h2 class="anchored" data-anchor-id="dimensionality-reduction">Dimensionality Reduction</h2>
<p style="text-align: justify">
The LDA transformation reduces the dimensionality of the data by projecting it onto a subspace spanned by the eigenvectors with the largest eigenvalues. For a dataset with <img src="https://latex.codecogs.com/png.latex?K"> classes, LDA can reduce the data to at most <img src="https://latex.codecogs.com/png.latex?K-1"> dimensions because <img src="https://latex.codecogs.com/png.latex?S_B"> has rank <img src="https://latex.codecogs.com/png.latex?K-1">. <br><br> If we have two classes, LDA will reduce the data to a one-dimensional subspace. For three classes, LDA can project the data onto a two-dimensional subspace, and so on.
</p>
<hr>
<p>Now before diving into the python code, let’s do some math by hand so that we can understand the skeleton of the process. Let’s create a small dataset with 6 features and 4 observations divided into 3 classes. We will use this dataset to manually go through the Linear Discriminant Analysis (LDA) process step by step.</p>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Observation</th>
<th>Feature 1</th>
<th>Feature 2</th>
<th>Feature 3</th>
<th>Feature 4</th>
<th>Feature 5</th>
<th>Feature 6</th>
<th>Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?x_1"></td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td><img src="https://latex.codecogs.com/png.latex?C_1"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?x_2"></td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td><img src="https://latex.codecogs.com/png.latex?C_1"></td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?x_3"></td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td><img src="https://latex.codecogs.com/png.latex?C_2"></td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?x_4"></td>
<td>7</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td><img src="https://latex.codecogs.com/png.latex?C_3"></td>
</tr>
</tbody>
</table>
<p>Now, we’ll walk through the mathematical steps of LDA for this small dataset.</p>
</section>
<section id="compute-class-means-mu_k-for-each-class" class="level3">
<h3 class="anchored" data-anchor-id="compute-class-means-mu_k-for-each-class">1. Compute Class Means <img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> for each class:</h3>
<ul>
<li><p>Class <img src="https://latex.codecogs.com/png.latex?C_1"> (mean of <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2">): <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_1%20=%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5C%5C%208%20%5Cend%7Bbmatrix%7D%20%5Cright)%20=%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%203.5%20%5C%5C%204.5%20%5C%5C%205.5%20%5C%5C%206.5%20%5C%5C%207.5%20%5Cend%7Bbmatrix%7D%0A"></p></li>
<li><p>Class <img src="https://latex.codecogs.com/png.latex?C_2"> (only one observation <img src="https://latex.codecogs.com/png.latex?x_3">): <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_2%20=%20%5Cbegin%7Bbmatrix%7D%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%0A"></p></li>
<li><p>Class <img src="https://latex.codecogs.com/png.latex?C_3"> (only one observation <img src="https://latex.codecogs.com/png.latex?x_4">): <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_3%20=%20%5Cbegin%7Bbmatrix%7D%207%20%5C%5C%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%0A"></p></li>
</ul>
</section>
<section id="compute-overall-mean-mu" class="level3">
<h3 class="anchored" data-anchor-id="compute-overall-mean-mu">2. Compute Overall Mean <img src="https://latex.codecogs.com/png.latex?%5Cmu">:</h3>
<p>We compute the overall mean <img src="https://latex.codecogs.com/png.latex?%5Cmu">, which is the average of all observations from all classes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu%20=%20%5Cfrac%7B1%7D%7B4%7D%20%5Cleft(%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5C%5C%208%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%207%20%5C%5C%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20%5Cright)=%20%5Cfrac%7B1%7D%7B4%7D%20%5Cbegin%7Bbmatrix%7D%2018%20%5C%5C%2018%20%5C%5C%2018%20%5C%5C%2018%20%5C%5C%2018%20%5C%5C%2018%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="compute-the-within-class-scatter-matrix-s_w" class="level3">
<h3 class="anchored" data-anchor-id="compute-the-within-class-scatter-matrix-s_w">3. <strong>Compute the Within-Class Scatter Matrix <img src="https://latex.codecogs.com/png.latex?S_W"></strong>:</h3>
<p>For each class <img src="https://latex.codecogs.com/png.latex?C_k">, the within-class scatter matrix <img src="https://latex.codecogs.com/png.latex?S_W"> is computed as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_W%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20(x_i%20-%20%5Cmu_k)(x_i%20-%20%5Cmu_k)%5ET%0A"></p>
<p>For <img src="https://latex.codecogs.com/png.latex?C_1">, the within-class scatter matrix is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(x_1%20-%20%5Cmu_1)%20=%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%203.5%20%5C%5C%204.5%20%5C%5C%205.5%20%5C%5C%206.5%20%5C%5C%207.5%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5Cend%7Bbmatrix%7D;%20%5Chspace%7B6mm%7D%20(x_2%20-%20%5Cmu_1)%20=%20%5Cbegin%7Bbmatrix%7D%203%20%5C%5C%204%20%5C%5C%205%20%5C%5C%206%20%5C%5C%207%20%5C%5C%208%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%203.5%20%5C%5C%204.5%20%5C%5C%205.5%20%5C%5C%206.5%20%5C%5C%207.5%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>For class <img src="https://latex.codecogs.com/png.latex?C_1">, the scatter matrix is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AS_%7BW1%7D%20&amp;=%20(x_1%20-%20%5Cmu_1)(x_1%20-%20%5Cmu_1)%5ET%20+%20(x_2%20-%20%5Cmu_1)(x_2%20-%20%5Cmu_1)%5ET%5C%5C%0A&amp;=%5Cbegin%7Bbmatrix%7D%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5C%5C%20-0.5%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20-0.5%20&amp;%20-0.5%20&amp;%20-0.5%20&amp;%20-0.5%20&amp;%20-0.5%20&amp;%20-0.5%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5C%5C%200.5%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5Cend%7Bbmatrix%7D%5C%5C%0A&amp;=%20%5Cbegin%7Bbmatrix%7D%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>For classes <img src="https://latex.codecogs.com/png.latex?C_2"> and <img src="https://latex.codecogs.com/png.latex?C_3">, there is only one data point in each, so there is no within-class scatter:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_%7BW2%7D%20=%200,%20%5Cquad%20S_%7BW3%7D%20=%200%0A"></p>
<p>Thus, the total within-class scatter matrix is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_W%20=%20S_%7BW1%7D%20+%20S_%7BW2%7D%20+%20S_%7BW3%7D%20=%20S_%7BW1%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_W%20=%20%5Cbegin%7Bbmatrix%7D%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="compute-the-between-class-scatter-matrix-s_b" class="level3">
<h3 class="anchored" data-anchor-id="compute-the-between-class-scatter-matrix-s_b">4. Compute the Between-Class Scatter Matrix <img src="https://latex.codecogs.com/png.latex?S_B">:</h3>
<p>For each class <img src="https://latex.codecogs.com/png.latex?C_k">, the between-class scatter matrix is computed as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_B%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20N_k%20(%5Cmu_k%20-%20%5Cmu)(%5Cmu_k%20-%20%5Cmu)%5ET%0A"></p>
<p>For class <img src="https://latex.codecogs.com/png.latex?C_1"> (where <img src="https://latex.codecogs.com/png.latex?N_1%20=%202">):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmu_1%20-%20%5Cmu)%20=%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%203.5%20%5C%5C%204.5%20%5C%5C%205.5%20%5C%5C%206.5%20%5C%5C%207.5%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-2%20%5C%5C%20-1%20%5C%5C%200%20%5C%5C%201%20%5C%5C%202%20%5C%5C%203%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>Thus, for <img src="https://latex.codecogs.com/png.latex?C_1">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AS_%7BB1%7D%20&amp;=%202%20%5Cbegin%7Bbmatrix%7D%20-2%20%5C%5C%20-1%20%5C%5C%200%20%5C%5C%201%20%5C%5C%202%20%5C%5C%203%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%20-1%20&amp;%200%20&amp;%201%20&amp;%202%20&amp;%203%20%5Cend%7Bbmatrix%7D=%202%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%202%20&amp;%200%20&amp;%20-2%20&amp;%20-4%20&amp;%20-6%20%5C%5C%202%20&amp;%201%20&amp;%200%20&amp;%20-1%20&amp;%20-2%20&amp;%20-3%20%5C%5C%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20%5C%5C%20-2%20&amp;%20-1%20&amp;%200%20&amp;%201%20&amp;%202%20&amp;%203%20%5C%5C%20-4%20&amp;%20-2%20&amp;%200%20&amp;%202%20&amp;%204%20&amp;%206%20%5C%5C%20-6%20&amp;%20-3%20&amp;%200%20&amp;%203%20&amp;%206%20&amp;%209%20%5Cend%7Bbmatrix%7D%5C%5C%0A&amp;=%5Cbegin%7Bbmatrix%7D%208%20&amp;%204%20&amp;%200%20&amp;%20-4%20&amp;%20-8%20&amp;%20-12%20%5C%5C%204%20&amp;%202%20&amp;%200%20&amp;%20-2%20&amp;%20-4%20&amp;%20-6%20%5C%5C%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20%5C%5C%20-4%20&amp;%20-2%20&amp;%200%20&amp;%202%20&amp;%204%20&amp;%206%20%5C%5C%20-8%20&amp;%20-4%20&amp;%200%20&amp;%204%20&amp;%208%20&amp;%2012%20%5C%5C%20-12%20&amp;%20-6%20&amp;%200%20&amp;%206%20&amp;%2012%20&amp;%2018%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>For <img src="https://latex.codecogs.com/png.latex?C_2"> (where <img src="https://latex.codecogs.com/png.latex?N_2%20=%201">):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmu_2%20-%20%5Cmu)%20=%20%5Cbegin%7Bbmatrix%7D%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%201.5%20%5C%5C%200.5%20%5C%5C%20-0.5%20%5C%5C%20-1.5%20%5C%5C%20-2.5%20%5C%5C%20-3.5%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>The between-class scatter matrix for <img src="https://latex.codecogs.com/png.latex?C_2"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AS_%7BB2%7D%20&amp;=%20%5Cbegin%7Bbmatrix%7D%201.5%20%5C%5C%200.5%20%5C%5C%20-0.5%20%5C%5C%20-1.5%20%5C%5C%20-2.5%20%5C%5C%20-3.5%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%201.5%20&amp;%200.5%20&amp;%20-0.5%20&amp;%20-1.5%20&amp;%20-2.5%20&amp;%20-3.5%20%5Cend%7Bbmatrix%7D%5C%5C%0A&amp;=%20%5Cbegin%7Bbmatrix%7D%202.25%20&amp;%200.75%20&amp;%20-0.75%20&amp;%20-2.25%20&amp;%20-3.75%20&amp;%20-5.25%20%5C%5C%200.75%20&amp;%200.25%20&amp;%20-0.25%20&amp;%20-0.75%20&amp;%20-1.25%20&amp;%20-1.75%20%5C%5C%20-0.75%20&amp;%20-0.25%20&amp;%200.25%20&amp;%200.75%20&amp;%201.25%20&amp;%201.75%20%5C%5C%20-2.25%20&amp;%20-0.75%20&amp;%200.75%20&amp;%202.25%20&amp;%203.75%20&amp;%205.25%20%5C%5C%20-3.75%20&amp;%20-1.25%20&amp;%201.25%20&amp;%203.75%20&amp;%206.25%20&amp;%208.75%20%5C%5C%20-5.25%20&amp;%20-1.75%20&amp;%201.75%20&amp;%205.25%20&amp;%208.75%20&amp;%2012.25%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>For <img src="https://latex.codecogs.com/png.latex?C_3"> (where <img src="https://latex.codecogs.com/png.latex?N_3%20=%201">):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmu_3%20-%20%5Cmu)%20=%20%5Cbegin%7Bbmatrix%7D%207%20%5C%5C%206%20%5C%5C%205%20%5C%5C%204%20%5C%5C%203%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5C%5C%204.5%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%201.5%20%5C%5C%200.5%20%5C%5C%20-0.5%20%5C%5C%20-1.5%20%5C%5C%20-2.5%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>The between-class scatter matrix for <img src="https://latex.codecogs.com/png.latex?C_3"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AS_%7BB3%7D%20&amp;=%20%5Cbegin%7Bbmatrix%7D%202.5%20%5C%5C%201.5%20%5C%5C%200.5%20%5C%5C%20-0.5%20%5C%5C%20-1.5%20%5C%5C%20-2.5%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%202.5%20&amp;%201.5%20&amp;%200.5%20&amp;%20-0.5%20&amp;%20-1.5%20&amp;%20-2.5%20%5Cend%7Bbmatrix%7D%5C%5C%0A&amp;=%5Cbegin%7Bbmatrix%7D%206.25%20&amp;%203.75%20&amp;%201.25%20&amp;%20-1.25%20&amp;%20-3.75%20&amp;%20-6.25%20%5C%5C%203.75%20&amp;%202.25%20&amp;%200.75%20&amp;%20-0.75%20&amp;%20-2.25%20&amp;%20-3.75%20%5C%5C%201.25%20&amp;%200.75%20&amp;%200.25%20&amp;%20-0.25%20&amp;%20-0.75%20&amp;%20-1.25%20%5C%5C%20-1.25%20&amp;%20-0.75%20&amp;%20-0.25%20&amp;%200.25%20&amp;%200.75%20&amp;%201.25%20%5C%5C%20-3.75%20&amp;%20-2.25%20&amp;%20-0.75%20&amp;%200.75%20&amp;%202.25%20&amp;%203.75%20%5C%5C%20-6.25%20&amp;%20-3.75%20&amp;%20-1.25%20&amp;%201.25%20&amp;%203.75%20&amp;%206.25%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>Total Between-Class Scatter Matrix <img src="https://latex.codecogs.com/png.latex?S_B">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AS_B%20&amp;=%20S_%7BB1%7D%20+%20S_%7BB2%7D%20+%20S_%7BB3%7D%5C%5C%0A&amp;=%5Cbegin%7Bbmatrix%7D%208%20&amp;%204%20&amp;%200%20&amp;%20-4%20&amp;%20-8%20&amp;%20-12%20%5C%5C%204%20&amp;%202%20&amp;%200%20&amp;%20-2%20&amp;%20-4%20&amp;%20-6%20%5C%5C%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20&amp;%200%20%5C%5C%20-4%20&amp;%20-2%20&amp;%200%20&amp;%202%20&amp;%204%20&amp;%206%20%5C%5C%20-8%20&amp;%20-4%20&amp;%200%20&amp;%204%20&amp;%208%20&amp;%2012%20%5C%5C%20-12%20&amp;%20-6%20&amp;%200%20&amp;%206%20&amp;%2012%20&amp;%2018%20%5Cend%7Bbmatrix%7D%20+%20%5Cbegin%7Bbmatrix%7D%202.25%20&amp;%200.75%20&amp;%20-0.75%20&amp;%20-2.25%20&amp;%20-3.75%20&amp;%20-5.25%20%5C%5C%200.75%20&amp;%200.25%20&amp;%20-0.25%20&amp;%20-0.75%20&amp;%20-1.25%20&amp;%20-1.75%20%5C%5C%20-0.75%20&amp;%20-0.25%20&amp;%200.25%20&amp;%200.75%20&amp;%201.25%20&amp;%201.75%20%5C%5C%20-2.25%20&amp;%20-0.75%20&amp;%200.75%20&amp;%202.25%20&amp;%203.75%20&amp;%205.25%20%5C%5C%20-3.75%20&amp;%20-1.25%20&amp;%201.25%20&amp;%203.75%20&amp;%206.25%20&amp;%208.75%20%5C%5C%20-5.25%20&amp;%20-1.75%20&amp;%201.75%20&amp;%205.25%20&amp;%208.75%20&amp;%2012.25%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A&amp;%5C%5C%0A&amp;%20+%20%5Cbegin%7Bbmatrix%7D%206.25%20&amp;%203.75%20&amp;%201.25%20&amp;%20-1.25%20&amp;%20-3.75%20&amp;%20-6.25%20%5C%5C%203.75%20&amp;%202.25%20&amp;%200.75%20&amp;%20-0.75%20&amp;%20-2.25%20&amp;%20-3.75%20%5C%5C%201.25%20&amp;%200.75%20&amp;%200.25%20&amp;%20-0.25%20&amp;%20-0.75%20&amp;%20-1.25%20%5C%5C%20-1.25%20&amp;%20-0.75%20&amp;%20-0.25%20&amp;%200.25%20&amp;%200.75%20&amp;%201.25%20%5C%5C%20-3.75%20&amp;%20-2.25%20&amp;%20-0.75%20&amp;%200.75%20&amp;%202.25%20&amp;%203.75%20%5C%5C%20-6.25%20&amp;%20-3.75%20&amp;%20-1.25%20&amp;%201.25%20&amp;%203.75%20&amp;%206.25%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>Adding the matrices gives:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_B%20=%20%5Cbegin%7Bbmatrix%7D%2016.5%20&amp;%208.5%20&amp;%200.5%20&amp;%20-7.5%20&amp;%20-15.5%20&amp;%20-23.5%20%5C%5C%208.5%20&amp;%204.5%20&amp;%200.5%20&amp;%20-3.5%20&amp;%20-7.5%20&amp;%20-11.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%20-7.5%20&amp;%20-3.5%20&amp;%200.5%20&amp;%204.5%20&amp;%208.5%20&amp;%2012.5%20%5C%5C%20-15.5%20&amp;%20-7.5%20&amp;%200.5%20&amp;%208.5%20&amp;%2016.5%20&amp;%2024.5%20%5C%5C%20-23.5%20&amp;%20-11.5%20&amp;%200.5%20&amp;%2012.5%20&amp;%2024.5%20&amp;%2036.5%20%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="solve-the-eigenvalue-problem" class="level3">
<h3 class="anchored" data-anchor-id="solve-the-eigenvalue-problem">5. Solve the Eigenvalue Problem:</h3>
<p>We now solve the eigenvalue problem:<br>
<img src="https://latex.codecogs.com/png.latex?%0AS_W%5E%7B-1%7D%20S_B%20%5Cmathbf%7Bw%7D%20=%20%5Clambda%20%5Cmathbf%7Bw%7D%0A"></p>
<p style="text-align:justify">
The solution to this eigenvalue problem gives us the eigenvalues <img src="https://latex.codecogs.com/png.latex?%5Clambda"> (which quantify the amount of variance captured in each direction) and the eigenvectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> (which give the directions of maximum class separation). The eigenvector corresponding to the largest eigenvalue defines the direction of the first discriminant axis, which is the direction that maximally separates the classes.
</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cbegin%7Bbmatrix%7D%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5C%5C%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5C%5C%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5C%5C%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5C%5C%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5C%5C%0A6.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20&amp;%206.67%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%2016.5%20&amp;%208.5%20&amp;%200.5%20&amp;%20-7.5%20&amp;%20-15.5%20&amp;%20-23.5%20%5C%5C%208.5%20&amp;%204.5%20&amp;%200.5%20&amp;%20-3.5%20&amp;%20-7.5%20&amp;%20-11.5%20%5C%5C%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20&amp;%200.5%20%5C%5C%20-7.5%20&amp;%20-3.5%20&amp;%200.5%20&amp;%204.5%20&amp;%208.5%20&amp;%2012.5%20%5C%5C%20-15.5%20&amp;%20-7.5%20&amp;%200.5%20&amp;%208.5%20&amp;%2016.5%20&amp;%2024.5%20%5C%5C%20-23.5%20&amp;%20-11.5%20&amp;%200.5%20&amp;%2012.5%20&amp;%2024.5%20&amp;%2036.5%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7Dw_1%5C%5Cw_2%5C%5Cw_3%5C%5Cw_4%5C%5Cw_5%5C%5Cw_6%5Cend%7Bbmatrix%7D&amp;=%5Clambda%5Cbegin%7Bbmatrix%7Dw_1%5C%5Cw_2%5C%5Cw_3%5C%5Cw_4%5C%5Cw_5%5C%5Cw_6%5Cend%7Bbmatrix%7D%5C%5C%0A%5Cimplies%20%5Cbegin%7Bbmatrix%7D%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5C%5C%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5C%5C%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5C%5C%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5C%5C%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5C%5C%0A-2.33%20&amp;%20-1.00%20&amp;%200.33%20&amp;%201.67%20&amp;%203.00%20&amp;%204.33%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7Dw_1%5C%5Cw_2%5C%5Cw_3%5C%5Cw_4%5C%5Cw_5%5C%5Cw_6%5Cend%7Bbmatrix%7D&amp;=%5Clambda%5Cbegin%7Bbmatrix%7Dw_1%5C%5Cw_2%5C%5Cw_3%5C%5Cw_4%5C%5Cw_5%5C%5Cw_6%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
<p>The eigenvalues of the matrix are:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda_1%20=%206.00,%20%5Cquad%20%5Clambda_2%20=%201.78%20%5Ctimes%2010%5E%7B-15%7D,%20%5Cquad%20%5Clambda_3%20=%209.86%20%5Ctimes%2010%5E%7B-32%7D,%20%5Cquad%20%5Clambda_4%20=%200.00,%20%5Cquad%20%5Clambda_5%20=%20-5.47%20%5Ctimes%2010%5E%7B-48%7D,%20%5Cquad%20%5Clambda_6%20=%20-5.95%20%5Ctimes%2010%5E%7B-16%7D%0A"></p>
<p>The two largest eigenvalues are:</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%206.00"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%201.78%20%5Ctimes%2010%5E%7B-15%7D"></li>
</ol>
<p>The corresponding eigenvectors for the two largest eigenvalues are:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bw_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A-0.408%20%5C%5C%0A-0.408%20%5C%5C%0A-0.408%20%5C%5C%0A-0.408%20%5C%5C%0A-0.408%20%5C%5C%0A-0.408%20%5Cend%7Bbmatrix%7D,%20%5Cquad%0A%5Cmathbf%7Bw_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A-0.848%20%5C%5C%0A-0.237%20%5C%5C%0A-0.237%20%5C%5C%0A-0.237%20%5C%5C%0A-0.237%20%5C%5C%0A-0.237%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>By projecting the data onto the eigenvector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">, we transform the original dataset into a lower-dimensional space where class separability is maximized. For this dataset, since there are 3 classes, LDA will find up to <img src="https://latex.codecogs.com/png.latex?K-1%20=%202"> discriminant axes. Let’s see how.</p>
<p>The matrix formed by the two largest eigenvectors is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AW=%5Cbegin%7Bbmatrix%7D%0A-0.408%20&amp;%20-0.848%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5Cend%7Bbmatrix%7D%0A"></p>
<p style="text-align: justify">
This matrix represents the projection directions corresponding to the two largest eigenvalues in the Linear Discriminant Analysis process. With the eigenvectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_1"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_2">, we can now project our original dataset onto the new 2D subspace. <br><br> Now, let <img src="https://latex.codecogs.com/png.latex?X"> represent our original dataset (where each row corresponds to an observation and each column to a feature). The projection of the original data onto the new 2D subspace is given by:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20=%20X%20W%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X"> is the <img src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%206"> matrix (4 observations, 6 features),</li>
<li><img src="https://latex.codecogs.com/png.latex?W"> is the <img src="https://latex.codecogs.com/png.latex?6%20%5Ctimes%202"> matrix of eigenvectors.</li>
</ul>
<p>After multiplying <img src="https://latex.codecogs.com/png.latex?X"> by <img src="https://latex.codecogs.com/png.latex?W">, we obtain the projected data matrix <img src="https://latex.codecogs.com/png.latex?Y">, which is a <img src="https://latex.codecogs.com/png.latex?4%20%5Ctimes%202"> matrix (4 observations, 2 features):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20=%20%5Cbegin%7Bbmatrix%7D%0Ay_%7B11%7D%20&amp;%20y_%7B12%7D%20%5C%5C%0Ay_%7B21%7D%20&amp;%20y_%7B22%7D%20%5C%5C%0Ay_%7B31%7D%20&amp;%20y_%7B32%7D%20%5C%5C%0Ay_%7B41%7D%20&amp;%20y_%7B42%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>This matrix <img src="https://latex.codecogs.com/png.latex?Y"> represents the data in the new 2D space where class separability is maximized. So for our data</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cbegin%7Bbmatrix%7D2&amp;3&amp;4&amp;5&amp;6&amp;7%5C%5C3&amp;4&amp;5&amp;6&amp;7&amp;8%5C%5C6&amp;5&amp;4&amp;3&amp;2&amp;1%5C%5C7&amp;6&amp;5&amp;4&amp;3&amp;2%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%0A-0.408%20&amp;%20-0.848%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5C%5C%0A-0.408%20&amp;%20-0.237%20%5Cend%7Bbmatrix%7D&amp;=%5Cbegin%7Bbmatrix%7D-11.016%20&amp;%20-7.621%5C%5C-13.464%20&amp;%20-9.654%5C%5C%20-8.568%20&amp;%20-8.643%5C%5C-11.016%20&amp;-10.676%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D"></p>
</section>
<section id="step-6-visualizing-the-results" class="level3">
<h3 class="anchored" data-anchor-id="step-6-visualizing-the-results">Step 6: Visualizing the Results</h3>
<p>If we were to plot the projected data in this new 2D space, we would see the observations from different classes are better separated, which is the ultimate goal of LDA. The two axes of this 2D space correspond to the two linear discriminants that maximize the separation between the classes.</p>
<div id="cb0afad1" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>],</span>
<span id="cb1-5">                  [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>],</span>
<span id="cb1-6">                  [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb1-7">                  [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]])</span>
<span id="cb1-8"></span>
<span id="cb1-9">W <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.848</span>],</span>
<span id="cb1-10">                         [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.237</span>],</span>
<span id="cb1-11">                         [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.237</span>],</span>
<span id="cb1-12">                         [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.237</span>],</span>
<span id="cb1-13">                         [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.237</span>],</span>
<span id="cb1-14">                         [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.408</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.237</span>]])</span>
<span id="cb1-15"></span>
<span id="cb1-16">Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, W)</span>
<span id="cb1-17"></span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the projection</span></span>
<span id="cb1-19">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(Y.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]):</span>
<span id="cb1-21">    plt.scatter(Y[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], Y[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Obs </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-22">    plt.text(Y[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, Y[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Obs </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-23"></span>
<span id="cb1-24">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Projected Data after LDA"</span>)</span>
<span id="cb1-25">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD1 (First Linear Discriminant)'</span>)</span>
<span id="cb1-26">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD2 (Second Linear Discriminant)'</span>)</span>
<span id="cb1-27">plt.axhline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-28">plt.axvline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gray'</span>, lw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-29">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-30">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>)</span>
<span id="cb1-31">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-32">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-33">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/lda/index_files/figure-html/cell-2-output-1.png" width="670" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="summary-of-the-process-of-eigenvalue-problem" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-the-process-of-eigenvalue-problem">Summary of the Process of Eigenvalue Problem</h3>
<ol type="1">
<li><strong>Eigenvalue Calculation</strong>: We found the eigenvalues <img src="https://latex.codecogs.com/png.latex?%5Clambda_1"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2"> to be the largest, indicating the directions with the most class separability. We did find only two eigenvaleus since total class is 3.</li>
<li><strong>Eigenvector Calculation</strong>: We computed the eigenvectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_1"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_2"> corresponding to these eigenvalues. These eigenvectors define the directions in the original feature space along which the class separation is maximized.</li>
<li><strong>Projection</strong>: We projected the original dataset onto the new 2D subspace spanned by the eigenvectors. This resulted in a new dataset in 2D, where the different classes are more separable.</li>
</ol>
<p>This completes the detailed walkthrough of solving the eigenvalue problem in LDA for our example dataset.</p>
<hr>
</section>
<section id="final-summary" class="level3">
<h3 class="anchored" data-anchor-id="final-summary">Final Summary</h3>
<ul>
<li><strong>Within-class scatter matrix</strong> <img src="https://latex.codecogs.com/png.latex?S_W"> quantifies the spread of data points within each class, and we calculated it for each class.</li>
<li><strong>Between-class scatter matrix</strong> <img src="https://latex.codecogs.com/png.latex?S_B"> quantifies the separation between the class means, and we calculated it using the mean of each class and the overall mean.</li>
<li>Solving the <strong>eigenvalue problem</strong> <img src="https://latex.codecogs.com/png.latex?S_W%5E%7B-1%7D%20S_B%20%5Cmathbf%7Bw%7D%20=%20%5Clambda%20%5Cmathbf%7Bw%7D"> gives us the directions <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> (eigenvectors) that maximize class separation.</li>
</ul>
<p>This is how LDA works step by step, using a small dataset as an example.</p>
</section>
</section>
<section id="python-code-example" class="level2">
<h2 class="anchored" data-anchor-id="python-code-example">Python Code Example</h2>
<p>Let’s now revisit the Python code, with an understanding of the math behind LDA. First build our own classifier</p>
<div id="24e0f39c" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CustomLDA:</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,n_components <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb2-3">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_components: int, optional (default=None)</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                      Number of components to keep. If None, all components are kept</span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_components <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_components</span>
<span id="cb2-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvalues <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb2-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> </span>
<span id="cb2-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mean_vectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> </span>
<span id="cb2-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.class_means <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb2-13">    </span>
<span id="cb2-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y):</span>
<span id="cb2-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X: ndarray of shape (n_samples, n_features)</span></span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        y: ndarray of shape (n_samples,)</span></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">           Target labels (must be categorical)</span></span>
<span id="cb2-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-21">        n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-22">        class_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.unique(y)</span>
<span id="cb2-23"></span>
<span id="cb2-24">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step1: Compute the class means mu_k for each class </span></span>
<span id="cb2-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mean_vectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-26">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> class_labels:</span>
<span id="cb2-27">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mean_vectors.append(np.mean(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span>c], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb2-28">        </span>
<span id="cb2-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2: Compute the within-class scatter matrix S_W </span></span>
<span id="cb2-30">        S_W <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_features, n_features))</span>
<span id="cb2-31">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> class_labels:</span>
<span id="cb2-32">            class_scatter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.cov(X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span>c].T, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Covariance matrix for each class</span></span>
<span id="cb2-33">            S_W <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> class_scatter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span>c].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb2-34"></span>
<span id="cb2-35">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 3: Compute the between-class scatter matrix S_B</span></span>
<span id="cb2-36">        overall_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(X, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb2-37">        S_B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_features, n_features))</span>
<span id="cb2-38"></span>
<span id="cb2-39"></span>
<span id="cb2-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i,mean_vector <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mean_vectors):</span>
<span id="cb2-41">            n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> class_labels[i]].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-42">            mean_differences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (mean_vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>overall_mean).reshape(n_features,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-43">            S_B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(mean_differences).dot(mean_differences.T)</span>
<span id="cb2-44">        </span>
<span id="cb2-45">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 4: Solve the Eigenvalue problem </span></span>
<span id="cb2-46">        eigvalues, eigvectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.eig(np.linalg.pinv(S_W).dot(S_B))</span>
<span id="cb2-47"></span>
<span id="cb2-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 5: Sort the Eigenvalues and corresponding eigenvectors </span></span>
<span id="cb2-49">        eigvalues_sort_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(eigvalues))[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-50">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvalues <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eigvalues[eigvalues_sort_idx]</span>
<span id="cb2-51">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eigvectors[:,eigvalues_sort_idx]</span>
<span id="cb2-52"></span>
<span id="cb2-53">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 6: Keep only the top n_components</span></span>
<span id="cb2-54">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_components:</span>
<span id="cb2-55">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors[:,:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_components]</span>
<span id="cb2-56">        </span>
<span id="cb2-57">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.class_means <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mean_vectors, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors)</span>
<span id="cb2-58">    </span>
<span id="cb2-59">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,X):</span>
<span id="cb2-60">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Project the data onto the LDA components </span></span>
<span id="cb2-62"></span>
<span id="cb2-63"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb2-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X: ndarray of shape (n_samples, n_features)</span></span>
<span id="cb2-65"></span>
<span id="cb2-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb2-67"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X_transformed: ndarray of shape (n_samples, n_features)</span></span>
<span id="cb2-68"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-69">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.dot(X,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvectors)</span>
<span id="cb2-70">    </span>
<span id="cb2-71">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit_transform(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y):</span>
<span id="cb2-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-73"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fit the LDA model and transform the data.</span></span>
<span id="cb2-74"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb2-75"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb2-76"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X : ndarray of shape (n_samples, n_features)</span></span>
<span id="cb2-77"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Training data.</span></span>
<span id="cb2-78"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        y : ndarray of shape (n_samples,)</span></span>
<span id="cb2-79"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Target labels (must be categorical).</span></span>
<span id="cb2-80"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        </span></span>
<span id="cb2-81"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb2-82"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X_transformed : ndarray of shape (n_samples, n_components)</span></span>
<span id="cb2-83"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Transformed data after fitting.</span></span>
<span id="cb2-84"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-85">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.fit(X, y)</span>
<span id="cb2-86">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.transform(X)</span>
<span id="cb2-87">    </span>
<span id="cb2-88">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb2-89">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-90"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Predict the class labels for new data points.</span></span>
<span id="cb2-91"></span>
<span id="cb2-92"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Parameters:</span></span>
<span id="cb2-93"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X : ndarray of shape (n_samples, n_features)</span></span>
<span id="cb2-94"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            New data to classify.</span></span>
<span id="cb2-95"></span>
<span id="cb2-96"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb2-97"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Predictions: ndarray of shape (n_samples,)</span></span>
<span id="cb2-98"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                     Predicted class labels</span></span>
<span id="cb2-99"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-100">        X_projected <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.transform(X)</span>
<span id="cb2-101"></span>
<span id="cb2-102">        predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-103">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> X_projected:</span>
<span id="cb2-104">            distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.norm(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.class_means, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-105">            predictions.append(np.argmin(distances))</span>
<span id="cb2-106">        </span>
<span id="cb2-107">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.array(predictions)</span>
<span id="cb2-108"></span>
<span id="cb2-109">    </span>
<span id="cb2-110">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> explained_variance_ratio(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb2-111">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb2-112"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Return the percentage of variance explained by each of the selected components</span></span>
<span id="cb2-113"></span>
<span id="cb2-114"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Returns:</span></span>
<span id="cb2-115"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        explained_variance: ndarray of shape (n_components,)</span></span>
<span id="cb2-116"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">                            Percentage of variance explained by each selected components</span></span>
<span id="cb2-117"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb2-118">        total <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvalues)</span>
<span id="cb2-119"></span>
<span id="cb2-120">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> [(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>total) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.eigenvalues[:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_components]]</span></code></pre></div>
</div>
<p>Next we apply both the custom classifier and the classifier from the <code>scikit-learn</code> library.</p>
<div id="b5bad497" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.discriminant_analysis <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearDiscriminantAnalysis <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> LDA</span>
<span id="cb3-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb3-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the dataset</span></span>
<span id="cb3-9">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb3-10">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.data</span>
<span id="cb3-11">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardize the dataset (optional but often improves performance)</span></span>
<span id="cb3-14">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-15">X_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X)</span>
<span id="cb3-16"></span>
<span id="cb3-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split into training and test sets</span></span>
<span id="cb3-18">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_scaled, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-19"></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply LDA from the scikit-learn library</span></span>
<span id="cb3-21">lda1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LDA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reduce to 2 dimensions</span></span>
<span id="cb3-22">X_train_lda1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda1.fit_transform(X_train, y_train)</span>
<span id="cb3-23">X_test_lda1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda1.transform(X_test)</span>
<span id="cb3-24"></span>
<span id="cb3-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply LDA from the custom built classifier</span></span>
<span id="cb3-26">lda2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomLDA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reduce to 2 dimensions</span></span>
<span id="cb3-27">X_train_lda2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda2.fit_transform(X_train, y_train)</span>
<span id="cb3-28">X_test_lda2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda2.transform(X_test)</span>
<span id="cb3-29"></span>
<span id="cb3-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the LDA-transformed data</span></span>
<span id="cb3-31">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb3-32"></span>
<span id="cb3-33">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].scatter(X_train_lda1[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_train_lda1[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rainbow'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb3-34">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD1'</span>)</span>
<span id="cb3-35">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD2'</span>)</span>
<span id="cb3-36">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Scikit-learn'</span>)</span>
<span id="cb3-37">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].scatter(X_train_lda2[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_train_lda2[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rainbow'</span>, edgecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb3-38">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD1'</span>)</span>
<span id="cb3-39">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LD2'</span>)</span>
<span id="cb3-40">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Custom'</span>)</span>
<span id="cb3-41"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> axes:</span>
<span id="cb3-42">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-43">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-44">fig.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LDA: Projection of the Iris Dataset'</span>)</span>
<span id="cb3-45">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/lda/index_files/figure-html/cell-4-output-1.png" width="773" height="394" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Next, apply LDA as a classifiers for the actual classification</p>
<div id="f473c4cc" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">lda_classifier1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LDA()</span>
<span id="cb4-2">lda_classifier1.fit(X_train, y_train)</span>
<span id="cb4-3">y_pred1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda_classifier1.predict(X_test)</span>
<span id="cb4-4"></span>
<span id="cb4-5">lda_classifier2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomLDA()</span>
<span id="cb4-6">lda_classifier2.fit(X_train, y_train)</span>
<span id="cb4-7">y_pred2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda_classifier2.predict(X_test)</span>
<span id="cb4-8"></span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check accuracy</span></span>
<span id="cb4-11">accuracy1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, y_pred1)</span>
<span id="cb4-12">accuracy2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, y_pred2)</span>
<span id="cb4-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'sklearn LDA Classifier Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">% and </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">custom LDA Classifier Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">%'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>sklearn LDA Classifier Accuracy: 100.00% and 
custom LDA Classifier Accuracy: 95.56%</code></pre>
</div>
</div>
<p>Not too bad, huh! Let’s see the confusion matrix for our custom classifier</p>
<div id="57611642" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> confusion_matrix</span>
<span id="cb6-2"></span>
<span id="cb6-3">conf_mat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, y_pred2)</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(pd.DataFrame(</span>
<span id="cb6-6">    conf_mat, </span>
<span id="cb6-7">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pred: Setosa'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pred: Virginica'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pred: Versicolor'</span>],</span>
<span id="cb6-8">    index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual: Setosa'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual: Virginica'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual: Versicolor'</span>]</span>
<span id="cb6-9">))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    Pred: Setosa  Pred: Virginica  Pred: Versicolor
Actual: Setosa                19                0                 0
Actual: Virginica              0               11                 2
Actual: Versicolor             0                0                13</code></pre>
</div>
</div>
<hr>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p style="text-align: justify">
Linear Discriminant Analysis (LDA) is a powerful technique for dimensionality reduction and classification. Its goal is to find directions (linear combinations of the original features) that best separate the classes by maximizing between-class variance while minimizing within-class variance.
</p>
<section id="disclaimer" class="level3">
<h3 class="anchored" data-anchor-id="disclaimer">Disclaimer</h3>
<p style="text-align: justify">
For the mathematical explanation, I used generative AI to produce the matrices and vectors and their manipulations. So it won’t be surprising if a calculation mistake is found. The custom python class was created by the help of ChatGPT4
</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>Fisher, R.A. (1936). “The Use of Multiple Measurements in Taxonomic Problems.” <em>Annals of Eugenics</em>, 7(2), 179–188.<br>
</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.<br>
</li>
<li>Strang, G. (2016). <em>Introduction to Linear Algebra</em> (5th ed.). Wellesley-Cambridge Press.<br>
</li>
<li>Lay, D. C. (2011). <em>Linear Algebra and Its Applications</em> (4th ed.). Pearson.</li>
</ul>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/lda/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/lda/" data-width="750" data-numposts="5">

</div>
<hr>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Classification: {Linear} {Discriminant} {Analysis} {(LDA)}},
  date = {2024-10-17},
  url = {https://mrislambd.github.io/posts/lda/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Classification: Linear Discriminant Analysis
(LDA).”</span> October 17, 2024. <a href="https://mrislambd.github.io/posts/lda/">https://mrislambd.github.io/posts/lda/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/lda/</guid>
  <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/lda/lda.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Classification: Techniques to handle multi-class classification problems</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/multiclass/</link>
  <description><![CDATA[ 




<section id="intro" class="level2">
<h2 class="anchored" data-anchor-id="intro">Introduction</h2>
<p style="text-align: justify">
In machine learning, classification is one of the most common tasks, where the goal is to assign a label to an input from a set of possible categories. While binary classification, where there are only two labels (e.g., spam vs.&nbsp;not spam), is well understood, real-world problems often involve more than two classes—this is where <strong>multi-class classification</strong> comes into play. In this post, we’ll explore various techniques and algorithms used to solve multi-class classification problems effectively.
</p>
</section>
<section id="what" class="level2">
<h2 class="anchored" data-anchor-id="what">What is Multi-class Classification?</h2>
<p style="text-align: justify">
Multi-class classification involves assigning an input to one of several distinct classes. For instance, given an image of an animal, the task may be to classify it as either a dog, cat, horse, or bird. The key challenge here is to handle more than two classes, which introduces additional complexity compared to binary classification.
</p>
</section>
<section id="key" class="level2">
<h2 class="anchored" data-anchor-id="key">Key Approaches to Multi-class Classification</h2>
<p>There are two main ways of handling multi-class classification:</p>
<ol type="1">
<li><strong>Native Multi-class Algorithms:</strong> Some algorithms are inherently designed to work with multiple classes without any modifications.</li>
<li><strong>Binary to Multi-class Strategies:</strong> These approaches decompose the multi-class problem into multiple binary classification problems.</li>
</ol>
<p style="text-align: justify">
Let’s consider the classic Iris dataset that contains three classes of iris species: <em>setosa, versicolor, virginica</em>. We will use this dataset to demonstrate different multi-class classification techniques in python.
</p>
<div id="5a1a4275" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd </span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns </span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt </span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># set the background color</span></span>
<span id="cb1-8">sns.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(rc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'axes.facecolor'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'figure.facecolor'</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>})</span>
<span id="cb1-9">  </span>
<span id="cb1-10"></span>
<span id="cb1-11">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb1-12">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.data, columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.feature_names)</span>
<span id="cb1-13">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span>
<span id="cb1-14">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>({<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'setosa'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'versicolor'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'virginica'</span>})</span>
<span id="cb1-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(df.head())</span>
<span id="cb1-16">sns.pairplot(df, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'species'</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.8</span>, aspect<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.99</span>)</span>
<span id="cb1-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \
0                5.1               3.5                1.4               0.2   
1                4.9               3.0                1.4               0.2   
2                4.7               3.2                1.3               0.2   
3                4.6               3.1                1.5               0.2   
4                5.0               3.6                1.4               0.2   

  species  
0  setosa  
1  setosa  
2  setosa  
3  setosa  
4  setosa  </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/multiclass/index_files/figure-html/cell-2-output-2.png" width="796" height="680" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<section id="native" class="level3">
<h3 class="anchored" data-anchor-id="native">Native Multi-class Algorithms</h3>
<p>These are algorithms that can directly handle multiple classes in their formulation:</p>
<p><strong>a. <a href="../../posts/decisiontree/index.html" style="text-decoration:none" target="_blank">Decision Trees</a></strong> (See more here)</p>
<p style="text-align: justify">
Decision Trees can naturally handle multi-class classification tasks. At each split, the tree decides on a rule that best separates the data into groups. The terminal nodes (leaves) represent the class predictions.
</p>
<ul>
<li><strong>Advantages</strong>: Easy to interpret, no need for extensive pre-processing, and handles both categorical and numerical features.</li>
<li><strong>Disadvantages</strong>: Prone to overfitting and can produce unstable models if not carefully tuned.</li>
</ul>
<div id="59a8f903" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeClassifier</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> classification_report </span>
<span id="cb3-4"></span>
<span id="cb3-5">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(</span>
<span id="cb3-6">    iris.data, </span>
<span id="cb3-7">    iris.target, </span>
<span id="cb3-8">    test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>,</span>
<span id="cb3-9">    random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span></span>
<span id="cb3-10">    )</span>
<span id="cb3-11">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DecisionTreeClassifier()</span>
<span id="cb3-12">clf.fit(X_train, y_train)</span>
<span id="cb3-13">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       0.83      1.00      0.91        10
   virginica       1.00      0.88      0.94        17

    accuracy                           0.96        45
   macro avg       0.94      0.96      0.95        45
weighted avg       0.96      0.96      0.96        45
</code></pre>
</div>
</div>
<p><strong>b. <a href="../../posts/randomforest/index.html" style="text-decoration:none" target="_blank">Random Forests</a></strong> (See more here)</p>
<p style="text-align: justify">
Random Forests are ensembles of decision trees and can also naturally handle multi-class classification. They aggregate the predictions from multiple trees to make a final classification decision.
</p>
<ul>
<li><strong>Advantages</strong>: Higher accuracy and reduced overfitting compared to single decision trees.</li>
<li><strong>Disadvantages</strong>: Less interpretable than individual trees, and training can be computationally intensive.</li>
</ul>
<div id="a58b3dc5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb5-2"></span>
<span id="cb5-3">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier()</span>
<span id="cb5-4">clf.fit(X_train, y_train)</span>
<span id="cb5-5">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       0.77      1.00      0.87        10
   virginica       1.00      0.82      0.90        17

    accuracy                           0.93        45
   macro avg       0.92      0.94      0.92        45
weighted avg       0.95      0.93      0.93        45
</code></pre>
</div>
</div>
<p><strong>c.&nbsp;<a href="../../posts/naivebayes/index.html" style="text-decoration:none" target="_blank">Naive Bayes</a></strong> (See more here)</p>
<p style="text-align: justify">
Naive Bayes is a probabilistic classifier based on Bayes’ theorem, assuming that the features are independent. The algorithm calculates the probability of each class and predicts the one with the highest probability.
</p>
<ul>
<li><strong>Advantages</strong>: Fast, simple, and works well for text classification.</li>
<li><strong>Disadvantages</strong>: Assumes feature independence, which might not hold in many real-world datasets.</li>
</ul>
<div id="5ee7e36d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.naive_bayes <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MultinomialNB</span>
<span id="cb7-2"></span>
<span id="cb7-3">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultinomialNB()</span>
<span id="cb7-4">clf.fit(X_train, y_train)</span>
<span id="cb7-5">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       0.37      1.00      0.54        10
   virginica       0.00      0.00      0.00        17

    accuracy                           0.62        45
   macro avg       0.46      0.67      0.51        45
weighted avg       0.48      0.62      0.52        45
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/python_environments/pytorch-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:

Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/python_environments/pytorch-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:

Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/python_environments/pytorch-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:

Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
</code></pre>
</div>
</div>
<p><strong>d.&nbsp;<a href="../../posts/knn/index.html" style="text-decoration:none" target="_blank">K-Nearest Neighbors (KNN)</a></strong> (See more here)</p>
<p style="text-align: justify">
KNN is a non-parametric algorithm that classifies a data point based on the majority class of its k-nearest neighbors. It can handle multi-class problems by considering the most frequent class among the neighbors.
</p>
<ul>
<li><strong>Advantages</strong>: Simple to implement, no training phase.</li>
<li><strong>Disadvantages</strong>: Slow at prediction time, sensitive to the choice of k and the distance metric.</li>
</ul>
<div id="0984a77d" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KNeighborsClassifier</span>
<span id="cb10-2"></span>
<span id="cb10-3">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KNeighborsClassifier(n_neighbors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb10-4">clf.fit(X_train, y_train)</span>
<span id="cb10-5">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb10-6"></span>
<span id="cb10-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       1.00      0.90      0.95        10
   virginica       0.94      1.00      0.97        17

    accuracy                           0.98        45
   macro avg       0.98      0.97      0.97        45
weighted avg       0.98      0.98      0.98        45
</code></pre>
</div>
</div>
</section>
<section id="binary" class="level3">
<h3 class="anchored" data-anchor-id="binary">Binary to Multi-class Strategies</h3>
<p>Some algorithms are inherently binary, but they can be adapted to handle multiple classes using strategies like:</p>
<p><strong>a. One-vs-Rest (OvR)</strong></p>
<p style="text-align: justify">
This technique involves training one classifier per class. Each classifier is trained to distinguish one class from the rest (i.e., treat it as a binary classification problem). During prediction, the classifier that outputs the highest confidence score assigns the label.
</p>
<ul>
<li><strong>Advantages</strong>: Simple and works well with many binary classifiers like logistic regression and support vector machines.</li>
<li><strong>Disadvantages</strong>: Can become inefficient when there are many classes, since it requires training one model per class.</li>
</ul>
<p>Example with <a href="../../posts/logreg/index.html" style="text-decoration:none" target="_blank">Logistic Regression</a></p>
<div id="2bc0af88" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb12-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.multiclass <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OneVsRestClassifier</span>
<span id="cb12-3"></span>
<span id="cb12-4">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OneVsRestClassifier(LogisticRegression())</span>
<span id="cb12-5">clf.fit(X_train, y_train)</span>
<span id="cb12-6">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       0.83      1.00      0.91        10
   virginica       1.00      0.88      0.94        17

    accuracy                           0.96        45
   macro avg       0.94      0.96      0.95        45
weighted avg       0.96      0.96      0.96        45
</code></pre>
</div>
</div>
<p><strong>b. One-vs-One (OvO)</strong></p>
<p style="text-align: justify">
This strategy involves training a binary classifier for every possible pair of classes. For a dataset with <img src="https://latex.codecogs.com/png.latex?n"> classes, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bn(n-1)%7D%7B2%7D"> classifiers are trained. The class with the most “votes” from the classifiers is the predicted label.
</p>
<ul>
<li><strong>Advantages</strong>: Works well when there are fewer classes.</li>
<li><strong>Disadvantages</strong>: Computationally expensive for large class numbers due to the many classifiers needed.</li>
</ul>
<p>Example with support vector classifier</p>
<div id="547d9ebe" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.multiclass <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OneVsOneClassifier</span>
<span id="cb14-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.svm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SVC</span>
<span id="cb14-3"></span>
<span id="cb14-4">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OneVsOneClassifier(SVC())</span>
<span id="cb14-5">clf.fit(X_train, y_train)</span>
<span id="cb14-6">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb14-7"></span>
<span id="cb14-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred, target_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

      setosa       1.00      1.00      1.00        18
  versicolor       0.71      1.00      0.83        10
   virginica       1.00      0.76      0.87        17

    accuracy                           0.91        45
   macro avg       0.90      0.92      0.90        45
weighted avg       0.94      0.91      0.91        45
</code></pre>
</div>
</div>
<section id="neural-networks-for-multi-class-classification" class="level4">
<h4 class="anchored" data-anchor-id="neural-networks-for-multi-class-classification">3. Neural Networks for Multi-class Classification</h4>
<p><strong>a. Softmax Regression</strong></p>
<p style="text-align: justify">
In neural networks, multi-class classification is typically handled using the <strong>softmax</strong> function in the output layer. Softmax converts raw output scores (logits) into probabilities for each class, ensuring they sum to 1. The class with the highest probability is chosen as the predicted class.
</p>
<ul>
<li><strong>Advantages</strong>: Can model complex non-linear relationships and works well with large datasets.</li>
<li><strong>Disadvantages</strong>: Requires more data and computational resources compared to simpler models.</li>
</ul>
<div id="265f916a" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensorflow <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tf </span>
<span id="cb16-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tensorflow.keras.models <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Sequential </span>
<span id="cb16-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tensorflow.keras.layers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dense, Input</span>
<span id="cb16-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tensorflow.keras.optimizers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SGD</span>
<span id="cb16-5"></span>
<span id="cb16-6">input_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Input(shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (X_train.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],))</span>
<span id="cb16-7"></span>
<span id="cb16-8">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Sequential([</span>
<span id="cb16-9">    input_layer,</span>
<span id="cb16-10">    Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, activation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'relu'</span>),</span>
<span id="cb16-11">    </span>
<span id="cb16-12">    Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, activation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'relu'</span>),</span>
<span id="cb16-13">    </span>
<span id="cb16-14">    Dense(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, activation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'softmax'</span>)</span>
<span id="cb16-15">])</span>
<span id="cb16-16"></span>
<span id="cb16-17">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SGD(learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span>
<span id="cb16-18">model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(</span>
<span id="cb16-19">    optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimizer, </span>
<span id="cb16-20">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb16-21">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'accuracy'</span>]</span>
<span id="cb16-22">    )</span>
<span id="cb16-23">model.fit(X_train, y_train, epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, verbose <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb16-24">test_loss, accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.evaluate(X_test, y_test)</span>
<span id="cb16-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Test Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)  </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.9688 - loss: 0.66252/2 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.9748 - loss: 0.6583
Test Accuracy: 0.9777777791023254</code></pre>
</div>
</div>
<p>Training and Validation loss</p>
<div id="ed72f7ed" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">X_train, X_val, y_train, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(</span>
<span id="cb18-2">    X_train, y_train, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>,</span>
<span id="cb18-3">    stratify<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train</span>
<span id="cb18-4">)</span>
<span id="cb18-5"></span>
<span id="cb18-6">history <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(</span>
<span id="cb18-7">    X_train, y_train, epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>, </span>
<span id="cb18-8">    batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, verbose <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb18-9">    validation_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (X_val, y_val)</span>
<span id="cb18-10">    )</span>
<span id="cb18-11"></span>
<span id="cb18-12">train_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> history.history[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>]</span>
<span id="cb18-13">val_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> history.history[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'val_loss'</span>]</span>
<span id="cb18-14"></span>
<span id="cb18-15">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train_loss)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-16">plt.plot(epochs, train_loss, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'b-'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Training Loss"</span>)</span>
<span id="cb18-17">plt.plot(epochs, val_loss, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r-'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Validation loss"</span>)</span>
<span id="cb18-18">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training and Validation loss'</span>)</span>
<span id="cb18-19">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Epochs'</span>)</span>
<span id="cb18-20">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Loss'</span>)</span>
<span id="cb18-21">plt.legend()</span>
<span id="cb18-22">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/multiclass/index_files/figure-html/cell-10-output-1.png" width="601" height="455" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><strong>b. Convolutional Neural Networks (CNNs)</strong></p>
<p>For image classification tasks, <strong>CNNs</strong> are widely used. CNNs automatically learn spatial hierarchies of features, making them highly effective for tasks like object recognition in images.</p>
<ul>
<li><strong>Advantages</strong>: Superior performance on image data, able to capture spatial dependencies.</li>
<li><strong>Disadvantages</strong>: Require large amounts of labeled data and significant computational power for training.</li>
</ul>
</section>
</section>
</section>
<section id="perf" class="level2">
<h2 class="anchored" data-anchor-id="perf">Performance Evaluation in Multi-class Classification</h2>
<p>Evaluating multi-class classification models requires more nuanced metrics than binary classification. Some common evaluation metrics include:</p>
<ul>
<li><strong>Accuracy</strong>: The percentage of correctly classified instances.</li>
<li><strong>Confusion Matrix</strong>: A table showing the actual versus predicted classes for each class.</li>
<li><strong>Precision, Recall, and F1-score</strong>: These can be extended to multiple classes by calculating them per class (micro, macro, or weighted averages).</li>
<li><strong>Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)</strong>: These are less commonly used for multi-class problems, but can still be adapted using OvR schemes.</li>
</ul>
<div id="e933c175" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> confusion_matrix</span>
<span id="cb19-2"></span>
<span id="cb19-3">cm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb19-4">sns.heatmap(</span>
<span id="cb19-5">    cm, annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'d'</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Blues'</span>,</span>
<span id="cb19-6">    xticklabels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names,</span>
<span id="cb19-7">    yticklabels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names</span>
<span id="cb19-8">)</span>
<span id="cb19-9">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb19-10">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb19-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/multiclass/index_files/figure-html/cell-11-output-1.png" width="556" height="441" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p style="text-align: justify">
Multi-class classification is a critical aspect of many real-world applications, from medical diagnosis to image recognition and beyond. By understanding the strengths and limitations of different algorithms and strategies, we can choose the best approach for the task at hand. Whether using native multi-class models like decision trees or adapting binary models with OvR or OvO strategies, it’s essential to carefully consider the nature of the data, the number of classes, and computational constraints when building the models.
</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>Scikit-learn Documentation</strong>:<br>
The Python code snippets for decision trees, random forests, KNN, logistic regression, and support vector machines (SVM) are based on the Scikit-learn library.
<ul>
<li>Scikit-learn: <a href="https://scikit-learn.org/stable/supervised_learning.html" style="text-decoration:none" target="_blank">https://scikit-learn.org/stable/supervised_learning.html</a></li>
</ul></li>
<li><strong>Iris Dataset</strong>:<br>
The Iris dataset is a well-known dataset for classification tasks and is included in the UCI Machine Learning Repository:
<ul>
<li>UCI Machine Learning Repository: <a href="https://archive.ics.uci.edu/ml/datasets/iris" style="text-decoration:none" target="_blank">https://archive.ics.uci.edu/ml/datasets/iris</a></li>
</ul></li>
<li><strong>Confusion Matrix &amp; Evaluation Metrics</strong>:<br>
For metrics such as accuracy, precision, recall, F1-score, and confusion matrices, the Scikit-learn library offers comprehensive functions to evaluate multi-class classification models:
<ul>
<li>Scikit-learn metrics documentation: <a href="https://scikit-learn.org/stable/modules/model_evaluation.html" style="text-decoration:none" target="_blank">https://scikit-learn.org/stable/modules/model_evaluation.html</a></li>
</ul></li>
<li><strong>Softmax and Neural Networks</strong>:<br>
The Python code for neural networks using TensorFlow/Keras employs the <code>softmax</code> function for multi-class classification.
<ul>
<li>TensorFlow/Keras: <a href="https://www.tensorflow.org/" style="text-decoration:none" target="_blank">https://www.tensorflow.org/</a></li>
</ul></li>
<li><strong>Introduction to Multi-class Classification</strong>:<br>
General information about multi-class classification can be found in machine learning books and resources, such as “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” by Aurélien Géron:
<ul>
<li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" style="text-decoration:none" target="_blank">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow on O’Reilly</a></li>
</ul></li>
</ol>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiclass" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/multiclass" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Classification: {Techniques} to Handle Multi-Class
    Classification Problems},
  date = {2024-10-17},
  url = {https://mrislambd.github.io/posts/multiclass/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Classification: Techniques to Handle
Multi-Class Classification Problems.”</span> October 17, 2024. <a href="https://mrislambd.github.io/posts/multiclass/">https://mrislambd.github.io/posts/multiclass/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/multiclass/</guid>
  <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/multiclass/multi.png" medium="image" type="image/png" height="124" width="144"/>
</item>
<item>
  <title>Model Evaluation and Fine Tuning: Classification Metrices</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/classificationmetrics/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align:justify">
In any classification problem, the goal is to build a model that accurately predicts labels or classes from input data. Once the model is built, it is important to evaluate its performance using a variety of metrics. Some of the most commonly used metrics are the confusion matrix, accuracy, precision, recall, F1 score, and ROC-AUC curve. This post will explain each metric and show how to compute them using real data in Python.
</p>
<section id="confusion-matrix" class="level3">
<h3 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix</h3>
<p>A confusion matrix is a tabular summary of the performance of a classification algorithm. It shows the number of correct and incorrect predictions broken down by each class.</p>
<p>For a binary classification, the confusion matrix looks like this:</p>
<div id="ca716352" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_confusion_matrix():</span>
<span id="cb1-6">    </span>
<span id="cb1-7">    matrix_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>]])</span>
<span id="cb1-8"></span>
<span id="cb1-9">    </span>
<span id="cb1-10">    extended_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))  </span>
<span id="cb1-11">    extended_matrix[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, :<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matrix_data  </span>
<span id="cb1-12"></span>
<span id="cb1-13">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros_like(extended_matrix, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>)</span>
<span id="cb1-14">    mask[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb1-15">    mask[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb1-16"></span>
<span id="cb1-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a plot</span></span>
<span id="cb1-18">    fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.2</span>))</span>
<span id="cb1-19"></span>
<span id="cb1-20">    fig.patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb1-21">    ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-22"></span>
<span id="cb1-23">    sns.heatmap(extended_matrix, mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mask,annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RdYlGn"</span>, cbar<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, linewidths<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linecolor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb1-24"></span>
<span id="cb1-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add the original confusion matrix values (True Positive, False Negative, etc.)</span></span>
<span id="cb1-26">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Positive (TP)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb1-27">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Negative (FN)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb1-28">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.60</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(Type II Error)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb1-29">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.25</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive (FP)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb1-30">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.40</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(Type I Error)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb1-31">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.45</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.4</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Negative (TN)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"red"</span>)</span>
<span id="cb1-32">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Positive'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-33">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.45</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Negative'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-34">    ax.text(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted Class'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-35"></span>
<span id="cb1-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add Precision and NPV in the bottom row of the confusion matrix</span></span>
<span id="cb1-37">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.17</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'Precision= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{TP}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TP + FP}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-38">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'NPV= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{TN}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TN + FN}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-39"></span>
<span id="cb1-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add Sensitivity and Specificity in the right column of the confusion matrix</span></span>
<span id="cb1-41">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.95</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'TPR=Sensitivity= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{TP}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TP + FN}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-42">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.89</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'or Recall'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-43">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.8</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Neg. Rate (FNR)'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-44">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.75</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'Type II Error rate= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{FN}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TP + FN}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-45">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.6</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'TNR=Specificity= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{TN}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TN + FP}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-46">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.48</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive Rate'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-47">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.43</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'FPR= $\frac</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{FP}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">{TN + FP}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-48">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.37</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Type I Error Rate'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-49"></span>
<span id="cb1-50">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add Accuracy in the bottom-right corner of the extended grid</span></span>
<span id="cb1-51">    ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.83</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'Accuracy= $\frac{TP + TN}{TP+TN+FP+FN}$'</span>, ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, va<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, transform<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax.transAxes, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-52"></span>
<span id="cb1-53">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Titles and labels</span></span>
<span id="cb1-54">    ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual Class'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">14</span>)</span>
<span id="cb1-55">    </span>
<span id="cb1-56"></span>
<span id="cb1-57">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set tick labels for actual and predicted</span></span>
<span id="cb1-58">    ax.xaxis.set_ticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>], fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-59">    ax.yaxis.set_ticklabels([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Positive'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Negative'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>], fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-60"></span>
<span id="cb1-61">    plt.tight_layout()</span>
<span id="cb1-62">    plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'conf.png'</span>)</span>
<span id="cb1-63">    plt.show()</span>
<span id="cb1-64"></span>
<span id="cb1-65"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate the confusion matrix plot</span></span>
<span id="cb1-66">plot_confusion_matrix()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-2-output-1.png" width="757" height="491" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>True Positive (TP)</strong>: The model correctly predicted the positive class.</li>
<li><strong>False Positive (FP)</strong>: The model incorrectly predicted the positive class (also known as a Type I error).</li>
<li><strong>True Negative (TN)</strong>: The model correctly predicted the negative class.</li>
<li><strong>False Negative (FN)</strong>: The model incorrectly predicted the negative class (also known as a Type II error).</li>
</ul>
</section>
<section id="accuracy" class="level3">
<h3 class="anchored" data-anchor-id="accuracy">Accuracy</h3>
<p>Accuracy is the ratio of correctly predicted observations to the total observations.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BAccuracy%7D%20=%20%5Cfrac%7BTP%20+%20TN%7D%7BTP%20+%20TN%20+%20FP%20+%20FN%7D%0A"></p>
<p>It is one of the most intuitive metrics, but it can be misleading if the classes are imbalanced.</p>
</section>
<section id="precision-positive-predictive-value" class="level3">
<h3 class="anchored" data-anchor-id="precision-positive-predictive-value">Precision (Positive Predictive Value)</h3>
<p>Precision measures the proportion of positive predictions that are actually correct.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BPrecision%7D%20=%20%5Cfrac%7BTP%7D%7BTP%20+%20FP%7D%0A"></p>
<p>It is useful when the cost of a false positive is high, such as in fraud detection.</p>
</section>
<section id="recall-sensitivity-or-true-positive-rate" class="level3">
<h3 class="anchored" data-anchor-id="recall-sensitivity-or-true-positive-rate">Recall (Sensitivity or True Positive Rate)</h3>
<p>Recall measures the proportion of actual positives that are correctly predicted.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BRecall%7D%20=%20%5Cfrac%7BTP%7D%7BTP%20+%20FN%7D%0A"></p>
<p>It is important in cases where missing a positive is more costly, like in medical diagnoses.</p>
</section>
<section id="f1-score" class="level3">
<h3 class="anchored" data-anchor-id="f1-score">F1 Score</h3>
<p>The F1 score is the harmonic mean of precision and recall, giving a balanced measure when both metrics are important.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BF1%20Score%7D%20=%202%20%5Ctimes%20%5Cfrac%7B%5Ctext%7BPrecision%7D%20%5Ctimes%20%5Ctext%7BRecall%7D%7D%7B%5Ctext%7BPrecision%7D%20+%20%5Ctext%7BRecall%7D%7D%0A"></p>
</section>
<section id="roc-auc-curve-receiver-operating-characteristic-area-under-the-curve" class="level3">
<h3 class="anchored" data-anchor-id="roc-auc-curve-receiver-operating-characteristic-area-under-the-curve">ROC-AUC Curve (Receiver Operating Characteristic – Area Under the Curve)</h3>
<p style="text-align: justify">
The ROC-AUC curve helps visualize the performance of a classification model by plotting the true positive rate (recall) against the false positive rate (1 - specificity) at various threshold settings. The AUC (Area Under the Curve) gives a single number that summarizes the performance. A model with an AUC of 1 is perfect, while a model with an AUC of 0.5 is as good as random guessing.
</p>
</section>
<section id="summary-of-the-metrices" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-the-metrices">Summary of the Metrices</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 47%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th>Formula</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Precision:</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BTP%7D%7BTP+FP%7D"></td>
</tr>
<tr class="even">
<td>Sensitivity or Recall or True Positive Rate (TPR):</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BTP%7D%7BTP+FN%7D"></td>
</tr>
<tr class="odd">
<td>Type II Error Rate or False Negative Rate (FNR):</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BFN%7D%7BFN+TP%7D"></td>
</tr>
<tr class="even">
<td>Sepecificity or Selectivity or True Negative Rate (TNR):</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BTN%7D%7BTN+FP%7D"></td>
</tr>
<tr class="odd">
<td>Type I Error Rate or False Positive Rate (FPR):</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BFP%7D%7BFP+TN%7D"></td>
</tr>
<tr class="even">
<td>Total Error Rate:</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BFP+FN%7D%7BTN+TP+FN+FP%7D"></td>
</tr>
<tr class="odd">
<td>Accuracy:</td>
<td><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7BTP+TN%7D%7BTN+TP+FN+FP%7D"></td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="example-in-python" class="level2">
<h2 class="anchored" data-anchor-id="example-in-python">Example in Python</h2>
<p>Let’s use a real dataset and compute these metrics using Python. In python the actual confusion matrix looks like this<br>
<img src="https://mrislambd.github.io/posts/classificationmetrics/confmat1.png" class="img-fluid" alt="Confusion matrix"></p>
<p>We’ll use the <code>breast cancer</code> dataset from <code>sklearn</code>, which is a binary classification problem where the task is to predict whether a tumor is malignant or benign.</p>
<div id="212eaf23" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_breast_cancer</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load dataset</span></span>
<span id="cb2-8">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_breast_cancer()</span>
<span id="cb2-9">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.data</span>
<span id="cb2-10">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.target</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split data into training and test sets</span></span>
<span id="cb2-13">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-14"></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train a RandomForest Classifier</span></span>
<span id="cb2-16">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-17">clf.fit(X_train, y_train)</span>
<span id="cb2-18"></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make predictions</span></span>
<span id="cb2-20">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb2-21">y_pred_proba <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-22"></span>
<span id="cb2-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the confusion matrix</span></span>
<span id="cb2-24">cm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb2-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot confusion matrix</span></span>
<span id="cb2-26">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb2-27">sns.heatmap(cm, annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'d'</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Blues'</span>, xticklabels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted Benign'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted Malignant'</span>], yticklabels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual Benign'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual Malignant'</span>])</span>
<span id="cb2-28">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted'</span>)</span>
<span id="cb2-29">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb2-30">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Confusion Matrix'</span>)</span>
<span id="cb2-31">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb2-32">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb2-33">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-3-output-1.png" width="619" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Next, Compute Accuracy, Precision, Recall, F1 Score, ROC-AUC</p>
<div id="f757110a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">tn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cm[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb3-2">fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cm[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb3-3">fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cm[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb3-4">tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cm[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb3-5">accuracy1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(accuracy_score(y_test, y_pred),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-6">accuracy2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(((tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tn)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>fp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>fn)),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">precision1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(precision_score(y_test, y_pred),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-9">precision2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(((tp)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>fp)),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-10"></span>
<span id="cb3-11">recall1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(recall_score(y_test, y_pred),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-12">recall2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(((tp)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>fn)),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-13"></span>
<span id="cb3-14">f1_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(f1_score(y_test, y_pred),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>) </span>
<span id="cb3-15">f1_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>precision2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>recall2)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(precision2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>recall2),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-16"></span>
<span id="cb3-17">roc_auc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb3-18"></span>
<span id="cb3-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Accuracy Using Library = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, and Accuracy Using Formula = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(accuracy1,accuracy2))</span>
<span id="cb3-20"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision Using Library = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, and Precision Using Formula = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(precision1,precision2))</span>
<span id="cb3-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Recall Using Library = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, and Recall Using Formula = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(recall1,recall2))</span>
<span id="cb3-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'F1 Score Using Library = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, and F1 Score Using Formula = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(f1_1,f1_2))</span>
<span id="cb3-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ROC-AUC score=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>roc_auc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy Using Library = 0.9708, and Accuracy Using Formula = 0.9708
Precision Using Library = 0.964, and Precision Using Formula = 0.964
Recall Using Library = 0.9907, and Recall Using Formula = 0.9907
F1 Score Using Library = 0.9772, and F1 Score Using Formula = 0.9772
ROC-AUC score=0.9968</code></pre>
</div>
</div>
<p>Plot ROC curve. ROC curve is found from plotting <em>True Positive Rate (TPRs)</em> against <em>False Positive Rate (FPRs)</em> for different cutoffs of probability values. To plot the ROC curve using the built-in function from <code>sklearn</code> we do the following:</p>
<div id="a2ad052f" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">fpr, tpr, thresholds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_curve(y_test, y_pred_proba)</span>
<span id="cb5-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb5-3">plt.plot(fpr, tpr, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ROC Curve (AUC = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>roc_auc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>)</span>
<span id="cb5-4">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>)</span>
<span id="cb5-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive Rate'</span>)</span>
<span id="cb5-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Positive Rate'</span>)</span>
<span id="cb5-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ROC Curve'</span>)</span>
<span id="cb5-8">plt.legend()</span>
<span id="cb5-9">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-10">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-5-output-1.png" width="663" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>To build our own</p>
<div id="5b9a0417" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">cutoff_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.99</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span>
<span id="cb6-2">true_pos_rates <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-3">false_pos_rates <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> cutoff <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> cutoff_values:</span>
<span id="cb6-6">    prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(clf.predict_proba(X_test)[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> cutoff)</span>
<span id="cb6-7">    conf_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> confusion_matrix(y_test, prediction)</span>
<span id="cb6-8">    tn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conf_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-9">    fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conf_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb6-10">    fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conf_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-11">    tp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> conf_matrix[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb6-12"></span>
<span id="cb6-13">    true_pos_rates.append(tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(tp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>fn))</span>
<span id="cb6-14">    false_pos_rates.append(fp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(fp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>tn))</span>
<span id="cb6-15"></span>
<span id="cb6-16">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb6-17">plt.plot(false_pos_rates, true_pos_rates, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ROC Curve (AUC = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>roc_auc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>)</span>
<span id="cb6-18">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>)</span>
<span id="cb6-19">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'False Positive Rate'</span>)</span>
<span id="cb6-20">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Positive Rate'</span>)</span>
<span id="cb6-21">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ROC Curve'</span>)</span>
<span id="cb6-22">plt.legend()</span>
<span id="cb6-23">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb6-24">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb6-25">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-6-output-1.png" width="663" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Next, precision-recall score</p>
<div id="e4a9daf4" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">cutoff_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.99</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>)</span>
<span id="cb7-2">precisions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-3">recalls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> cutoff <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> cutoff_values:</span>
<span id="cb7-6">    prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(clf.predict_proba(X_test)[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> cutoff)</span>
<span id="cb7-7"></span>
<span id="cb7-8">    precisions.append(precision_score(y_test, prediction))</span>
<span id="cb7-9">    recalls.append(recall_score(y_test, prediction))</span>
<span id="cb7-10"></span>
<span id="cb7-11">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb7-12">plt.plot(recalls, precisions, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>)</span>
<span id="cb7-13">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, linestyle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--'</span>)</span>
<span id="cb7-14">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Recalls'</span>)</span>
<span id="cb7-15">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precisions'</span>)</span>
<span id="cb7-16">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision-Recall Curve'</span>)</span>
<span id="cb7-17">plt.legend()</span>
<span id="cb7-18">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb7-19">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb7-20">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-7-output-1.png" width="663" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<section id="explanation-of-results" class="level3">
<h3 class="anchored" data-anchor-id="explanation-of-results">Explanation of Results</h3>
<ol type="1">
<li><p><strong>Confusion Matrix</strong>: The heatmap shows the number of true positives, false positives, true negatives, and false negatives, which gives a detailed insight into the model’s performance.</p></li>
<li><p><strong>Accuracy</strong>: This value tells us the overall correctness of the model. It may not always be reliable if the data is imbalanced.</p></li>
<li><p><strong>Precision</strong>: A higher precision indicates fewer false positives. In this dataset, it tells us how well the model identifies malignant tumors correctly.</p></li>
<li><p><strong>Recall</strong>: A higher recall indicates fewer false negatives. This is particularly important in medical settings where missing a positive case (malignant tumor) can be dangerous.</p></li>
<li><p><strong>F1 Score</strong>: The F1 score balances precision and recall, especially when the class distribution is uneven.</p></li>
<li><p><strong>ROC-AUC Curve</strong>: The ROC curve gives a visualization of the trade-off between sensitivity and specificity. The AUC gives a single number summarizing the overall ability of the model to distinguish between classes.</p></li>
</ol>
</section>
</section>
<section id="when-to-use-each-metric" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-each-metric">When to Use Each Metric?</h2>
<p>It’s important to explain when to prioritize specific metrics based on the problem context:</p>
<ul>
<li><p><strong>Accuracy</strong>: Use when classes are balanced and misclassification costs are similar across classes. Avoid if the dataset is imbalanced.</p></li>
<li><p><strong>Precision</strong>: Useful when false positives are costly. For example, in spam detection, it’s better to have a few missed spams than to mark important emails as spam.</p></li>
<li><p><strong>Recall</strong>: Use when false negatives are costly. In medical diagnoses (e.g., cancer detection), it’s crucial to minimize missed positive cases (false negatives).</p></li>
<li><p><strong>F1 Score</strong>: Best when you need a balance between precision and recall, especially with imbalanced classes.</p></li>
<li><p><strong>ROC-AUC</strong>: Useful for evaluating how well your model separates the two classes across various thresholds. Works well when you want an overall measure of performance.</p></li>
</ul>
</section>
<section id="threshold-tuning-and-decision-making" class="level2">
<h2 class="anchored" data-anchor-id="threshold-tuning-and-decision-making">Threshold Tuning and Decision Making</h2>
<p style="text-align:justify">
For classification problems, the decision threshold is crucial, especially for metrics like ROC-AUC. Often, models use a default threshold of 0.5 to classify whether an instance belongs to the positive class or not, but you can adjust this threshold to prioritize recall over precision or vice versa. You could add a section showing how adjusting the threshold can change model performance.
</p>
<p>Here’s an additional Python example showing how to adjust thresholds:</p>
<div id="2717718c" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjust threshold</span></span>
<span id="cb8-2">threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span></span>
<span id="cb8-3">y_pred_thresholded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (y_pred_proba <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> threshold).astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Recompute metrics</span></span>
<span id="cb8-6">new_precision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_score(y_test, y_pred_thresholded)</span>
<span id="cb8-7">new_recall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall_score(y_test, y_pred_thresholded)</span>
<span id="cb8-8">new_f1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> f1_score(y_test, y_pred_thresholded)</span>
<span id="cb8-9"></span>
<span id="cb8-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'New Precision: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>new_precision<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb8-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'New Recall: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>new_recall<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb8-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'New F1 Score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>new_f1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>New Precision: 0.9554
New Recall: 0.9907
New F1 Score: 0.9727</code></pre>
</div>
</div>
<p>This shows that the default threshold isn’t set in stone, and adjusting it can significantly affect precision, recall, and other metrics.</p>
</section>
<section id="class-imbalance-and-its-effect-on-metrics" class="level2">
<h2 class="anchored" data-anchor-id="class-imbalance-and-its-effect-on-metrics">Class Imbalance and Its Effect on Metrics</h2>
<p style="text-align:justify">
Class imbalance can skew metrics like accuracy. A discussion on how to handle imbalance through methods such as resampling (oversampling/undersampling) or using techniques like SMOTE (Synthetic Minority Over-sampling Technique) could provide further depth.
</p>
<p>For example:</p>
<div id="49c85870" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> imblearn.over_sampling <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SMOTE</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handling class imbalance using SMOTE</span></span>
<span id="cb10-4">smote <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SMOTE(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb10-5">X_resampled, y_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> smote.fit_resample(X_train, y_train)</span>
<span id="cb10-6"></span>
<span id="cb10-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Retrain the model on resampled data</span></span>
<span id="cb10-8">clf_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb10-9">clf_resampled.fit(X_resampled, y_resampled)</span>
<span id="cb10-10"></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions and metrics</span></span>
<span id="cb10-12">y_pred_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf_resampled.predict(X_test)</span>
<span id="cb10-13">accuracy_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, y_pred_resampled)</span>
<span id="cb10-14">precision_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_score(y_test, y_pred_resampled)</span>
<span id="cb10-15">recall_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> recall_score(y_test, y_pred_resampled)</span>
<span id="cb10-16"></span>
<span id="cb10-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Resampled Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_resampled<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb10-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Resampled Precision: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>precision_resampled<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb10-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Resampled Recall: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>recall_resampled<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Resampled Accuracy: 0.9708
Resampled Precision: 0.9813
Resampled Recall: 0.9722</code></pre>
</div>
</div>
<p>This demonstrates the effect of handling class imbalance on model performance.</p>
</section>
<section id="precision-recall-curve" class="level2">
<h2 class="anchored" data-anchor-id="precision-recall-curve">Precision-Recall Curve</h2>
<p style="text-align: justify">
While the ROC curve is useful, the <strong>Precision-Recall (PR) curve</strong> is often more informative when dealing with imbalanced datasets because it focuses on the performance of the positive class. Including a section on this can enhance the evaluation process.
</p>
<div id="79adc39b" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> precision_recall_curve</span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute Precision-Recall curve</span></span>
<span id="cb12-4">precision_vals, recall_vals, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_recall_curve(y_test, y_pred_proba)</span>
<span id="cb12-5"></span>
<span id="cb12-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot Precision-Recall curve</span></span>
<span id="cb12-7">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>))</span>
<span id="cb12-8">plt.plot(recall_vals, precision_vals, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>)</span>
<span id="cb12-9">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Recall'</span>)</span>
<span id="cb12-10">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision'</span>)</span>
<span id="cb12-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Precision-Recall Curve'</span>)</span>
<span id="cb12-12">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb12-13">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb12-14">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://mrislambd.github.io/posts/classificationmetrics/index_files/figure-html/cell-10-output-1.png" width="672" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The PR curve shows how precision and recall change with different classification thresholds.</p>
</section>
<section id="kappa-score-and-matthews-correlation-coefficient-mcc" class="level2">
<h2 class="anchored" data-anchor-id="kappa-score-and-matthews-correlation-coefficient-mcc">Kappa Score and Matthews Correlation Coefficient (MCC)</h2>
<ul>
<li><p><strong>Cohen’s Kappa</strong> measures agreement between observed accuracy and expected accuracy.</p></li>
<li><p><strong>Matthews Correlation Coefficient (MCC)</strong> provides a balanced metric even when classes are imbalanced. It considers true and false positives and negatives, giving a correlation-like score between predictions and actuals.</p></li>
</ul>
<div id="97c088c4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cohen_kappa_score, matthews_corrcoef</span>
<span id="cb13-2"></span>
<span id="cb13-3">kappa <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cohen_kappa_score(y_test, y_pred)</span>
<span id="cb13-4">mcc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matthews_corrcoef(y_test, y_pred)</span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Cohen</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\'</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">s Kappa: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>kappa<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb13-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'MCC: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mcc<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cohen's Kappa: 0.9365
MCC: 0.9372</code></pre>
</div>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://scikit-learn.org/stable/user_guide.html" target="_blank" style="text-decoration:none">Scikit-learn Documentation</a></li>
<li><a href="https://sebastianraschka.com/faq/docs/roc-vs-pr.html" target="_blank" style="text-decoration:none">Precision-Recall vs ROC Curves article by <em>Sebastian Raschka</em></a><br>
</li>
<li><a href="https://towardsdatascience.com/f1-score-what-is-it-and-how-to-use-it-444b04d9aad8" target="_blank" style="text-decoration:none">F1 Score Explained <em>towardsdatascience.com</em> blog post</a></li>
</ul>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/classificationmetrics/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/classificationmetrics/" data-width="750" data-numposts="5">

</div>
<hr>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Model {Evaluation} and {Fine} {Tuning:} {Classification}
    {Metrices}},
  date = {2024-10-17},
  url = {https://mrislambd.github.io/posts/classificationmetrics/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Model Evaluation and Fine Tuning:
Classification Metrices.”</span> October 17, 2024. <a href="https://mrislambd.github.io/posts/classificationmetrics/">https://mrislambd.github.io/posts/classificationmetrics/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/classificationmetrics/</guid>
  <pubDate>Thu, 17 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/classificationmetrics/conf.png" medium="image" type="image/png" height="94" width="144"/>
</item>
<item>
  <title>PyTorch Basics</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/pytorch/</link>
  <description><![CDATA[ 




<section id="introduction-to-tensors" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-tensors">Introduction to Tensors</h2>
<div id="e14b5afa" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.__version__)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.5.1</code></pre>
</div>
</div>
<section id="creating-tensors" class="level3">
<h3 class="anchored" data-anchor-id="creating-tensors">Creating Tensors</h3>
<ul>
<li><p>Scaler</p>
<div id="f7da89fa" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb3-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(scaler)</span>
<span id="cb3-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(scaler.ndim)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(7)
0</code></pre>
</div>
</div></li>
<li><p>Vector</p>
<div id="be8d4532" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">vec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>])</span>
<span id="cb5-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(vec.ndim)</span>
<span id="cb5-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(vec.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1
torch.Size([3])</code></pre>
</div>
</div></li>
<li><p>Matrix</p>
<div id="399b1330" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">MAT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>],</span>
<span id="cb7-2">                    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>]])</span>
<span id="cb7-3">MAT</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>tensor([[2, 3, 4],
        [3, 2, 6]])</code></pre>
</div>
</div></li>
<li><p>Tensor</p>
<div id="4b112f12" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">TEN <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor([[[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb9-2">                     [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]]])</span>
<span id="cb9-3">TEN.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([1, 2, 3])</code></pre>
</div>
</div></li>
</ul>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1730179317257" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1733213800936" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1728684641298" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<!-- img(9CEB782EFEE6)[progressive=false, height=150px]:listing:posts/naivebayes/index.html -->
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a> ]]></description>
  <category>Programming</category>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Python</category>
  <category>PyTorch</category>
  <guid>https://mrislambd.github.io/posts/pytorch/</guid>
  <pubDate>Wed, 16 Oct 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Classification using Naive Bayes algorithm</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/naivebayes/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Naive Bayes is a family of simple yet powerful probabilistic classifiers based on Bayes’ Theorem, with the assumption of independence among predictors. It is widely used for tasks like spam detection, text classification, and sentiment analysis due to its efficiency and simplicity. Despite being called “naive” for its strong assumption of feature independence, it often performs remarkably well in real-world scenarios.
</p>
</section>
<section id="what-is-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="what-is-naive-bayes">What is Naive Bayes?</h2>
<p style="text-align: justify">
Naive Bayes is a probabilistic classifier that leverages Bayes’ Theorem to predict the class of a given data point. It belongs to the family of generative models and works by estimating the posterior probability of a class given a set of features. The term “Naive” refers to the assumption that features are conditionally independent given the class label, which simplifies computation.
</p>
<section id="bayes-theorem-the-foundation" class="level3">
<h3 class="anchored" data-anchor-id="bayes-theorem-the-foundation">Bayes’ Theorem: The Foundation</h3>
<p>Bayes’ Theorem provides a way to update our beliefs about the probability of an event, based on new evidence. The formula for Bayes’ Theorem is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7CX)%20=%20%5Cfrac%7BP(X%7Cy)%20%5Ccdot%20P(y)%7D%7BP(X)%7D%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?P(y%7CX)">: Posterior probability of class <img src="https://latex.codecogs.com/png.latex?y"> given feature set <img src="https://latex.codecogs.com/png.latex?X"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(X%7Cy)">: Likelihood of feature set <img src="https://latex.codecogs.com/png.latex?X"> given class <img src="https://latex.codecogs.com/png.latex?y"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(y)">: Prior probability of class <img src="https://latex.codecogs.com/png.latex?y"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(X)">: Evidence or probability of feature set <img src="https://latex.codecogs.com/png.latex?X"></li>
</ul>
<p>In the context of classification:</p>
<ul>
<li>The goal is to predict <img src="https://latex.codecogs.com/png.latex?y"> (the class) given <img src="https://latex.codecogs.com/png.latex?X"> (the features).<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(y)"> is derived from the distribution of classes in the training data.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(X%7Cy)"> is derived from the distribution of features for each class.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?P(X)"> is a normalizing constant to ensure probabilities sum to 1, but it can be ignored for classification purposes because it is the same for all classes.</li>
</ul>
</section>
<section id="assumptions-and-requirements" class="level3">
<h3 class="anchored" data-anchor-id="assumptions-and-requirements">Assumptions and Requirements</h3>
<p>The key assumption in Naive Bayes is the <strong>conditional independence</strong> of features. Specifically, it assumes that the likelihood of each feature is independent of the others, given the class label:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X_1,%20X_2,%20%5Cdots,%20X_n%20%7C%20y)%20=%20P(X_1%20%7C%20y)%20%5Ccdot%20P(X_2%20%7C%20y)%20%5Ccdot%20%5Cdots%20%5Ccdot%20P(X_n%20%7C%20y)%0A"></p>
<p>While this assumption is often violated in real-world data, Naive Bayes can still perform well, especially when certain features dominate the prediction.</p>
<p><strong>Requirements:</strong></p>
<ul>
<li><strong>Numerical Data</strong>: Naive Bayes can handle both numerical and categorical data, though different versions (Gaussian, Multinomial, Bernoulli) of the algorithm handle specific types of data more effectively</li>
<li><strong>Non-Collinear Features</strong>: Highly correlated features can distort predictions since the model assumes independence.<br>
</li>
<li><strong>Sufficient Data</strong>: Naive Bayes relies on probability estimates; thus, insufficient data might lead to unreliable predictions.</li>
</ul>
</section>
</section>
<section id="types-of-naive-bayes-classifiers" class="level2">
<h2 class="anchored" data-anchor-id="types-of-naive-bayes-classifiers">Types of Naive Bayes Classifiers</h2>
<p>There are several variants of Naive Bayes, depending on the nature of the data:</p>
<ol type="1">
<li><strong>Gaussian Naive Bayes</strong>: Assumes features follow a Gaussian distribution (useful for continuous data).<br>
</li>
<li><strong>Multinomial Naive Bayes</strong>: Suitable for discrete data, often used in text classification (e.g., word counts).<br>
</li>
<li><strong>Bernoulli Naive Bayes</strong>: Works well for binary/boolean data, often used in scenarios where the features represent the presence/absence of a characteristic.</li>
</ol>
</section>
<section id="mathematics-behind-the-process" class="level2">
<h2 class="anchored" data-anchor-id="mathematics-behind-the-process">Mathematics behind the process</h2>
<p>To understand the working of Naive Bayes, let’s start with the Bayes’s theorem</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y_k%20%7C%20X)%20=%20%5Cfrac%7BP(X%7Cy_k)%20%5Ccdot%20P(y_k)%7D%7BP(X)%7D%0A"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?y_k"> is one of the possible classes. Due to the independence assumption, the likelihood term <img src="https://latex.codecogs.com/png.latex?P(X%7Cy_k)"> can be factorized as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X%7Cy_k)%20=%20P(x_1%7Cy_k)%20%5Ccdot%20P(x_2%7Cy_k)%20%5Ccdot%20%5Cdots%20%5Ccdot%20P(x_n%7Cy_k)%0A"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20%5Cdots,%20x_n"> are the individual features in the feature set <img src="https://latex.codecogs.com/png.latex?X">. For each class <img src="https://latex.codecogs.com/png.latex?y_k">, compute the posterior probability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y_k%20%7C%20X)%20%5Cpropto%20P(y_k)%20%5Ccdot%20%5Cprod_%7Bi=1%7D%5En%20P(x_i%7Cy_k)%0A"></p>
<p>The denominator <img src="https://latex.codecogs.com/png.latex?P(X)"> is constant for all classes, so we can ignore it during classification. Finally, the class <img src="https://latex.codecogs.com/png.latex?y_k"> with the highest posterior probability is chosen as the predicted class:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Chat%7By%7D%20&amp;=%20%5Carg%5Cmax_%7By_k%7D%20P(y_k)%20%5Ccdot%20%5Cprod_%7Bi=1%7D%5En%20P(x_i%7Cy_k)%5C%5C%0A%5Clog%7B(%5Chat%7By%7D)%7D&amp;=%20%5Clog%7B%20%5Cleft(%5Carg%5Cmax_%7By_k%7D%20P(y_k)%20%5Ccdot%20%5Cprod_%7Bi=1%7D%5En%20P(x_i%7Cy_k)%5Cright)%7D%5C%5C%0A%5Cimplies%20%5Chat%7By%7D%20&amp;%20=%20%5Carg%5Cmax_%7By_k%7D%20%5Cleft(%5Clog%20P(y_k)+%5Csum_%7Bi=1%7D%5E%7Bn%7D%20P(x_i%7Cy_k)%5Cright)%0A%5Cend%7Balign*%7D"></p>
<section id="computing-the-probabilities" class="level3">
<h3 class="anchored" data-anchor-id="computing-the-probabilities">Computing the probabilities</h3>
<section id="prior-probabilities" class="level4">
<h4 class="anchored" data-anchor-id="prior-probabilities">Prior Probabilities</h4>
<p><img src="https://latex.codecogs.com/png.latex?P(y_k)"> is the prior probability, usually frequency of each class <img src="https://latex.codecogs.com/png.latex?k">.<br>
<img src="https://latex.codecogs.com/png.latex?%0A%20%20P(y_k)=%5Cfrac%7B%5Ctext%7Bnumber%20of%20instances%20in%20class%20%7Dy_k%7D%7B%5Ctext%7Btotal%20number%20of%20instances%7D%7D%0A"></p>
</section>
<section id="class-conditional-probabilities" class="level4">
<h4 class="anchored" data-anchor-id="class-conditional-probabilities">Class Conditional Probabilities</h4>
<p><img src="https://latex.codecogs.com/png.latex?P(x_i%7Cy_k)"> is the class conditional probability. For the</p>
<ol type="1">
<li><p><strong><em>Gaussian Naive Bayes:</em></strong> when the features are continuous and assumed that the features follow a <strong><em>Gaussian</em></strong> distribution, the <code>class conditional</code> probability is given as <img src="https://latex.codecogs.com/png.latex?%0AP(x_i%7Cy_k)%20=%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%20%5Csigma%5E2_k%7D%7D%5Cexp%7B%5Cleft(-%5Cfrac%7B(x_i-%5Cmu_i)%5E2%7D%7B2%5Csigma%5E2_k%7D%5Cright)%7D%0A"></p></li>
<li><p><strong><em>Multinomial Naive Bayes:</em></strong> when the featrues (typically word frequencies) follow a multinomial distribution, the <code>class conditional</code> distribution is given as<br>
<img src="https://latex.codecogs.com/png.latex?%0AP(x_i%7Cy_k)=%5Cfrac%7BN_%7Bx_i,y_k%7D+%5Calpha%7D%7BN_%7By_k%7D+%5Calpha%20V%7D%0A"></p>
<p>where,</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?N_%7Bx_i,y_k%7D"> is the count of the feature (e.g.&nbsp;word or term) <img src="https://latex.codecogs.com/png.latex?x_i"> appearing in documents of class <img src="https://latex.codecogs.com/png.latex?y_k"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?N_%7By_k%7D"> is the total count of all features (e.g.&nbsp;words) in all documents belonging to class <img src="https://latex.codecogs.com/png.latex?y_k"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha"> is a smoothing parameter (often called <strong>Laplace smoothing</strong>), used to avoid zero probabilities. If not using smoothing, set <img src="https://latex.codecogs.com/png.latex?%5Calpha=0"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?V"> is the size of the vocabulary (i.e., the number of unique words)</li>
</ul></li>
<li><p><strong><em>Bernoulli Naive Bayes:</em></strong> when features are binary/boolean data, often used in scenarios where the features represent the presence/absence of a characteristic, the <code>class conditional</code> distribution is given as<br>
<img src="https://latex.codecogs.com/png.latex?%0AP(x_i%7Cy_k)=%5Cbegin%7Bcases%7D%5Cfrac%7BN_%7Bx_i,y_k%7D+%5Calpha%7D%7BN_%7By_k%7D+2%5Calpha%20%7D%5Chspace%7B2mm%7D%5Ctext%7B%20if%20%7D%20x_i=1%5C%5C%0A1-%5Cfrac%7BN_%7Bx_i,y_k%7D+%5Calpha%7D%7BN_%7By_k%7D+2%5Calpha%20%7D%5Chspace%7B2mm%7D%5Ctext%7B%20if%20%7D%20x_i=0%5Cend%7Bcases%7D%0A"></p></li>
</ol>
</section>
</section>
</section>
<section id="python-implementation" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation">Python Implementation</h2>
<section id="gaussian-naive-bayes" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-naive-bayes">Gaussian Naive Bayes</h3>
<p>Code credit for the custom classifier goes to <a href="https://github.com/AssemblyAI-Community/Machine-Learning-From-Scratch/blob/main/06%20NaiveBayes/naive_bayes.py" target="_blank" style="text-decoration:none">Assembly AI</a></p>
<div id="6f521d40" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GNaiveBayes:</span>
<span id="cb1-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X,y):</span>
<span id="cb1-5">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_samples: number of observed data n; int;</span></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_features: number of continueous features d; int;</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        _classes: unique classes</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_classes: number of unique classes</span></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb1-11">        n_samples, n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape</span>
<span id="cb1-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.unique(y)</span>
<span id="cb1-13">        n_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes)</span>
<span id="cb1-14"></span>
<span id="cb1-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate mean, variance, and prior for each class  </span></span>
<span id="cb1-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_classes,n_features),dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb1-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_classes,n_features),dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb1-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(n_classes,dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb1-19"></span>
<span id="cb1-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes):</span>
<span id="cb1-21">            X_c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span>c]</span>
<span id="cb1-22">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._mean[idx,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.mean(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-23">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._var[idx,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.var(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-24">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior[idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(n_samples)</span>
<span id="cb1-25">    </span>
<span id="cb1-26">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,X):</span>
<span id="cb1-27">        y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> X]</span>
<span id="cb1-28"></span>
<span id="cb1-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.array(y_pred)</span>
<span id="cb1-30"></span>
<span id="cb1-31">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-32">        posteriors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-33"></span>
<span id="cb1-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate the posterior probability for each class  </span></span>
<span id="cb1-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx,c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes):</span>
<span id="cb1-36">            prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior[idx])</span>
<span id="cb1-37">            post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(np.log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._pdf(idx,x)))</span>
<span id="cb1-38">            posterior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> post <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> prior</span>
<span id="cb1-39">            posteriors.append(posterior)</span>
<span id="cb1-40">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the class with the highest posterior</span></span>
<span id="cb1-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes[np.argmax(posteriors)]</span>
<span id="cb1-42">    </span>
<span id="cb1-43">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _pdf(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, class_idx, x):</span>
<span id="cb1-44">        mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._mean[class_idx]</span>
<span id="cb1-45">        var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._var[class_idx]</span>
<span id="cb1-46">        numerator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>mean)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>var))</span>
<span id="cb1-47">        denominator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.pi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>var)</span>
<span id="cb1-48"></span>
<span id="cb1-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> numerator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>denominator</span></code></pre></div>
</div>
<p>Let’s apply this to the <code>irish</code> data set</p>
<div id="04eac058" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb2-3"></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load Iris dataset</span></span>
<span id="cb2-6">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb2-7">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.data  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Features</span></span>
<span id="cb2-8">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.target  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target variable (Classes)</span></span>
<span id="cb2-9">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(X, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data.feature_names)</span>
<span id="cb2-10">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Categorical.from_codes(y, data.target_names)</span>
<span id="cb2-11">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length (cm)</th>
<th data-quarto-table-cell-role="th">sepal width (cm)</th>
<th data-quarto-table-cell-role="th">petal length (cm)</th>
<th data-quarto-table-cell-role="th">petal width (cm)</th>
<th data-quarto-table-cell-role="th">target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="6cdacb76" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.naive_bayes <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GaussianNB</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score, confusion_matrix, classification_report  </span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split into training and testing sets</span></span>
<span id="cb3-6">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">gnb1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GNaiveBayes()</span>
<span id="cb3-9">gnb1.fit(X_train, y_train)</span>
<span id="cb3-10">pred1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gnb1.predict(X_test)</span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluate the model</span></span>
<span id="cb3-12">acc1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, pred1)</span>
<span id="cb3-13"></span>
<span id="cb3-14">gnb2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GaussianNB()</span>
<span id="cb3-15">gnb2.fit(X_train, y_train)</span>
<span id="cb3-16">pred2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gnb2.predict(X_test)</span>
<span id="cb3-17">acc2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, pred2) </span>
<span id="cb3-18"></span>
<span id="cb3-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Accuracy from custom classifier = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{:.2f}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(acc1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>))</span>
<span id="cb3-20"></span>
<span id="cb3-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Confusion matrix and classification report</span></span>
<span id="cb3-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(confusion_matrix(y_test, pred1))</span>
<span id="cb3-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, pred1))</span>
<span id="cb3-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb3-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Accuracy from sklearn classifier = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{:.2f}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(acc2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>))</span>
<span id="cb3-26"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(confusion_matrix(y_test, pred2))</span>
<span id="cb3-27"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, pred2))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy from custom classifier = 97.78
[[19  0  0]
 [ 0 12  1]
 [ 0  0 13]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        19
           1       1.00      0.92      0.96        13
           2       0.93      1.00      0.96        13

    accuracy                           0.98        45
   macro avg       0.98      0.97      0.97        45
weighted avg       0.98      0.98      0.98        45



Accuracy from sklearn classifier = 97.78
[[19  0  0]
 [ 0 12  1]
 [ 0  0 13]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        19
           1       1.00      0.92      0.96        13
           2       0.93      1.00      0.96        13

    accuracy                           0.98        45
   macro avg       0.98      0.97      0.97        45
weighted avg       0.98      0.98      0.98        45
</code></pre>
</div>
</div>
</section>
<section id="multinomial-naive-bayes" class="level3">
<h3 class="anchored" data-anchor-id="multinomial-naive-bayes">Multinomial Naive Bayes</h3>
<div id="1eb2fdba" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MNaiveBayes:</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb5-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alpha</span>
<span id="cb5-4"></span>
<span id="cb5-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X,y):</span>
<span id="cb5-6">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Fit the Multinomial Naive Bayes model to the training data.  </span></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        X: input data (n_samples, n_features)</span></span>
<span id="cb5-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        y: target labels (n_samples)</span></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb5-11">        n_samples, n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape</span>
<span id="cb5-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.unique(y)</span>
<span id="cb5-13">        n_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes)</span>
<span id="cb5-14"></span>
<span id="cb5-15">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize and count priors </span></span>
<span id="cb5-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_feature_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_classes, n_features),dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb5-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(n_classes, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb5-18">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(n_classes, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.float64)</span>
<span id="cb5-19"></span>
<span id="cb5-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx,c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes):</span>
<span id="cb5-21">            X_c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span>c]</span>
<span id="cb5-22">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_feature_count[idx,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb5-23">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_count[idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb5-24">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior[idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(n_samples)</span>
<span id="cb5-25">        </span>
<span id="cb5-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Total count of all features accross all classes </span></span>
<span id="cb5-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._total_feature_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_feature_count.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-28">    </span>
<span id="cb5-29">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb5-30">        y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> X]</span>
<span id="cb5-31">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.array(y_pred)</span>
<span id="cb5-32">    </span>
<span id="cb5-33">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,x):</span>
<span id="cb5-34">        posteriors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb5-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes):</span>
<span id="cb5-36">            prior <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._prior[idx])</span>
<span id="cb5-37">            likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(np.log(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._likelihood(idx,x)))</span>
<span id="cb5-38">            posterior_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prior<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> likelihood</span>
<span id="cb5-39">            posteriors.append(posterior_prob)</span>
<span id="cb5-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._classes[np.argmax(posteriors)]</span>
<span id="cb5-41">    </span>
<span id="cb5-42">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _likelihood(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, class_idx, x):</span>
<span id="cb5-43">        alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alpha</span>
<span id="cb5-44">        V <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_feature_count[class_idx])</span>
<span id="cb5-45">        class_feature_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._class_feature_count[class_idx]</span>
<span id="cb5-46">        total_class_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._total_feature_count[class_idx]</span>
<span id="cb5-47">        likelihood <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (class_feature_count<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>alpha)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(total_class_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> V)</span>
<span id="cb5-48"></span>
<span id="cb5-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> likelihood<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>x</span>
<span id="cb5-50"></span>
<span id="cb5-51">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb5-52">              [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb5-53">              [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb5-54">              [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb5-55">              [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]])</span>
<span id="cb5-56"></span>
<span id="cb5-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Corresponding labels (2 classes: 0 and 1)</span></span>
<span id="cb5-58">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb5-59"></span>
<span id="cb5-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create and train Multinomial Naive Bayes model</span></span>
<span id="cb5-61">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MNaiveBayes()</span>
<span id="cb5-62">model.fit(X, y)</span>
<span id="cb5-63"></span>
<span id="cb5-64"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict for new sample</span></span>
<span id="cb5-65">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]])</span>
<span id="cb5-66">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test)</span>
<span id="cb5-67"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(predictions)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0 0]</code></pre>
</div>
</div>
</section>
</section>
<section id="pros-and-cons-of-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons-of-naive-bayes">Pros and Cons of Naive Bayes</h2>
<section id="pros" class="level3">
<h3 class="anchored" data-anchor-id="pros">Pros:</h3>
<ul>
<li><strong>Simplicity</strong>: Easy to implement and computationally efficient.<br>
</li>
<li><strong>Fast Training and Prediction</strong>: Naive Bayes is especially fast for both training and inference, even on large datasets.<br>
</li>
<li><strong>Performs Well with Small Data</strong>: Despite its simplicity, Naive Bayes works well even with relatively small datasets.<br>
</li>
<li><strong>Handles Irrelevant Features</strong>: Naive Bayes can often ignore irrelevant features in the data since the independence assumption dilutes their influence.<br>
</li>
<li><strong>Multi-Class Classification</strong>: Naturally suited for multi-class classification problems.</li>
</ul>
</section>
<section id="cons" class="level3">
<h3 class="anchored" data-anchor-id="cons">Cons:</h3>
<ul>
<li><strong>Strong Assumption of Independence</strong>: The assumption that features are independent is rarely true in real-world data, which can limit the model’s effectiveness.<br>
</li>
<li><strong>Poor Estimation of Probabilities</strong>: When dealing with very small datasets or unseen feature combinations, Naive Bayes can yield inaccurate probability estimates.<br>
</li>
<li><strong>Zero-Frequency Problem</strong>: If a feature value was not present in the training data, Naive Bayes will assign zero probability to the entire class, which can be addressed using Laplace smoothing.</li>
</ul>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/naivebayes/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/naivebayes/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Data Science,Machine Learning,Artificial Intelligence,Data Engineering" data-listing-date-sort="1729137600000" data-listing-file-modified-sort="1742009228355" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="27" data-listing-word-count-sort="5383">
<a href="../../posts/lda/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/lda/lda.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification: Linear Discriminant Analysis (LDA)
</h5>
<div class="listing-reading-time card-text text-muted">
27 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 17, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Classification Using {Naive} {Bayes} Algorithm},
  date = {2024-10-10},
  url = {https://mrislambd.github.io/posts/naivebayes/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Classification Using Naive Bayes
Algorithm.”</span> October 10, 2024. <a href="https://mrislambd.github.io/posts/naivebayes/">https://mrislambd.github.io/posts/naivebayes/</a>.
</div></div></section></div> ]]></description>
  <category>Statistics</category>
  <category>Data Science</category>
  <category>Data Engineering</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/naivebayes/</guid>
  <pubDate>Thu, 10 Oct 2024 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Classification: Logistic Regression - A Comprehensive Guide with Mathematical Derivation and Python Code</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/logreg/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Logistic Regression is a popular classification algorithm used for binary and multi-class classification problems. Unlike Linear Regression, which is used for regression problems, Logistic Regression is used to predict categorical outcomes. In binary classification, the output is either 0 or 1, and the relationship between the input features and the outcome is modeled using a logistic function (also called the sigmoid function).
</p>
</section>
<section id="what-is-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="what-is-logistic-regression">What is Logistic Regression?</h2>
<p style="text-align: justify">
Logistic Regression is a type of regression analysis used when the dependent variable is categorical. In binary logistic regression, the output can have only two possible outcomes (e.g., 0 or 1, pass or fail, spam or not spam). <br> Logistic Regression works by modeling the probability of an event occurring based on one or more input features. It estimates the probability that a given input belongs to a particular category (0 or 1) using the <strong>logistic function (sigmoid function)</strong>.
</p>
</section>
<section id="the-sigmoid-function" class="level2">
<h2 class="anchored" data-anchor-id="the-sigmoid-function">The Sigmoid Function</h2>
<p>The sigmoid function maps any real-valued number to a value between 0 and 1, making it ideal for modeling probabilities.</p>
<p>The sigmoid function is given by the formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma(z)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-z%7D%7D%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?z"> is the input to the sigmoid function (in logistic regression, <img src="https://latex.codecogs.com/png.latex?z%20=%20%5Cmathbf%7Bx%7D%20%5Ccdot%20%5Ctheta">)</li>
<li><img src="https://latex.codecogs.com/png.latex?e"> is the base of the natural logarithm</li>
</ul>
<p>The output of the sigmoid function is interpreted as the probability <img src="https://latex.codecogs.com/png.latex?P(y=1%7CX)">.</p>
</section>
<section id="logistic-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-model">Logistic Regression Model</h2>
<p>In Logistic Regression, the hypothesis is modeled as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah_%5Ctheta(X)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-%5Ctheta%5ET%20X%7D%7D%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X"> is the input feature vector</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the parameter vector (weights)</li>
</ul>
</section>
<section id="cost-function-for-logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="cost-function-for-logistic-regression">Cost Function for Logistic Regression</h2>
<p style="text-align: justify">
Unlike Linear Regression, which uses the Mean Squared Error (MSE) as the cost function, Logistic Regression uses <strong>log loss</strong> or <strong>binary cross-entropy</strong> as the cost function, as the output is binary (0 or 1).
</p>
<p>So, basically we model probability from the given data. In other words, we can write</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cmathbb%7BP%7D(y=%201%20%5Ctext%7B%20or%20%7D0%20%7C%5Ctext%7B%20given%20%7DX)&amp;=p(%5Cmathbf%7Bx%7D)=%5Csigma(%5Cmathbf%7Bx%7D%5Ccdot%5Ctheta)=%5Cfrac%7B1%7D%7B1+e%5E%7B-%5Cmathbf%7Bx%7D%5Ccdot%20%5Ctheta%7D%7D%5C%5C%0A%5Cimplies%20p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)&amp;%20=%20%5Cfrac%7B1%7D%7B1+e%5E%7B-(%5Ctheta_0+%5Ctheta_1x_1+%5Ccdots+%5Ctheta_dx_d)%7D%7D%5C%5C%0A%5Cimplies%20p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)&amp;%20=%20%5Cbegin%7Bcases%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)%20&amp;%20%5Ctext%7B%20if%20%7D%20y=1%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%201-p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)%20&amp;%20%5Ctext%7B%20if%20%7D%20y=0%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cend%7Bcases%7D%0A%5Cend%7Balign*%7D"></p>
<p>Where, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Ctheta%7D,%5Cmathbf%7Bx%7D%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd+1%7D"> and <img src="https://latex.codecogs.com/png.latex?d"> is the dimension of the data. For single data vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> the binary cross-entropy function can be written as</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Al(%5Ctheta)%20=%20yp_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)+%20(1-y)(1-p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D))%0A"></p>
<p>Since we have <img src="https://latex.codecogs.com/png.latex?n"> of those i.i.d data vectors therefore, we can write</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(%5Ctheta)%20=%20%5Cprod_%7Bi=1%7D%5E%7Bn%7D%20%5Cleft(y_ip_%7B%5Ctheta%7D(%5Cmathbf%7Bx_i%7D)+%20(1-y_i)(1-p_%7B%5Ctheta%7D(%5Cmathbf%7Bx_i%7D))%5Cright)%0A"></p>
<p>Since our goal is to minimize the loss, we need to perform derivatives of the loss function. Therefore, to change from the product form to addition form we take negative log of the above expression</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cell%20(%5Ctheta)%20=%20-%5Clog%7BL(%5Ctheta)%7D%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7Bp_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D)%7D+(1-y_i)%5Clog%7B(1-p_%7B%5Ctheta%7D(%5Cmathbf%7Bx%7D))%7D%0A%5Cend%7Balign*%7D"></p>
<p>For the ease of calculation, let’s rewrite the above equation in terms of <img src="https://latex.codecogs.com/png.latex?m"> and <img src="https://latex.codecogs.com/png.latex?b"> where <img src="https://latex.codecogs.com/png.latex?m%5Cin%20%5Cmathbb%7BR%7D%5Ed%20=%20(%5Ctheta_1,%5Ctheta_2,%5Ccdots,%5Ctheta_d)%5ET"> and <img src="https://latex.codecogs.com/png.latex?b%5Cin%20%5Cmathbb%7BR%7D">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cell%20(%5Ctheta)%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7Bp_%7Bm,b%7D(%5Cmathbf%7Bx%7D)%7D+(1-y_i)%5Clog%7B(1-p_%7Bm,b%7D(%5Cmathbf%7Bx%7D))%7D%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?n"> is the number of training examples<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?m"> is the number of features</li>
<li><img src="https://latex.codecogs.com/png.latex?y%5E%7B(i)%7D"> is the true label of the <img src="https://latex.codecogs.com/png.latex?i%5E%7Bth%7D"> example</li>
<li><img src="https://latex.codecogs.com/png.latex?b"> is the bias for the <img src="https://latex.codecogs.com/png.latex?i%5E%7Bth%7D"> example</li>
</ul>
</section>
<section id="gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h2>
<p>To minimize the cost function and find the optimal values for <img src="https://latex.codecogs.com/png.latex?%5Ctheta">, we use <strong>gradient descent</strong>. We start from the last form of the loss function and convert this to a form that is easy to take the partial dervivatives.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cell%20(%5Ctheta)%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7Bp_%7Bm,b%7D(%5Cmathbf%7Bx%7D)%7D+(1-y_i)%5Clog%7B(1-p_%7Bm,b%7D(%5Cmathbf%7Bx%7D))%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7B(%5Csigma(mx_i+b))%7D+(1-y_i)%5Clog%7B(1-%5Csigma(mx_i+b))%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7B(%5Csigma(mx_i+b))%7D+(1-y_i)%5Clog%7B(%5Csigma(-(mx_i+b)))%7D;%5Chspace%7B3mm%7D%5Ctext%7B%20Since%20%7D%201-%5Csigma(x)=%5Csigma(-x)%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Cleft%5B%5Clog%7B(%5Csigma(mx_i+b))%7D-%5Clog%7B(%5Csigma(-(mx_i+b)))%7D%5Cright%5D+%5Clog%7B(-%5Csigma(mx_i+b))%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i%5Clog%7B%5Cleft(%5Cfrac%7B%5Csigma(mx_i+b)%7D%7B%5Csigma(-(mx_i+b))%7D%5Cright)%7D+%5Clog%7B(-%5Csigma(mx_i+b))%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_i(mx_i+b)+%5Clog%7B(%5Csigma(-(mx_i+b)))%7D;%5Chspace%7B3mm%7D%5Ctext%7B%20Since%20%7D%5Cfrac%7B%5Csigma(x)%7D%7B-%5Csigma(x)%7D=e%5Ex%5C%5C%0A%5Cend%7Balign*%7D"></p>
<p>Now we again use the beautiful features of the sigmoid function<br>
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cfrac%7Bd%5Csigma(x)%7D%7Bdx%7D&amp;=%5Cfrac%7Bd%7D%7Bdx%7D%5Cleft(%5Cfrac%7B1%7D%7B1+e%5E%7B-x%7D%7D%5Cright)=%5Cfrac%7Be%5E%7B-x%7D%7D%7B%5Cleft(1+e%5E%7B-x%7D%5Cright)%5E2%7D=%5Cfrac%7B1%7D%7B1+e%5E%7B-x%7D%7D%5Ccdot%20%5Cfrac%7Be%5E%7B-x%7D%7D%7B1+e%5E%7B-x%7D%7D%5C%5C%0A&amp;=%5Csigma(x)%5Cleft(1-%5Cfrac%7B1%7D%7B1+e%5E%7B-x%7D%7D%5Cright)=%5Csigma(x)(1-%5Csigma(x))%5C%5C%0A&amp;=%5Csigma(x)%5Csigma(-x)%0A%5Cend%7Balign*%7D"></p>
<p>Finally, we are ready to take the partial derivatives of the loss function with respect to <img src="https://latex.codecogs.com/png.latex?m"> and <img src="https://latex.codecogs.com/png.latex?b">,</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cfrac%7B%5Cpartial%20%5Cell%7D%7B%5Cpartial%20m%7D%20&amp;=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_ix_i+%5Cfrac%7B1%7D%7B%5Csigma(-(mx_i+b))%7D%5Cfrac%7Bd%7D%7Bdx%7D(%5Csigma(-(mx_i+b)))%5C%5C%0A&amp;%20=-%5Csum_%7Bi=1%7D%5E%7Bn%7Dy_ix_i+%5Cfrac%7B1%7D%7B%5Csigma(-(mx_i+b))%7D%5Csigma(-(mx_i+b))%5Csigma(mx_i+b)(-x_i)%5C%5C%0A&amp;%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i(y_i-%5Csigma(mx_i+b))%5C%5C%0A&amp;%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7Dx_i(p_%7Bm,b%7D(x_i)-y_i)=%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i(%5Chat%7By_i%7D-y_i)%5C%5C%0A&amp;%20=%20%5Cmathbf%7Bx_i%7D%5Ccdot(%5Cmathbf%7B%5Chat%7By_i%7D%7D-%5Cmathbf%7By_i%7D)%5C%5C%0A%5Ctext%7B%20and%20%7D%20&amp;%20%5C%5C%0A&amp;%20%5C%5C%0A%5Cfrac%7B%5Cpartial%20%5Cell%7D%7B%5Cpartial%20b%7D%20&amp;%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7D%20y_i%20+%5Cfrac%7B1%7D%7B%5Csigma(-(mx_i+b))%7D%5Cfrac%7Bd%7D%7Bdx%7D(%5Csigma(-(mx_i+b)))%5C%5C%0A&amp;%20=%20%20-%5Csum_%7Bi=1%7D%5E%7Bn%7D%20y_i%20-%20%5Cfrac%7B1%7D%7B%5Csigma(-(mx_i+b))%7D%5Csigma(-(mx_i+b))%5Csigma(mx_i+b)%5C%5C%0A&amp;%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20p_%7Bm,b%7D(x_i)-y_i=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Chat%7By%7D_i-y_i%5C%5C%0A&amp;%20=%20%5Chat%7B%5Cmathbf%7By%7D%7D_i-%5Cmathbf%7By%7D_i%0A%5Cend%7Balign*%7D"></p>
<p>Using this gradient, we update the parameter vector <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> iteratively:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bj+1%7D%20:=%20%5Ctheta_j%20-%20%5Calpha%20%5Cnabla%20%5Cell%20(%5Ctheta_j)%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Calpha"> is the learning rate</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cnabla%20%5Cell%20(%5Ctheta_j)"> is the partial derivative of the cost function with respect to <img src="https://latex.codecogs.com/png.latex?%5Ctheta_j"> and <img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%20%5Cell%20(%5Ctheta)%20=%20%5Cbegin%7Bbmatrix%7D%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Chat%7By%7D_i-y_i%20%5C%5C%0A%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i(%5Chat%7By_i%7D-y_i)%20%5Cend%7Bbmatrix%7D%20%20=%5Cbegin%7Bbmatrix%7D%5Chat%7B%5Cmathbf%7By%7D%7D_i-%5Cmathbf%7By%7D_i%20%5C%5C%0A%5Cmathbf%7Bx_i%7D%5Ccdot(%5Cmathbf%7B%5Chat%7By_i%7D%7D-%5Cmathbf%7By_i%7D)%20%5Cend%7Bbmatrix%7D=%20X%5ET(%5Chat%7B%5Cmathbf%7By%7D%7D_i-%5Cmathbf%7By%7D_i)=X%5ET(%5Csigma(X%5Cvec%7B%5Ctheta%7D)-%5Cvec%7By%7D)%0A"></li>
</ul>
<hr>
</section>
<section id="python-code-implementation-from-scratch" class="level2">
<h2 class="anchored" data-anchor-id="python-code-implementation-from-scratch">Python Code Implementation from Scratch</h2>
<p>Here’s how to implement Logistic Regression from scratch in Python. We will use two different forms for our class</p>
<div id="59baf6f3" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> LogisticRegression1:</span>
<span id="cb1-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, n_iterations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb1-5">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Hyper Parameters</span></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        - learning_rate: learning rate; float; default 0.01</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        - n_itearations: number of iterations; int; default 1000</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Model Parameters</span></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        - weights: weights of the features; float or int</span></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        - bias: bias of the model; float or int</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb1-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learning_rate</span>
<span id="cb1-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_iterations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> n_iterations </span>
<span id="cb1-15">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> </span>
<span id="cb1-17">    </span>
<span id="cb1-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _sigmoid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>np.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>x))</span>
<span id="cb1-20"></span>
<span id="cb1-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X,y):</span>
<span id="cb1-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_sample = number of samples in the data set: the value n</span></span>
<span id="cb1-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        n_features = number of features or the dimension of the data set: the value d</span></span>
<span id="cb1-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        """</span></span>
<span id="cb1-26">        n_sample,n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape</span>
<span id="cb1-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(n_features) </span>
<span id="cb1-28">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb1-29"></span>
<span id="cb1-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.n_iterations):</span>
<span id="cb1-31">            linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias</span>
<span id="cb1-32">            pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._sigmoid(linear)</span>
<span id="cb1-33"></span>
<span id="cb1-34">            dw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_sample)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.dot(X.T,(pred<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y))</span>
<span id="cb1-35">            db <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_sample) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(pred<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y)</span>
<span id="cb1-36"></span>
<span id="cb1-37">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> dw </span>
<span id="cb1-38">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> db</span>
<span id="cb1-39">    </span>
<span id="cb1-40">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb1-41">        linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias</span>
<span id="cb1-42">        predicted_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._sigmoid(linear)</span>
<span id="cb1-43">        class_of_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> y <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> predicted_y]</span>
<span id="cb1-44">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> class_of_y</span></code></pre></div>
</div>
<p>Now let’s use this using the <code>scikit-learn</code> breast cancer data set.</p>
<div id="9d5ab62f" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_breast_cancer</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb2-5"></span>
<span id="cb2-6">b_cancer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_breast_cancer()</span>
<span id="cb2-7">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b_cancer.data, b_cancer.target</span>
<span id="cb2-8">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X,y, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>, stratify<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.30</span>)</span>
<span id="cb2-9"></span>
<span id="cb2-10">clf1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression1(learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>)</span>
<span id="cb2-11">clf1.fit(X_train, y_train)</span>
<span id="cb2-12">predicted_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf1.predict(X_test)</span>
<span id="cb2-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(accuracy_score(predicted_y, y_test),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.91</code></pre>
</div>
</div>
<p>Now lets compare this with the standard <code>scikit-learn</code> library</p>
<div id="52abbcf2" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb4-2"></span>
<span id="cb4-3">clf2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression()</span>
<span id="cb4-4">clf2.fit(X_train, y_train)</span>
<span id="cb4-5">predicted_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf2.predict(X_test)</span>
<span id="cb4-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(accuracy_score(predicted_y, y_test),<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.96</code></pre>
</div>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer.</li>
<li>Gradient descent is a widely used optimization technique in machine learning.</li>
<li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</li>
<li>Nocedal, J., &amp; Wright, S. (2006). <em>Numerical Optimization</em> (2nd ed.). Springer.</li>
<li>Regularization techniques like L2 (Ridge) and L1 (Lasso) are commonly used in logistic regression to prevent overfitting.</li>
<li>Ng, A. (2004). <em>Feature Selection, L1 vs.&nbsp;L2 Regularization, and Rotational Invariance</em>. ICML Proceedings.</li>
<li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010). <em>Regularization Paths for Generalized Linear Models via Coordinate Descent</em>. Journal of Statistical Software, 33(1), 1-22.</li>
<li>The extension of logistic regression to multiclass classification via the softmax function is part of the core material for understanding classification tasks.</li>
<li>Murphy, K. P. (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</li>
<li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li>VanderPlas, J. (2016). <em>Python Data Science Handbook: Essential Tools for Working with Data</em>. O’Reilly Media.</li>
<li>Raschka, S., &amp; Mirjalili, V. (2017). <em>Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2</em>. Packt Publishing.</li>
</ul>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/logreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/logreg/" data-width="750" data-numposts="5">

</div>
<hr>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Classification: {Logistic} {Regression} - {A} {Comprehensive}
    {Guide} with {Mathematical} {Derivation} and {Python} {Code}},
  date = {2024-10-07},
  url = {https://mrislambd.github.io/posts/logreg/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Classification: Logistic Regression - A
Comprehensive Guide with Mathematical Derivation and Python
Code.”</span> October 7, 2024. <a href="https://mrislambd.github.io/posts/logreg/">https://mrislambd.github.io/posts/logreg/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/logreg/</guid>
  <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/logreg/logreg.png" medium="image" type="image/png" height="115" width="144"/>
</item>
<item>
  <title>Ensemble Methods: Gradient Boosting - A detailed overview</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/gradientboosting/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Gradient Boosting is one of the most powerful techniques for building predictive models. It has gained popularity in the realms of both classification and regression due to its flexibility and effectiveness, particularly with decision trees as weak learners.
</p>
</section>
<section id="what-is-gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="what-is-gradient-boosting">What is Gradient Boosting?</h2>
<p style="text-align: justify">
Gradient Boosting is an ensemble learning technique where several weak learners (typically decision trees) are combined to form a strong learner. The key idea behind boosting is to train models sequentially, where each new model tries to correct the errors of the previous ones. Gradient Boosting achieves this by minimizing a loss function using gradient descent.
</p>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Weak Learners</strong>: These are models that are only slightly better than random guessing. Decision trees with few splits (depth-1 trees) are commonly used as weak learners.<br>
</li>
<li><strong>Sequential Learning</strong>: Models are trained one after another. Each model focuses on the errors (residuals) made by the previous models.<br>
</li>
<li><strong>Gradient Descent</strong>: Gradient Boosting relies on gradient descent to minimize the loss function.</li>
</ul>
<hr>
</section>
<section id="mathematical-derivation-of-gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-derivation-of-gradient-boosting">Mathematical Derivation of Gradient Boosting</h2>
<p>Let’s consider a regression problem where we aim to predict the target values <img src="https://latex.codecogs.com/png.latex?y%20%5Cin%20%5Cmathbb%7BR%7D"> using the features <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5Ed">. We aim to find a function <img src="https://latex.codecogs.com/png.latex?F(x)"> that minimizes the expected value of a loss function <img src="https://latex.codecogs.com/png.latex?L(y,%20F(x))">, where <img src="https://latex.codecogs.com/png.latex?L"> could be mean squared error or any other appropriate loss function.</p>
<p>The idea behind Gradient Boosting is to improve the current model by adding a new model that reduces the loss:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF_%7Bm+1%7D(x)%20=%20F_m(x)%20+%20%5Ceta%20h_m(x)%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?F_m(x)"> is the current model after <img src="https://latex.codecogs.com/png.latex?m"> iterations,<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?h_m(x)"> is the new weak learner added at iteration <img src="https://latex.codecogs.com/png.latex?m">,<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate, which controls how much the new learner impacts the final model.</li>
</ul>
<p style="text-align: justify">
We aim to minimize the loss function <img src="https://latex.codecogs.com/png.latex?L(y,%20F(x))">. At each iteration, Gradient Boosting fits a new model <img src="https://latex.codecogs.com/png.latex?h_m(x)"> to the negative gradient of the loss function. The negative gradient represents the direction of steepest descent, essentially capturing the errors or residuals of the model. <br> Given a loss function <img src="https://latex.codecogs.com/png.latex?L(y,%20F(x))">, we compute the residuals (or pseudo-residuals) as:
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ar_%7Bi,m%7D%20=%20-%20%5Cfrac%7B%5Cpartial%20L(y_i,%20F_m(x_i))%7D%7B%5Cpartial%20F_m(x_i)%7D%0A"></p>
<p>These residuals are then used to fit the new weak learner <img src="https://latex.codecogs.com/png.latex?h_m(x)">. In the case of squared error (for regression), the residuals simplify to the difference between the observed and predicted values:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ar_%7Bi,m%7D%20=%20y_i%20-%20F_m(x_i)%0A"></p>
<p>Thus, the new learner is fit to minimize these residuals.</p>
<p><strong>Steps</strong></p>
<p><strong>Initialize</strong> the model with a constant prediction: <img src="https://latex.codecogs.com/png.latex?%0AF_0(x)%20=%20%5Carg%20%5Cmin_%7Bc%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20L(y_i,%20c)%0A"> For squared error loss, <img src="https://latex.codecogs.com/png.latex?F_0(x)"> would be the mean of the target values <img src="https://latex.codecogs.com/png.latex?y">.</p>
<p><strong>For each iteration <img src="https://latex.codecogs.com/png.latex?m%20=%201,%202,%20%5Cdots,%20M">:</strong></p>
<ul>
<li>Compute the residuals: <img src="https://latex.codecogs.com/png.latex?%0Ar_%7Bi,m%7D%20=%20-%20%5Cfrac%7B%5Cpartial%20L(y_i,%20F_m(x_i))%7D%7B%5Cpartial%20F_m(x_i)%7D%0A"><br>
</li>
<li>Fit a weak learner <img src="https://latex.codecogs.com/png.latex?h_m(x)"> to the residuals <img src="https://latex.codecogs.com/png.latex?r_%7Bi,m%7D">.<br>
</li>
<li>Update the model: <img src="https://latex.codecogs.com/png.latex?%0AF_%7Bm+1%7D(x)%20=%20F_m(x)%20+%20%5Ceta%20h_m(x)%0A"><br>
</li>
<li>Continue until a stopping criterion is met (e.g., a fixed number of iterations or convergence).</li>
</ul>
</section>
<section id="assumptions-of-gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="assumptions-of-gradient-boosting">Assumptions of Gradient Boosting</h2>
<p>Gradient Boosting, like any algorithm, comes with its own set of assumptions and limitations. Key assumptions include:</p>
<ol type="1">
<li><strong>Independence of Features</strong>: Gradient Boosting assumes that the features are independent. Correlated features can lead to overfitting.</li>
<li><strong>Weak Learners</strong>: It assumes that weak learners, typically shallow decision trees, are adequate for capturing the patterns in the data, though overly complex learners may lead to overfitting.</li>
<li><strong>Additive Model</strong>: The model is additive, meaning it combines weak learners to improve performance. This makes it sensitive to noisy data, as adding too many learners might lead to overfitting.</li>
</ol>
</section>
<section id="when-to-use-gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-gradient-boosting">When to Use Gradient Boosting?</h2>
<p>Gradient Boosting is ideal in the following scenarios:</p>
<ul>
<li><strong>High Predictive Power</strong>: When accuracy is a top priority, Gradient Boosting often outperforms simpler algorithms like linear regression or basic decision trees.<br>
</li>
<li><strong>Complex Datasets</strong>: It works well with datasets that have complex patterns, non-linear relationships, or multiple feature interactions.<br>
</li>
<li><strong>Feature Engineering</strong>: It is less reliant on extensive feature engineering because decision trees are capable of handling mixed types of features (numerical and categorical) and automatically learning interactions.<br>
</li>
<li><strong>Imbalanced Data</strong>: Gradient Boosting can handle class imbalances by tuning the loss function, making it suitable for classification tasks like fraud detection.</li>
</ul>
<p>However, due to its complexity, Gradient Boosting can be computationally expensive, so it’s less ideal for very large datasets or real-time predictions.</p>
</section>
<section id="python-implementation-of-gradient-boosting" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-of-gradient-boosting">Python Implementation of Gradient Boosting</h2>
<p>Below is a Python implementation using the <code>scikit-learn</code> library for a regression problem. We will use the Boston Housing dataset as an example.</p>
<div id="036f6011" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GradientBoostingRegressor</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the Boston Housing dataset</span></span>
<span id="cb1-8">data_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://lib.stat.cmu.edu/datasets/boston"</span></span>
<span id="cb1-9">raw_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(data_url, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\s+"</span>, skiprows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb1-10">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([raw_df.values[::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, :], raw_df.values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, :<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]])</span>
<span id="cb1-11">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> raw_df.values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb1-12"></span>
<span id="cb1-13">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data</span>
<span id="cb1-14">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split the data into training and test sets</span></span>
<span id="cb1-17">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize and fit the Gradient Boosting Regressor</span></span>
<span id="cb1-20">gb_regressor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GradientBoostingRegressor(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-21">gb_regressor.fit(X_train, y_train)</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict on the test set</span></span>
<span id="cb1-24">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gb_regressor.predict(X_test)</span>
<span id="cb1-25"></span>
<span id="cb1-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluate the model</span></span>
<span id="cb1-27">mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb1-28"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 6.240854334653895</code></pre>
</div>
</div>
<p>In this example:</p>
<ul>
<li>We use the <code>GradientBoostingRegressor</code> from <code>scikit-learn</code> for a regression task.<br>
</li>
<li>We fit the model on the Boston Housing dataset, and predict values on the test set.<br>
</li>
<li>The mean squared error (MSE) is used to evaluate the model’s performance.</li>
</ul>
<p><strong>Hyperparameters</strong>:</p>
<ul>
<li><code>n_estimators</code>: Number of boosting stages to run.<br>
</li>
<li><code>learning_rate</code>: Controls the contribution of each tree to the final model.<br>
</li>
<li><code>max_depth</code>: Limits the depth of the individual decision trees (weak learners).</li>
</ul>
<p style="text-align: justify">
Gradient Boosting is a powerful ensemble technique, particularly effective for both classification and regression tasks. It builds models sequentially, focusing on correcting the mistakes of prior models. While it is computationally expensive and prone to overfitting if not properly regularized, it often achieves state-of-the-art results in predictive tasks.
</p>
<hr>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/" target="_blank" style="text-decoration:none"><strong>“The Elements of Statistical Learning”</strong> by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</a> (freely available online).</li>
<li><strong>“Pattern Recognition and Machine Learning”</strong> by Christopher M. Bishop:</li>
<li><a href="https://projecteuclid.org/euclid.aos/1013203451" target="_blank" style="text-decoration:none"><strong>“Greedy Function Approximation: A Gradient Boosting Machine”</strong> by Jerome Friedman</a><br>
</li>
<li><a href="https://www.jmlr.org/papers/volume2/friedman01a/friedman01a.pdf" target="_blank" style="text-decoration:none"><strong>“A Short Introduction to Boosting”</strong> by Yoav Freund and Robert E. Schapire</a><br>
</li>
<li><a href="https://explained.ai/gradient-boosting/index.html" target="_blank" style="text-decoration:none"><strong>“Understanding Gradient Boosting Machines”</strong> by Terence Parr and Jeremy Howard</a><br>
</li>
<li><a href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/" target="_blank" style="text-decoration:none"><strong>“A Gentle Introduction to Gradient Boosting”</strong> by Jason Brownlee</a></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/gradientboosting/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/gradientboosting/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Ensemble {Methods:} {Gradient} {Boosting} - {A} Detailed
    Overview},
  date = {2024-10-07},
  url = {https://mrislambd.github.io/posts/gradientboosting/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Ensemble Methods: Gradient Boosting - A
Detailed Overview.”</span> October 7, 2024. <a href="https://mrislambd.github.io/posts/gradientboosting/">https://mrislambd.github.io/posts/gradientboosting/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/gradientboosting/</guid>
  <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/gradientboosting/gb.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Ensemble Methods: Random Forest - A detailed overview</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/randomforest/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Random Forest is one of the most popular machine learning algorithms, known for its simplicity, versatility, and ability to perform both classification and regression tasks. It operates by constructing a multitude of decision trees during training and outputs the mode of the classes (for classification) or the mean prediction (for regression) of the individual trees.
</p>
</section>
<section id="what-is-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="what-is-random-forest">What is Random Forest?</h2>
<p style="text-align: justify">
Random Forest is an ensemble learning method that builds multiple decision trees and combines their predictions to obtain a more accurate and stable result. Each tree is built using a different random subset of the data, and at each node, a random subset of features is considered when splitting the data.
</p>
<ul>
<li><strong>Classification:</strong> The final output is determined by majority voting from all the decision trees</li>
<li><strong>Regression:</strong> The output is the average of all tree predictions.</li>
</ul>
</section>
<section id="mathematics-behind-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="mathematics-behind-random-forest">Mathematics Behind Random Forest</h2>
<p>To understand Random Forest, we first need to recap how a decision tree works and then explore how Random Forest extends this idea.</p>
<section id="decision-tree-recap" class="level3">
<h3 class="anchored" data-anchor-id="decision-tree-recap"><a href="../../posts/decisiontree/index.html" target="_blank" style="text-decoration:none">Decision Tree Recap</a></h3>
<p>A decision tree is a tree-structured model where each internal node represents a “test” on an attribute (e.g., whether the feature value is above or below a threshold), each branch represents the outcome of the test, and each leaf node represents a class label (classification) or a value (regression).</p>
<ul>
<li>For <strong>classification</strong>, the goal is to partition the data such that the class labels in each partition are as homogeneous as possible.<br>
</li>
<li>For <strong>regression</strong>, the goal is to minimize the variance of the predicted values.</li>
</ul>
<p>Mathematically, the decision tree makes decisions by minimizing the <strong>Gini Index</strong> or <strong>Entropy</strong> for classification tasks and minimizing the <strong>Mean Squared Error (MSE)</strong> for regression tasks.</p>
</section>
<section id="random-forest-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-algorithm">Random Forest Algorithm</h3>
<p>Random Forest enhances decision trees by employing two key concepts:</p>
<ul>
<li><strong>Random Sampling (Bootstrap Sampling):</strong> From the training set of size <img src="https://latex.codecogs.com/png.latex?N">, randomly draw <img src="https://latex.codecogs.com/png.latex?N"> samples with replacement.<br>
</li>
<li><strong>Feature Subsampling:</strong> At each node of the decision tree, a random subset of the features is selected, and the best split is chosen only from these features.</li>
</ul>
<p>The process for building a Random Forest can be summarized as follows:</p>
<ol type="1">
<li>Draw <img src="https://latex.codecogs.com/png.latex?B"> bootstrap samples from the original dataset.</li>
<li>For each bootstrap sample, grow an unpruned decision tree using a random subset of features at each node.</li>
<li>For <strong>classification</strong>, combine the predictions of all the trees by majority voting.</li>
<li>For <strong>regression</strong>, combine the predictions by averaging the outputs of all trees.</li>
</ol>
</section>
<section id="random-forest-for-classification" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-for-classification">Random Forest for Classification</h3>
<p>For classification tasks, Random Forest works by constructing multiple decision trees, each built on a different subset of the data and a random subset of the features.</p>
<p>Given a dataset <img src="https://latex.codecogs.com/png.latex?D%20=%20%5C%7B(x_1,%20y_1),%20(x_2,%20y_2),%20...,%20(x_N,%20y_N)%5C%7D">, where <img src="https://latex.codecogs.com/png.latex?x_i"> is a feature vector and <img src="https://latex.codecogs.com/png.latex?y_i"> is the class label, Random Forest generates <img src="https://latex.codecogs.com/png.latex?B"> decision trees <img src="https://latex.codecogs.com/png.latex?T_1,%20T_2,%20...,%20T_B">.</p>
<p>For each test point <img src="https://latex.codecogs.com/png.latex?x">, each tree <img src="https://latex.codecogs.com/png.latex?T_b"> gives a class prediction: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D_b(x)%20=%20T_b(x)%0A"> The final prediction is determined by majority voting: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D(x)%20=%20%5Ctext%7Bargmax%7D_k%20%5Csum_%7Bb=1%7D%5E%7BB%7D%20I(%5Chat%7By%7D_b(x)%20=%20k)%0A"> where <img src="https://latex.codecogs.com/png.latex?I(%5Ccdot)"> is an indicator function that equals 1 if the condition is true and 0 otherwise.</p>
<hr>
</section>
<section id="random-forest-for-regression" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-for-regression">Random Forest for Regression</h3>
<p>In regression tasks, Random Forest builds trees that predict continuous values and averages the results.</p>
<p>Given a dataset <img src="https://latex.codecogs.com/png.latex?D%20=%20%5C%7B(x_1,%20y_1),%20(x_2,%20y_2),%20...,%20(x_N,%20y_N)%5C%7D">, where <img src="https://latex.codecogs.com/png.latex?x_i"> is a feature vector and <img src="https://latex.codecogs.com/png.latex?y_i"> is the continuous target variable, Random Forest generates <img src="https://latex.codecogs.com/png.latex?B"> decision trees <img src="https://latex.codecogs.com/png.latex?T_1,%20T_2,%20...,%20T_B">.</p>
<p>For each test point <img src="https://latex.codecogs.com/png.latex?x">, each tree <img src="https://latex.codecogs.com/png.latex?T_b"> gives a predicted value: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D_b(x)%20=%20T_b(x)%0A"> The final prediction is the average of all the tree predictions: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D(x)%20=%20%5Cfrac%7B1%7D%7BB%7D%20%5Csum_%7Bb=1%7D%5E%7BB%7D%20%5Chat%7By%7D_b(x)%0A"></p>
<hr>
</section>
</section>
<section id="assumptions-of-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="assumptions-of-random-forest">Assumptions of Random Forest</h2>
<p>Random Forest makes few assumptions about the data, making it highly flexible. Some assumptions include:</p>
<ul>
<li><strong>Independent Features:</strong> While Random Forest does not explicitly assume that features are independent, correlated features can reduce its performance slightly.<br>
</li>
<li><strong>Noisy Data:</strong> Random Forest is robust to noise due to its ensemble nature.<br>
</li>
<li><strong>Non-linearity:</strong> Random Forest can handle non-linear relationships between features and the target.</li>
</ul>
</section>
<section id="advantages-of-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="advantages-of-random-forest">Advantages of Random Forest</h2>
<ul>
<li><strong>Reduction of Overfitting:</strong> Random Forest reduces overfitting by averaging the predictions of multiple trees.</li>
<li><strong>Handles Missing Data:</strong> It can handle missing values by assigning them to the most frequent class (classification) or mean value (regression).</li>
<li><strong>Robust to Noise:</strong> It is relatively resistant to outliers and noise due to its ensemble nature.</li>
<li><strong>Works with Categorical &amp; Continuous Variables:</strong> Random Forest can handle both categorical and continuous data types.</li>
<li><strong>Feature Importance:</strong> It provides an estimate of feature importance, allowing for better interpretability of models.</li>
</ul>
</section>
<section id="disadvantages-of-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="disadvantages-of-random-forest">Disadvantages of Random Forest</h2>
<ul>
<li><strong>Complexity:</strong> The algorithm is computationally intensive, especially with a large number of trees.</li>
<li><strong>Interpretability:</strong> While decision trees are interpretable, Random Forest is a “black-box” model where it’s hard to understand individual predictions.</li>
<li><strong>Memory Usage:</strong> Random Forest can require more memory to store multiple decision trees.</li>
<li><strong>Bias in Imbalanced Data:</strong> For classification tasks with imbalanced data, Random Forest may be biased toward the majority class.</li>
</ul>
<hr>
</section>
<section id="python-implementation" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation">Python Implementation</h2>
<p>Here is a Python code example of how to implement Random Forest for both classification and regression using <code>scikit-learn</code>.</p>
<div id="483ea690" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score, mean_squared_error</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Classification Example: Iris dataset</span></span>
<span id="cb1-9">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb1-10">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.data, iris.target</span>
<span id="cb1-11">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize RandomForest Classifier</span></span>
<span id="cb1-14">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-15">clf.fit(X_train, y_train)</span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict and evaluate</span></span>
<span id="cb1-18">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.predict(X_test)</span>
<span id="cb1-19">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb1-20"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Classification Accuracy: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Regression Example: Boston Housing dataset</span></span>
<span id="cb1-23">data_url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://lib.stat.cmu.edu/datasets/boston"</span></span>
<span id="cb1-24">raw_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(data_url, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\s+"</span>, skiprows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb1-25">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.hstack([raw_df.values[::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, :], raw_df.values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, :<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]])</span>
<span id="cb1-26">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> raw_df.values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>::<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb1-27"></span>
<span id="cb1-28">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data</span>
<span id="cb1-29">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target</span>
<span id="cb1-30">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize RandomForest Regressor</span></span>
<span id="cb1-33">reg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestRegressor(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-34">reg.fit(X_train, y_train)</span>
<span id="cb1-35"></span>
<span id="cb1-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict and evaluate</span></span>
<span id="cb1-37">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> reg.predict(X_test)</span>
<span id="cb1-38">mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb1-39"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Regression Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Accuracy: 1.0
Regression Mean Squared Error: 9.711591381578941</code></pre>
</div>
</div>
</section>
<section id="hyperparameter-tuning-for-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-tuning-for-random-forest">Hyperparameter Tuning for Random Forest</h2>
<p>Tuning the hyperparameters of a Random Forest can significantly improve its performance. Here are some important hyperparameters to consider:</p>
<section id="important-hyperparameters" class="level3">
<h3 class="anchored" data-anchor-id="important-hyperparameters">Important Hyperparameters</h3>
<ul>
<li><strong><code>n_estimators</code>:</strong> This is the number of trees in the forest. Increasing this number usually improves performance but also increases computational cost.
<ul>
<li><strong>Tip:</strong> Start with a default value of 100 and increase as needed.<br>
</li>
</ul></li>
<li><strong><code>max_depth</code>:</strong> The maximum depth of each tree. Deeper trees can model more complex relationships, but they also increase the risk of overfitting.
<ul>
<li><strong>Tip:</strong> Use cross-validation to find the optimal depth that balances bias and variance<br>
</li>
</ul></li>
<li><strong><code>min_samples_split</code>:</strong> The minimum number of samples required to split an internal node. Higher values prevent the tree from becoming too specific (overfitting).
<ul>
<li><strong>Tip:</strong> Use higher values (e.g., 5 or 10) to reduce overfitting in noisy datasets.</li>
</ul></li>
<li><strong><code>min_samples_leaf</code>:</strong> The minimum number of samples required to be at a leaf node. Larger leaf sizes reduce model complexity and can help generalization.</li>
<li><strong><code>max_features</code>:</strong> The number of features to consider when looking for the best split. Randomly selecting fewer features can reduce correlation between trees and improve generalization.
<ul>
<li><strong>Tip:</strong> For classification, a common choice is <code>sqrt(number_of_features)</code>. For regression, <code>max_features = number_of_features / 3</code> is often effective.</li>
</ul></li>
<li><strong><code>bootstrap</code>:</strong> Whether to use bootstrap samples when building trees. Set this to <code>True</code> for Random Forest (default) or <code>False</code> for extremely randomized trees (also known as ExtraTrees).</li>
</ul>
</section>
<section id="grid-search-for-hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="grid-search-for-hyperparameter-tuning">Grid Search for Hyperparameter Tuning</h3>
<p>To fine-tune the hyperparameters of a Random Forest, we can use <strong>GridSearchCV</strong> or <strong>RandomizedSearchCV</strong> in <code>scikit-learn</code>. Here’s an example of how to use <code>GridSearchCV</code> for tuning a Random Forest Classifier:</p>
<div id="0ec888eb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb3-2"></span>
<span id="cb3-3">param_grid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb3-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'n_estimators'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>],</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>],</span>
<span id="cb3-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_split'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>],</span>
<span id="cb3-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_leaf'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>],</span>
<span id="cb3-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_features'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sqrt'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log2'</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]</span>
<span id="cb3-9">}</span>
<span id="cb3-10"></span>
<span id="cb3-11">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb3-12">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.data, iris.target</span>
<span id="cb3-13">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize Random Forest Classifier</span></span>
<span id="cb3-16">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-17"></span>
<span id="cb3-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform grid search</span></span>
<span id="cb3-19">grid_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(estimator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>clf, param_grid<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>param_grid, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, n_jobs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-20">grid_search.fit(X_train, y_train)</span>
<span id="cb3-21"></span>
<span id="cb3-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Best parameters from grid search</span></span>
<span id="cb3-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Best Hyperparameters:"</span>, grid_search.best_params_)</span>
<span id="cb3-24"></span>
<span id="cb3-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluate with best parameters</span></span>
<span id="cb3-26">best_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_search.best_estimator_</span>
<span id="cb3-27">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> best_model.predict(X_test)</span>
<span id="cb3-28">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb3-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Accuracy with Best Parameters: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}
Accuracy with Best Parameters: 1.0</code></pre>
</div>
</div>
<p>Using this technique, we can find the combination of hyperparameters that yields the best model performance.</p>
</section>
</section>
<section id="feature-importance-in-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="feature-importance-in-random-forest">Feature Importance in Random Forest</h2>
<p>One of the appealing aspects of Random Forest is that it provides a measure of <strong>feature importance</strong>, which indicates how much each feature contributes to the model’s predictions.</p>
<section id="computing-feature-importance" class="level3">
<h3 class="anchored" data-anchor-id="computing-feature-importance">Computing Feature Importance</h3>
<p>In Random Forest, feature importance is computed by measuring the <strong>average reduction in impurity</strong> (e.g., Gini impurity or MSE) brought by each feature across all trees. Features that lead to larger reductions are considered more important.</p>
<div id="a016f655" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb5-3"></span>
<span id="cb5-4">clf.fit(X_train,y_train)</span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get feature importance from the RandomForest model</span></span>
<span id="cb5-6">importances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.feature_importances_</span>
<span id="cb5-7">indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(importances)[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb5-8"></span>
<span id="cb5-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the feature importance</span></span>
<span id="cb5-10">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb5-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Feature Importance"</span>)</span>
<span id="cb5-12">plt.bar(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), importances[indices], align<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"center"</span>)</span>
<span id="cb5-13">plt.xticks(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), iris.feature_names, rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">90</span>)</span>
<span id="cb5-14">plt.tight_layout()</span>
<span id="cb5-15">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/randomforest/index_files/figure-html/cell-4-output-1.png" width="950" height="565" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The bar chart is showing the relative importance of each feature, making it easier to understand which features have the most predictive power.</p>
</section>
</section>
<section id="out-of-bag-oob-error-estimate" class="level2">
<h2 class="anchored" data-anchor-id="out-of-bag-oob-error-estimate">Out-of-Bag (OOB) Error Estimate</h2>
<p>Random Forest uses <strong>Out-of-Bag (OOB)</strong> samples as an alternative to cross-validation. Since each tree is trained on a bootstrap sample, about one-third of the data is left out in each iteration. These “out-of-bag” samples can be used to estimate the model’s performance without the need for a separate validation set.</p>
<section id="enabling-oob-in-python" class="level3">
<h3 class="anchored" data-anchor-id="enabling-oob-in-python">Enabling OOB in Python</h3>
<p>You can enable the out-of-bag error estimate by setting <code>oob_score=True</code> in the <code>RandomForestClassifier</code> or <code>RandomForestRegressor</code>.</p>
<div id="375201c1" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, oob_score<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb6-2">clf.fit(X_train, y_train)</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Access the OOB score</span></span>
<span id="cb6-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"OOB Score: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>clf<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>oob_score_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>OOB Score: 0.9428571428571428</code></pre>
</div>
</div>
<p>The OOB score is an unbiased estimate of the model’s performance, which is particularly useful when the dataset is small and splitting it further into training/validation sets might reduce training effectiveness.</p>
</section>
</section>
<section id="dealing-with-imbalanced-data" class="level2">
<h2 class="anchored" data-anchor-id="dealing-with-imbalanced-data">Dealing with Imbalanced Data</h2>
<p>For imbalanced classification tasks (where one class is much more frequent than the others), Random Forest may be biased toward predicting the majority class. Several techniques can help mitigate this issue:</p>
<ul>
<li><strong>Class Weights:</strong> You can assign higher weights to the minority class to force the model to pay more attention to it.</li>
</ul>
<div id="719a3580" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(class_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'balanced'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb8-2">clf.fit(X_train, y_train)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestClassifier(class_weight='balanced', random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(class_weight='balanced', random_state=42)</pre></div> </div></div></div></div>
</div>
</div>
<ul>
<li><strong>Resampling:</strong> You can either oversample the minority class or undersample the majority class.</li>
</ul>
<div id="8236042f" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> imblearn.over_sampling <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SMOTE</span>
<span id="cb9-2">sm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SMOTE(random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb9-3">X_resampled, y_resampled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.fit_resample(X_train, y_train)</span></code></pre></div>
</div>
</section>
<section id="random-forest-in-practice-best-practices" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-in-practice-best-practices">Random Forest in Practice: Best Practices</h2>
<ul>
<li><strong>Cross-Validation:</strong> Always perform cross-validation to ensure the model generalizes well</li>
<li><strong>Parallelization:</strong> Random Forest naturally supports parallelization. If using <code>scikit-learn</code>, set <code>n_jobs=-1</code> to utilize all CPU cores for training.<br>
</li>
<li><strong>Ensemble Methods:</strong> For better results, you can combine Random Forest with other ensemble methods, such as boosting (e.g., XGBoost or Gradient Boosting) to further improve performance.</li>
</ul>
<p>Random Forest is a highly flexible, non-parametric machine learning algorithm that can be used for both classification and regression tasks. Its ensemble-based approach reduces overfitting, improves predictive performance, and provides valuable insights like feature importance. Despite its many advantages, Random Forest is computationally intensive and may not be the best choice for real-time applications or datasets with extremely high dimensionality.</p>
<hr>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Breiman, L. (2001). “Random Forests”. Machine Learning, 45(1), 5-32.</li>
<li>Pedregosa, F., et al.&nbsp;(2011). “Scikit-learn: Machine Learning in Python”. Journal of Machine Learning Research, 12, 2825-2830.</li>
<li>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). “The Elements of Statistical Learning”. Springer Series in Statistics.</li>
</ol>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/randomforest/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/randomforest/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742008464950" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Ensemble {Methods:} {Random} {Forest} - {A} Detailed
    Overview},
  date = {2024-10-07},
  url = {https://mrislambd.github.io/posts/randomforest/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Ensemble Methods: Random Forest - A Detailed
Overview.”</span> October 7, 2024. <a href="https://mrislambd.github.io/posts/randomforest/">https://mrislambd.github.io/posts/randomforest/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/randomforest/</guid>
  <pubDate>Mon, 07 Oct 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/randomforest/gb.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Unsupervised Learning: K-Means Clustering</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/kmeans/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Clustering is a fundamental technique in unsupervised learning where the goal is to group similar data points into clusters. One of the most popular algorithms for clustering is <strong>K-Means</strong>. K-Means is a centroid-based algorithm that partitions the dataset into <img src="https://latex.codecogs.com/png.latex?k"> clusters. The algorithm iterates over data points, assigning each to one of <img src="https://latex.codecogs.com/png.latex?k"> centroids (cluster centers), and then updates the centroids based on the current assignments. The objective is to minimize the sum of squared distances (also known as inertia) between each data point and its assigned centroid.
</p>
</section>
<section id="mathematics-behind-k-means" class="level2">
<h2 class="anchored" data-anchor-id="mathematics-behind-k-means">Mathematics Behind K-Means</h2>
<p>The K-Means algorithm works through the following key steps:</p>
<ol type="1">
<li><p><strong>Initialization</strong>: Randomly select <img src="https://latex.codecogs.com/png.latex?k"> points from the dataset as initial centroids.</p></li>
<li><p><strong>Assignment Step</strong>: For each data point, assign it to the closest centroid based on the Euclidean distance:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bdistance%7D(x_i,%20%5Cmu_j)%20=%20%5Csqrt%7B%5Csum_%7Bd=1%7D%5E%7BD%7D%20(x_i%5Ed%20-%20%5Cmu_j%5Ed)%5E2%7D%0A"></p></li>
</ol>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?x_i"> is the i-th data point.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_j"> is the j-th centroid.</li>
<li><img src="https://latex.codecogs.com/png.latex?D"> is the number of features (dimensions).</li>
</ul>
<ol start="3" type="1">
<li><p><strong>Update Step</strong>: After all data points are assigned, recalculate the centroid of each cluster as the mean of all data points assigned to it:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_j%20=%20%5Cfrac%7B1%7D%7Bn_j%7D%20%5Csum_%7Bi=1%7D%5E%7Bn_j%7D%20x_i%0A"> where <img src="https://latex.codecogs.com/png.latex?n_j"> is the number of points in cluster <code>j</code>.</p></li>
<li><p><strong>Repeat</strong>: The assignment and update steps are repeated until the centroids no longer change or the maximum number of iterations is reached.</p></li>
</ol>
<section id="objective-function-inertia" class="level3">
<h3 class="anchored" data-anchor-id="objective-function-inertia">Objective Function (Inertia)</h3>
<p>The objective of K-Means is to minimize the following cost function, also called inertia or within-cluster sum of squares:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ%20=%20%5Csum_%7Bj=1%7D%5E%7Bk%7D%20%5Csum_%7Bi=1%7D%5E%7Bn_j%7D%20%5C%7Cx_i%20-%20%5Cmu_j%5C%7C%5E2%0A"></p>
<p>This measures how compact the clusters are, i.e., how close the points within each cluster are to their centroid.</p>
</section>
<section id="how-to-choose-the-best-k-value" class="level3">
<h3 class="anchored" data-anchor-id="how-to-choose-the-best-k-value">How to Choose the Best <img src="https://latex.codecogs.com/png.latex?k"> Value?</h3>
<p>One of the critical tasks in K-Means clustering is selecting the optimal number of clusters (<img src="https://latex.codecogs.com/png.latex?k">). Several methods can be used:</p>
<section id="the-elbow-method" class="level4">
<h4 class="anchored" data-anchor-id="the-elbow-method">1. The Elbow Method</h4>
<p>The most common way to determine the best <img src="https://latex.codecogs.com/png.latex?k"> is the <strong>elbow method</strong>. It involves plotting the inertia (the sum of squared distances from each point to its assigned cluster centroid) for different values of <img src="https://latex.codecogs.com/png.latex?k">. The point where the inertia starts to flatten out (forming an elbow) is considered a good choice for <img src="https://latex.codecogs.com/png.latex?k">.</p>
</section>
<section id="silhouette-score" class="level4">
<h4 class="anchored" data-anchor-id="silhouette-score">2. Silhouette Score</h4>
<p>The <strong>silhouette score</strong> measures how similar each point is to its own cluster (cohesion) compared to other clusters (separation). It ranges from -1 to 1:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?1"> indicates that the point is well inside its cluster.<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?0"> means the point is on the boundary between two clusters.<br>
</li>
<li>Negative values indicate the point may have been assigned to the wrong cluster.</li>
</ul>
</section>
<section id="gap-statistic" class="level4">
<h4 class="anchored" data-anchor-id="gap-statistic">3. Gap Statistic</h4>
<p>The <strong>gap statistic</strong> compares the total within-cluster variation for different values of <img src="https://latex.codecogs.com/png.latex?k"> with the expected value under null reference distribution. The optimal number of clusters is where the gap statistic is the largest.</p>
<hr>
</section>
</section>
</section>
<section id="python-implementation-of-k-means" class="level2">
<h2 class="anchored" data-anchor-id="python-implementation-of-k-means">Python Implementation of K-Means</h2>
<section id="synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data">Synthetic Data</h3>
<p>Let’s implement K-Means clustering using Python with visualizations and explore how to choose the best value of <img src="https://latex.codecogs.com/png.latex?k"> using the elbow method.</p>
<div id="ad8c2b69" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KMeans</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_blobs</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> silhouette_score</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For plotting purposes</span></span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-9">sns.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>()</span></code></pre></div>
</div>
<p>We’ll create a simple dataset with 4 distinct clusters for visualization.</p>
<div id="34ffc69f" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a dataset with 4 clusters</span></span>
<span id="cb2-2">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_blobs(n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, cluster_std<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.60</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize the dataset</span></span>
<span id="cb2-5">plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb2-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dataset with 4 Clusters'</span>)</span>
<span id="cb2-7">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb2-8">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb2-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-3-output-1.png" width="573" height="435" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can now apply K-Means clustering with different values of <img src="https://latex.codecogs.com/png.latex?k"> and observe how the clusters are formed.</p>
<div id="d0de3e2e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit KMeans with k=4 (since we know we generated 4 clusters)</span></span>
<span id="cb3-2">kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-3">kmeans.fit(X)</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict clusters</span></span>
<span id="cb3-6">y_kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.predict(X)</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the clustered data</span></span>
<span id="cb3-9">plt.scatter(X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_kmeans, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the centroids</span></span>
<span id="cb3-12">centers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.cluster_centers_</span>
<span id="cb3-13">plt.scatter(centers[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], centers[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>)</span>
<span id="cb3-14">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K-Means Clustering with k=4'</span>)</span>
<span id="cb3-15">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'kmeans.png'</span>)</span>
<span id="cb3-16">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb3-17">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-18">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-4-output-1.png" width="573" height="435" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>To determine the optimal number of clusters, we’ll plot the inertia for different values of <img src="https://latex.codecogs.com/png.latex?k"> using the elbow method.</p>
<div id="87e40b18" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Test multiple k values</span></span>
<span id="cb4-2">inertia <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-3">k_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> k_values:</span>
<span id="cb4-6">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>k)</span>
<span id="cb4-7">    kmeans.fit(X)</span>
<span id="cb4-8">    inertia.append(kmeans.inertia_)</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the inertia vs. k values</span></span>
<span id="cb4-11">plt.plot(k_values, inertia, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb4-12">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Elbow Method: Choosing the Optimal k'</span>)</span>
<span id="cb4-13">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of Clusters (k)'</span>)</span>
<span id="cb4-14">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Inertia'</span>)</span>
<span id="cb4-15">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb4-16">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb4-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-5-output-1.png" width="605" height="455" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We see that the curve starts to flatten at <img src="https://latex.codecogs.com/png.latex?k=4">, suggesting this is a good choice for the number of clusters. Let’s also compute the silhouette score for different values of <img src="https://latex.codecogs.com/png.latex?k"> to confirm our choice.</p>
<div id="d60807f9" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">sil_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb5-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb5-3">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>k)</span>
<span id="cb5-4">    kmeans.fit(X)</span>
<span id="cb5-5">    labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.predict(X)</span>
<span id="cb5-6">    sil_scores.append(silhouette_score(X, labels))</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot Silhouette Score vs. k</span></span>
<span id="cb5-9">plt.plot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), sil_scores, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb5-10">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Score for Different k Values'</span>)</span>
<span id="cb5-11">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of Clusters (k)'</span>)</span>
<span id="cb5-12">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhouette Score'</span>)</span>
<span id="cb5-13">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb5-14">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-15">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-6-output-1.png" width="601" height="455" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="real-data" class="level3">
<h3 class="anchored" data-anchor-id="real-data">Real Data</h3>
<strong>Description</strong>:<br>

<p style="text-align:justify">
This dataset contains information about customers of a shopping mall, including their annual income, spending score, gender, and age.
</p>
<p><strong>Goal:</strong> Our goal is to segment customers into different groups based on their spending behavior and income.</p>
<p><strong>Columns</strong>:<br>
- <code>CustomerID</code>: Unique identifier for each customer.<br>
- <code>Gender</code>: The gender of the customer (Male or Female).<br>
- <code>Age</code>: Age of the customer.<br>
- <code>Annual Income</code>: Annual income of the customer in thousands of dollars.<br>
- <code>Spending Score</code>: A score assigned by the mall based on customer behavior and spending patterns.</p>
<p><strong>Data Source:</strong> You can find the Mall Customer Segmentation data on <a href="https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python" style="text-decoration:none" target="_blank">Kaggle</a>.</p>
<div id="84872ebb" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd </span>
<span id="cb6-2">mall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mall_Customers.csv'</span>)</span>
<span id="cb6-3">mall.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CustomerID</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Annual Income (k$)</th>
<th data-quarto-table-cell-role="th">Spending Score (1-100)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Male</td>
<td>19</td>
<td>15</td>
<td>39</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Male</td>
<td>21</td>
<td>15</td>
<td>81</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Female</td>
<td>20</td>
<td>16</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Female</td>
<td>23</td>
<td>16</td>
<td>77</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Female</td>
<td>31</td>
<td>17</td>
<td>40</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="1d4f6fee" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data Information</span></span>
<span id="cb7-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mall.info())</span>
<span id="cb7-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check for Missing Data</span></span>
<span id="cb7-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mall.isnull().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>())</span>
<span id="cb7-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data Description</span></span>
<span id="cb7-8">mall.rename(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'CustomerID'</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Annual Income (k$)'</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Spending Score (1-100)'</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SpendingScore'</span>},inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-9">cmall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mall.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>,axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(cmall.describe().loc[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'std'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max'</span>]].T)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 200 entries, 0 to 199
Data columns (total 5 columns):
 #   Column                  Non-Null Count  Dtype 
---  ------                  --------------  ----- 
 0   CustomerID              200 non-null    int64 
 1   Gender                  200 non-null    object
 2   Age                     200 non-null    int64 
 3   Annual Income (k$)      200 non-null    int64 
 4   Spending Score (1-100)  200 non-null    int64 
dtypes: int64(4), object(1)
memory usage: 7.9+ KB
None


CustomerID                0
Gender                    0
Age                       0
Annual Income (k$)        0
Spending Score (1-100)    0
dtype: int64


                mean        std   min    max
Age            38.85  13.969007  18.0   70.0
Income         60.56  26.264721  15.0  137.0
SpendingScore  50.20  25.823522   1.0   99.0</code></pre>
</div>
</div>
<p><strong>Pre-Process:</strong> Since our data contains categorical variable <code>Gender</code>, we need to encode this column and scale the numerical features like <code>Age</code>, <code>Annual Income</code>, and <code>Spending Score</code>.</p>
<div id="de8e8742" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb9-2">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mall[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SpendingScore'</span>]]</span>
<span id="cb9-3">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb9-4">X_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X)</span>
<span id="cb9-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(X_scaled[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[-1.42456879 -1.73899919 -0.43480148]
 [-1.28103541 -1.73899919  1.19570407]
 [-1.3528021  -1.70082976 -1.71591298]
 [-1.13750203 -1.70082976  1.04041783]
 [-0.56336851 -1.66266033 -0.39597992]]</code></pre>
</div>
</div>
<p>Next we use the <code>Elbow</code> method to find the best <img src="https://latex.codecogs.com/png.latex?k">, the number of clusters</p>
<div id="af14b308" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">k_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb11-2">inertia <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb11-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> k_values:</span>
<span id="cb11-4">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>k, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb11-5">    kmeans.fit(X_scaled)</span>
<span id="cb11-6">    inertia.append(kmeans.inertia_)</span>
<span id="cb11-7">plt.plot(k_values,inertia, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb11-8">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Elbow method to find $k$'</span>)</span>
<span id="cb11-9">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of Clusters $k$'</span>)</span>
<span id="cb11-10">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Inertia'</span>)</span>
<span id="cb11-11">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb11-12">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb11-13">plt.show() </span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-10-output-1.png" width="597" height="455" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The elbow point in the plot (where the decrease in inertia starts to slow) helps determine the optimal number of clusters. Let’s say we find that <img src="https://latex.codecogs.com/png.latex?k=5"> looks like a reasonable choice from the plot.</p>
<p>To further validate the choice of <img src="https://latex.codecogs.com/png.latex?k">, let’s compute the <code>silhouette</code> score for different cluster numbers. A higher <code>silhouette</code> score indicates better-defined clusters</p>
<div id="96ff970e" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">sil_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb12-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>):</span>
<span id="cb12-3">    kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>k, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb12-4">    labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb12-5">    sil_scores.append(silhouette_score(X_scaled,labels))</span>
<span id="cb12-6">plt.plot(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>),sil_scores, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>)</span>
<span id="cb12-7">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhoutte method to find $k$'</span>)</span>
<span id="cb12-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of Clusters $k$'</span>)</span>
<span id="cb12-9">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Silhoutte Score'</span>)</span>
<span id="cb12-10">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb12-11">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb12-12">plt.show() </span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-11-output-1.png" width="601" height="455" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Next, we apply <img src="https://latex.codecogs.com/png.latex?k=5"> clusters</p>
<div id="92cd76bf" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb13-2">kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb13-3">mall[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cluster'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.fit_predict(X_scaled)</span>
<span id="cb13-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mall.head())</span>
<span id="cb13-5">sns.scatterplot(</span>
<span id="cb13-6">    x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SpendingScore'</span>, hue<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cluster'</span>,</span>
<span id="cb13-7">    data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mall, palette<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb13-8">    )</span>
<span id="cb13-9">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Customer Segmentation Based on Income and Spending Score'</span>)</span>
<span id="cb13-10">plt.legend()</span>
<span id="cb13-11">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb13-12">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb13-13">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   ID  Gender  Age  Income  SpendingScore  Cluster
0   1    Male   19      15             39        2
1   2    Male   21      15             81        2
2   3  Female   20      16              6        4
3   4  Female   23      16             77        2
4   5  Female   31      17             40        2</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-12-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://mrislambd.github.io/posts/kmeans/index_files/figure-html/cell-12-output-2.png" width="783" height="529" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Analyze the segments</p>
<div id="37f621cd" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">cluster_summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mall.drop(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gender'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>]).groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cluster'</span>).mean()</span>
<span id="cb15-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(cluster_summary)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Age     Income  SpendingScore
Cluster                                     
0        32.875000  86.100000      81.525000
1        55.638298  54.382979      48.851064
2        25.185185  41.092593      62.240741
3        39.871795  86.102564      19.358974
4        46.250000  26.750000      18.350000</code></pre>
</div>
</div>
<p>Now say we have two new customers</p>
<div id="9a36aabc" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">new_customer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">201</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">202</span>],<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gender'</span>:[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Male'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Female'</span>],<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>],<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>],<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SpendingScore'</span>:[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>]}</span>
<span id="cb17-2">new_customer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(new_customer)</span>
<span id="cb17-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(new_customer)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    ID  Gender  Age  Income  SpendingScore
0  201    Male   30      40             70
1  202  Female   50      70             20</code></pre>
</div>
</div>
<p>We would like to know in which cluster they belong.</p>
<div id="9f63d8cc" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">X_new <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_customer[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Income'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SpendingScore'</span>]]</span>
<span id="cb19-2">X_new_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(X_new)</span>
<span id="cb19-3">cluster_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.predict(X_new_sc)</span>
<span id="cb19-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(cluster_labels)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[2 3]</code></pre>
</div>
</div>
<p>K-Means is a powerful and widely used clustering algorithm, but it has limitations, such as assuming spherical clusters of equal sizes.</p>
<hr>
</section>
</section>
<section id="limitations-of-k-means-clustering" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-k-means-clustering">Limitations of K-Means Clustering</h2>
<p>While K-Means is a widely used clustering algorithm due to its simplicity and scalability, it has several notable limitations:</p>
<section id="assumption-of-spherical-clusters" class="level3">
<h3 class="anchored" data-anchor-id="assumption-of-spherical-clusters">1. <strong>Assumption of Spherical Clusters</strong></h3>
<p>K-Means assumes that clusters are spherical and have roughly the same size. This assumption may not hold true in real-world datasets, where clusters may have different shapes and densities. For example, if clusters are elongated or irregularly shaped, K-Means may not perform well.</p>
<ul>
<li><strong>Solution</strong>: Use algorithms like <strong>DBSCAN</strong> (Density-Based Spatial Clustering of Applications with Noise) or <strong>Spectral Clustering</strong>, which do not assume any specific shape for the clusters.</li>
</ul>
</section>
<section id="sensitivity-to-initialization" class="level3">
<h3 class="anchored" data-anchor-id="sensitivity-to-initialization">2. <strong>Sensitivity to Initialization</strong></h3>
<p>K-Means is sensitive to the initial selection of centroids. Different initializations can lead to different final clusters, and in some cases, the algorithm may converge to suboptimal solutions. To address this, the algorithm is often run multiple times with different initializations (e.g., using the <code>k-means++</code> initialization method).</p>
<ul>
<li><strong>Solution</strong>: Use the <code>k-means++</code> initialization, which ensures that centroids are chosen in a way that increases the likelihood of converging to an optimal solution.</li>
</ul>
</section>
<section id="needs-to-specify-k-in-advance" class="level3">
<h3 class="anchored" data-anchor-id="needs-to-specify-k-in-advance">3. <strong>Needs to Specify <code>k</code> in Advance</strong></h3>
<p>One of the main limitations is that K-Means requires the number of clusters (<code>k</code>) to be specified in advance. This can be a challenge when the number of clusters is unknown, and choosing the wrong <code>k</code> can lead to poor clustering results.</p>
<ul>
<li><strong>Solution</strong>: Use the <strong>Elbow Method</strong>, <strong>Silhouette Score</strong>, or the <strong>Gap Statistic</strong> to estimate the best value for <code>k</code>.</li>
</ul>
</section>
<section id="outliers-and-noise-sensitivity" class="level3">
<h3 class="anchored" data-anchor-id="outliers-and-noise-sensitivity">4. <strong>Outliers and Noise Sensitivity</strong></h3>
<p>K-Means is highly sensitive to outliers, as they can significantly affect the position of centroids. An outlier will either form its own cluster or distort the positions of nearby centroids, leading to incorrect clustering.</p>
<ul>
<li><strong>Solution</strong>: Preprocess your data by removing outliers or use clustering methods like <strong>DBSCAN</strong>, which can handle outliers more effectively by considering them as noise.</li>
</ul>
</section>
<section id="equal-cluster-size-assumption" class="level3">
<h3 class="anchored" data-anchor-id="equal-cluster-size-assumption">5. <strong>Equal Cluster Size Assumption</strong></h3>
<p>The algorithm tends to assign roughly equal-sized clusters because it minimizes variance. This can be a problem if clusters in your data have highly varying sizes. Small clusters might be absorbed into larger ones.</p>
<ul>
<li><strong>Solution</strong>: Use <strong>Hierarchical Clustering</strong>, which can naturally handle different cluster sizes.</li>
</ul>
</section>
<section id="non-convex-shapes" class="level3">
<h3 class="anchored" data-anchor-id="non-convex-shapes">6. <strong>Non-Convex Shapes</strong></h3>
<p>K-Means struggles with data where clusters have non-convex shapes, such as two overlapping rings or crescent shapes. It partitions the space into Voronoi cells, which are convex, leading to poor clustering results in non-convex structures.</p>
<ul>
<li><strong>Solution</strong>: Algorithms like <strong>Spectral Clustering</strong> or <strong>Gaussian Mixture Models (GMM)</strong> can better handle non-convex clusters.</li>
</ul>
<hr>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>K-Means Algorithm</strong>:
<ul>
<li>MacQueen, J. B. (1967). “Some Methods for Classification and Analysis of Multivariate Observations”. Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics.</li>
<li>Hartigan, J. A., &amp; Wong, M. A. (1979). “Algorithm AS 136: A K-means clustering algorithm”. Journal of the Royal Statistical Society. Series C (Applied Statistics), 28(1), 100-108.</li>
</ul></li>
<li><strong>Choosing <code>k</code> (Elbow Method &amp; Silhouette Score)</strong>:
<ul>
<li>Rousseeuw, P. J. (1987). “Silhouettes: A graphical aid to the interpretation and validation of cluster analysis”. Journal of Computational and Applied Mathematics, 20, 53-65.</li>
</ul></li>
<li><strong>Inertia and the Elbow Method</strong>:
<ul>
<li>Tibshirani, R., Walther, G., &amp; Hastie, T. (2001). “Estimating the number of clusters in a dataset via the gap statistic”. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(2), 411-423.</li>
</ul></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/kmeans/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/kmeans/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Unsupervised {Learning:} {K-Means} {Clustering}},
  date = {2024-09-28},
  url = {https://mrislambd.github.io/posts/kmeans/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Unsupervised Learning: K-Means
Clustering.”</span> September 28, 2024. <a href="https://mrislambd.github.io/posts/kmeans/">https://mrislambd.github.io/posts/kmeans/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/kmeans/</guid>
  <pubDate>Sat, 28 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/kmeans/kmeans.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Dimensionality Reduction: Principle Component Analysis (PCA)</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/pca/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align:justify">
Principal Component Analysis (PCA) is a powerful technique used in machine learning and statistics for <strong>unsupervised dimensionality reduction</strong>. It transforms high-dimensional data into a lower-dimensional form while preserving the most important features or “components” of the data. This is particularly useful when dealing with large datasets that are difficult to visualize or computationally expensive to process.<br> <br> For example, if we have a dataset that contains a lot of images of 20x20 pixels and we convert the images to one dimensional vectors then there are total 400 features which makes the analysis harder. PCA finds a low (best <img src="https://latex.codecogs.com/png.latex?d">) dimensional subspace approximation that minimizes the least square error
</p>
<hr>
</section>
<section id="what-is-principal-component-analysis-pca" class="level2">
<h2 class="anchored" data-anchor-id="what-is-principal-component-analysis-pca">What is Principal Component Analysis (PCA)?</h2>
<p>Let’s start from the beginning. If we have a set of orthogonal basis vectors say <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D=(u_1,u_2,%5Cdots,%20u_p)"> then <img src="https://latex.codecogs.com/png.latex?u_i%5ETu_j=%5Cdelta_%7Bij%7D"> for <img src="https://latex.codecogs.com/png.latex?1%5Cle%20i,j%20%5Cle%20m">. For example, consider <img src="https://latex.codecogs.com/png.latex?u_1=%5Cbegin%7Bbmatrix%7D1%5C%5C%200%5Cend%7Bbmatrix%7D"> and <img src="https://latex.codecogs.com/png.latex?u_2=%5Cbegin%7Bbmatrix%7D0%5C%5C1%5Cend%7Bbmatrix%7D"></p>
<div id="90aa792d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb1-5">ax.set_xlim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-6">ax.set_ylim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-7">ax.axhline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-8">ax.axvline(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-9">ax.quiver(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, scale_units<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xy'</span>, angles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xy'</span>)</span>
<span id="cb1-10">ax.quiver(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, scale_units<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xy'</span>, angles<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xy'</span>)</span>
<span id="cb1-11">ax.text(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$u_1$'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-12">ax.text(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$u_2$'</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb1-13">ax.set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb1-14">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-15">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb1-16">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-17">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/pca/index_files/figure-html/cell-2-output-1.png" width="441" height="416" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Au_1%5ETu_2%20&amp;%20=%20%5Cbegin%7Bbmatrix%7D1%20&amp;%200%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D0%5C%5C1%5Cend%7Bbmatrix%7D%20=%200%20%5Chspace%7B4mm%7D%5Ctext%7Band%7D%5Chspace%7B4mm%7D%20u_2%5ETu_1%20=%20%5Cbegin%7Bbmatrix%7D0%20&amp;%201%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D1%20%5C%5C%200%5Cend%7Bbmatrix%7D=0%5C%5C%0Au_1%5ETu_1%20&amp;%20=%20%5Cbegin%7Bbmatrix%7D1%20&amp;%200%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D1%5C%5C0%5Cend%7Bbmatrix%7D%20=%201%20%5Chspace%7B4mm%7D%5Ctext%7Band%7D%5Chspace%7B4mm%7D%20u_2%5ETu_2%20=%20%5Cbegin%7Bbmatrix%7D0%20&amp;%201%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D0%20%5C%5C%201%5Cend%7Bbmatrix%7D=1%0A%5Cend%7Balign*%7D"></p>
<p>Now suppose we have a data set <img src="https://latex.codecogs.com/png.latex?X"> with columns are features and <img src="https://latex.codecogs.com/png.latex?k">th observation <img src="https://latex.codecogs.com/png.latex?x%5E%7B(k)%7D=(x_1%5E%7B(k)%7D,x_2%5E%7B(k)%7D,%5Cdots,x_p%5E%7B(k)%7D)%5ET">. Now let <img src="https://latex.codecogs.com/png.latex?%5Cmu=%5Cbar%7Bx%7D=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bk=1%7D%5E%7Bn%7Dx%5Ek">, that is for <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AX%20&amp;%20=%20%5Cbegin%7Bbmatrix%7Dx_%7B11%7D&amp;x_%7B12%7D&amp;%5Cdots%20x_%7B1p%7D%20%5C%5Cx_%7B21%7D&amp;x_%7B22%7D&amp;%5Cdots%20x_%7B2p%7D%20%5C%5C%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%5Cddots%20%5Cvdots%20%5C%5Cx_%7Bn1%7D&amp;x_%7Bn2%7D&amp;%5Cdots%20x_%7Bnp%7D%20%5Cend%7Bbmatrix%7D%5C%5C%0A%5Cmu_j%20&amp;=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_%7Bij%7D%5C%5C%0A%5Cmu%20&amp;%20=%5Cbegin%7Bbmatrix%7D%5Cmu_1%5C%5C%20%5Cmu_2%20%5C%5C%20%5Cvdots%5C%5C%20%5Cmu_p%5Cend%7Bbmatrix%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20X%5Ei%0A%5Cend%7Balign*%7D"></p>
<p>Now with the orthogonal vectors, we can write <img src="https://latex.codecogs.com/png.latex?%20x%5Ek-%5Cmu%20=%20%5Csum_%7Bi=1%7D%5E%7Bp%7D%5Cleft%5B(x%5Ek-%5Cmu)%5Ccdot%20u_i%5Cright%5Du_i%20=%20%5Csum_%7Bi=1%7D%5E%7Bp%7D%20a_i%5Ek%20u_i"></p>
<p>In PCA, we aim to find <img src="https://latex.codecogs.com/png.latex?(u_1,u_2,%5Cdots,%20u_d)"> that minimizes the reconstruction error, defined as the squared distance between each data point <img src="https://latex.codecogs.com/png.latex?x%5Ek"> and its projection onto the subspace spanned by the top <img src="https://latex.codecogs.com/png.latex?d"> principle components: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BE%7D(u_1,u_2,%5Cdots,%20u_d)=%5Csum_%7Bk=1%7D%5E%7Bn%7D%5Cleft%5C%7Cx%5Ek%20-%5Cleft(%5Cmu+%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Ek%20u_i%5Cright)%5Cright%5C%7C%5E2"></p>
<p>Here <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Eku_i"> is the projection of <img src="https://latex.codecogs.com/png.latex?x%5Ek"> onto the subspace spanned by the top <img src="https://latex.codecogs.com/png.latex?d"> dimensional components. The term inside the norm, <img src="https://latex.codecogs.com/png.latex?x%5Ek%20-%5Cleft(%5Cmu+%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Ek%20u_i%5Cright)">, represents the residual error after projecting <img src="https://latex.codecogs.com/png.latex?x%5Ek"> onto this subspace. The goal is to minimize this error.</p>
<p>The residual variance corresponds to the directions (or principal components) <strong>not</strong> captured by the top <img src="https://latex.codecogs.com/png.latex?d"> principal components. Specifically, these are the components corresponding to <img src="https://latex.codecogs.com/png.latex?u_%7Bd+1%7D,%20%5Cdots,%20u_p">, where <img src="https://latex.codecogs.com/png.latex?p"> is the total number of features (or components).</p>
<p>Now, the norm inside the error function can be decomposed as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax%5Ek%20-%20%5Cleft(%20%5Cbar%7Bx%7D%20+%20%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Ek%20u_i%20%5Cright)%20=%20%5Cleft(%20x%5Ek%20-%20%5Cbar%7Bx%7D%20%5Cright)%20-%20%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Ek%20u_i%0A"></p>
<p>We define <img src="https://latex.codecogs.com/png.latex?z%5Ek%20=%20x%5Ek%20-%20%5Cbar%7Bx%7D">, so the error becomes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE(u_1,%20%5Cdots,%20u_d)%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%20%5Cleft%5C%7C%20z%5Ek%20-%20%5Csum_%7Bi=1%7D%5E%7Bd%7D%20a_i%5Ek%20u_i%20%5Cright%5C%7C%5E2%0A"></p>
<p>The key idea here is that <img src="https://latex.codecogs.com/png.latex?z%5Ek"> is a vector in the original <img src="https://latex.codecogs.com/png.latex?p">-dimensional space, and we are approximating it by projecting it onto the top <img src="https://latex.codecogs.com/png.latex?d">-dimensional subspace spanned by <img src="https://latex.codecogs.com/png.latex?u_1,%20%5Cdots,%20u_d">.</p>
<p>Since <img src="https://latex.codecogs.com/png.latex?u_1,%20%5Cdots,%20u_p"> form an orthogonal basis, <img src="https://latex.codecogs.com/png.latex?z%5Ek"> can be completely expressed in terms of all the basis vectors <img src="https://latex.codecogs.com/png.latex?u_1,%20%5Cdots,%20u_p">. In particular:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%5Ek%20=%20%5Csum_%7Bi=1%7D%5E%7Bp%7D%20a_i%5Ek%20u_i%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_i%5Ek%20=%20z%5Ek%20%5Ccdot%20u_i"> are the projections of <img src="https://latex.codecogs.com/png.latex?z%5Ek"> onto each basis vector <img src="https://latex.codecogs.com/png.latex?u_i">. Therefore, the reconstruction error <img src="https://latex.codecogs.com/png.latex?E(u_1,%20%5Cdots,%20u_d)"> is the squared norm of the residual part of <img src="https://latex.codecogs.com/png.latex?z%5Ek"> that is <strong>not captured</strong> by the top <img src="https://latex.codecogs.com/png.latex?d"> principal components:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE(u_1,%20%5Cdots,%20u_d)%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%20%5Csum_%7Bi=d+1%7D%5E%7BM%7D%20(a_i%5Ek)%5E2%0A"></p>
<p>This means that the error comes from the projection of <img src="https://latex.codecogs.com/png.latex?z%5Ek"> onto the remaining <img src="https://latex.codecogs.com/png.latex?p-d"> principal components, i.e., <img src="https://latex.codecogs.com/png.latex?u_%7Bd+1%7D,%20%5Cdots,%20u_p">. Thus,</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AE(%5Cmathbf%7Bu%7D)%20&amp;%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%20%5Cleft%5C%7C%5Csum_%7Bi=d+1%7D%5E%7Bp%7D(z%5Ek%5Ccdot%20u_i)u_i%5Cright%5C%7C%5E2%5C%5C%0A&amp;%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20%5Cleft(z%5Ek%5Ccdot%20u_i%5Cright)%5E2%0A%5Cend%7Balign*%7D"></p>
<p>We start with the dot product <img src="https://latex.codecogs.com/png.latex?z%5Ek%20%5Ccdot%20u_i">, which is just a scalar:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%5Ek%20%5Ccdot%20u_i%20=%20(z%5Ek)%5ET%20u_i%0A"></p>
<p>This is simply the sum of the element-wise products of <img src="https://latex.codecogs.com/png.latex?z%5Ek"> and <img src="https://latex.codecogs.com/png.latex?u_i">: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0Az%5Ek%20%5Ccdot%20u_i%20&amp;=%20%5Csum_%7Bj=1%7D%5E%7BM%7D%20z_j%5Ek%20u_%7Bij%7D%5C%5C%0A%5Cimplies%20(z%5Ek%20%5Ccdot%20u_i)%5E2%20&amp;=%20%5Cleft(%20%5Csum_%7Bj=1%7D%5E%7BM%7D%20z_j%5Ek%20u_%7Bij%7D%20%5Cright)%5E2%0A%5Cimplies%20%5Cleft(%20%5Csum_%7Bj=1%7D%5E%7BM%7D%20z_j%5Ek%20u_%7Bij%7D%20%5Cright)%5E2%20&amp;=%20%5Csum_%7Bj=1%7D%5E%7BM%7D%20%5Csum_%7Bl=1%7D%5E%7BM%7D%20z_j%5Ek%20z_l%5Ek%20u_%7Bij%7D%20u_%7Bil%7D%0A%5Cend%7Balign*%7D"></p>
<p>Notice that we can rewrite the product <img src="https://latex.codecogs.com/png.latex?z_j%5Ek%20z_l%5Ek"> as an <strong>outer product</strong> of the vector <img src="https://latex.codecogs.com/png.latex?z%5Ek"> with itself:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%5Ek%20z%5E%7BkT%7D%0A"></p>
<p>The outer product <img src="https://latex.codecogs.com/png.latex?z%5Ek%20z%5E%7BkT%7D"> is a matrix, specifically an <img src="https://latex.codecogs.com/png.latex?p%20%5Ctimes%20p"> matrix. Each element of this matrix at position <img src="https://latex.codecogs.com/png.latex?(j,%20l)"> is <img src="https://latex.codecogs.com/png.latex?z_j%5Ek%20z_l%5Ek">, exactly what we have in the double sum.</p>
<p>So, instead of writing out all the sums explicitly, we can represent the whole thing as a matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(z%5Ek%20%5Ccdot%20u_i)%5E2%20=%20u_i%5ET%20(z%5Ek%20z%5E%7BkT%7D)%20u_i%0A"></p>
<p>This is called a <strong>quadratic form</strong>. So,</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0AE(%5Cmathbf%7Bu%7D)%20&amp;%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%20%5Cleft%5C%7C%5Csum_%7Bi=d+1%7D%5E%7Bp%7D(z%5Ek%5Ccdot%20u_i)u_i%5Cright%5C%7C%5E2%5C%5C%0A&amp;%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20%5Cleft(z%5Ek%5Ccdot%20u_i%5Cright)%5E2%20%5C%5C%0A&amp;%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20u_i%5ETz%5Ekz%5E%7BkT%7Du_i%20%5C%5C%0A&amp;%20=%20%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20u_i%5ET%5CSigma%20u_i%20%5C%5C%0A%5Cend%7Balign*%7D"></p>
<p>where,</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5CSigma%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D(x%5Ek-%5Cmu)(x%5Ek-%5Cmu)%5ET=X%5ETX"><br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?X=(x%5E1-%5Cmu,%20x%5E2-%5Cmu,%5Cdots,x%5Ep-%5Cmu)%5ET"></li>
</ul>
<p>So now we have <img src="https://latex.codecogs.com/png.latex?E(%5Cmathbf%7Bu%7D)=%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20u_i%5ET%5CSigma%20u_i%20"></p>
<p>and <img src="https://latex.codecogs.com/png.latex?E(%5Cmathbf%7Bu%7D)"> is minimized when <img src="https://latex.codecogs.com/png.latex?u_i">’s are the eigenvectors of <img src="https://latex.codecogs.com/png.latex?%5CSigma">. Then</p>
<p><img src="https://latex.codecogs.com/png.latex?E(%5Cmathbf%7Bu%7D)=%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20u_i%5ET%5Clambda_i%20u_i%20=%5Csum_%7Bi=d+1%7D%5E%7Bp%7D%20%5Clambda_i%20"></p>
<p>and we get our desired <img src="https://latex.codecogs.com/png.latex?u_%7Bd+1%7D,%5Cdots,%20u_%7Bp%7D"> components that minimizes the projection error. So if we take the first <img src="https://latex.codecogs.com/png.latex?d"> of these correspond to the <img src="https://latex.codecogs.com/png.latex?d">-largest eigenvalues we get the principle components.</p>
<p><strong>Long story short</strong></p>
<ul>
<li>We have <img src="https://latex.codecogs.com/png.latex?n"> data points with <img src="https://latex.codecogs.com/png.latex?p"> column vectors <img src="https://latex.codecogs.com/png.latex?x%5E1,x%5E2,%5Cdots,x%5Ep"><br>
</li>
<li>We compute the mean <img src="https://latex.codecogs.com/png.latex?%5Cmu=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bk=1%7D%5E%7Bn%7Dx%5Ek"><br>
</li>
<li>Then we compute the matrix <img src="https://latex.codecogs.com/png.latex?X=(x%5E1-%5Cmu,%20x%5E2-%5Cmu,%5Cdots,x%5Ep-%5Cmu)%5ET"><br>
</li>
<li>Next, compute the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5CSigma%20=%20%5Csum_%7Bk=1%7D%5E%7Bn%7D(x%5Ek-%5Cmu)(x%5Ek-%5Cmu)%5ET=X%5ETX"> and short them in decreasing order<br>
</li>
<li>Choose <img src="https://latex.codecogs.com/png.latex?d">, the number of principle components</li>
<li>Then we get the principle components <img src="https://latex.codecogs.com/png.latex?P=%5Bv_1,v_2,%5Cdots,%20v_d%5D_%7Bp%5Ctimes%20d%7D"><br>
</li>
<li>To project any column vector <img src="https://latex.codecogs.com/png.latex?z">, we compute <img src="https://latex.codecogs.com/png.latex?projection(z)=P%5ET(z-%5Cmu)"></li>
</ul>
<hr>
</section>
<section id="benefits-of-pca" class="level2">
<h2 class="anchored" data-anchor-id="benefits-of-pca">Benefits of PCA</h2>
<ul>
<li><strong>Dimensionality Reduction</strong>: PCA can reduce the number of variables, which speeds up algorithms and makes models more interpretable.</li>
<li><strong>Visualization</strong>: PCA is often used to project high-dimensional data into 2D or 3D for visualization.</li>
<li><strong>Noise Reduction</strong>: By focusing on the principal components, PCA can eliminate irrelevant noise in the data.</li>
<li><strong>Avoid Multicollinearity</strong>: PCA removes multicollinearity by creating uncorrelated principal components.</li>
</ul>
<hr>
</section>
<section id="limitations-of-pca" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-pca">Limitations of PCA</h2>
<ul>
<li><strong>Linear Assumption</strong>: PCA assumes linear relationships between features. Non-linear patterns in data are not captured well by PCA.</li>
<li><strong>Interpretability</strong>: While PCA can simplify data, the new components may not be easily interpretable.</li>
<li><strong>Loss of Information</strong>: Reducing dimensions might result in the loss of some information or variance, depending on how many components are retained.</li>
</ul>
<hr>
</section>
<section id="pca-in-python-implementation-and-visualization" class="level2">
<h2 class="anchored" data-anchor-id="pca-in-python-implementation-and-visualization">PCA in Python: Implementation and Visualization</h2>
<p>Now that we understand the theory behind PCA, let’s implement it in Python using the <code>sklearn</code> library and visualize the results.</p>
<div id="b649d0ea" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span></code></pre></div>
</div>
<p>For this example, we will use the famous Iris dataset, which contains 4 features (sepal length, sepal width, petal length, and petal width) of 3 species of iris flowers.</p>
<div id="18ff973d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the Iris dataset</span></span>
<span id="cb3-2">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb3-3">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.data</span>
<span id="cb3-4">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Standardize the data</span></span>
<span id="cb3-7">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-8">X_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X)</span></code></pre></div>
</div>
<p>We will reduce the data from 4 dimensions to 2 for visualization.</p>
<div id="b3721306" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb4-2">X_pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Explained Variance Ratio: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Explained Variance Ratio: [0.72962445 0.22850762]</code></pre>
</div>
</div>
<p>The explained variance ratio shows how much variance each principal component captures. In many cases, the first two components capture most of the variance.</p>
<p>Let’s plot the Iris dataset using the first two principal components.</p>
<div id="1e846b61" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb6-2">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]</span>
<span id="cb6-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, color <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(colors):</span>
<span id="cb6-4">    plt.scatter(X_pca[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], X_pca[y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names[i], color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>color)</span>
<span id="cb6-5"></span>
<span id="cb6-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PCA of Iris Dataset'</span>)</span>
<span id="cb6-7">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Principal Component 1'</span>)</span>
<span id="cb6-8">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Principal Component 2'</span>)</span>
<span id="cb6-9">plt.legend()</span>
<span id="cb6-10">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-11">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca.png'</span>)</span>
<span id="cb6-12">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb6-13">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb6-14">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/pca/index_files/figure-html/cell-6-output-1.png" width="662" height="523" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The plot shows the data projected onto the first two principal components. We can observe how the three species cluster in the reduced 2D space. This visualization helps us see the separability of the classes using only two dimensions, instead of four.</p>
<hr>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references"><strong>References</strong></h3>
<ol type="1">
<li><strong>Jolliffe, I. T.</strong> (2002). <em>Principal Component Analysis</em>. Springer Series in Statistics.
<ul>
<li>The seminal book on PCA, providing an in-depth theoretical background.</li>
</ul></li>
<li><strong>Shlens, J.</strong> (2014). A tutorial on principal component analysis. <em>arXiv preprint arXiv:1404.1100</em>.
<ul>
<li>An excellent tutorial that breaks down PCA concepts with clear mathematical derivations.</li>
</ul></li>
<li><strong>Bishop, C. M.</strong> (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.
<ul>
<li>This book offers a comprehensive guide to PCA and other machine learning techniques.</li>
</ul></li>
<li><strong>Hastie, T., Tibshirani, R., &amp; Friedman, J.</strong> (2009). <em>The Elements of Statistical Learning</em>. Springer.
<ul>
<li>Covers PCA as well as a variety of other machine learning and statistical techniques.</li>
</ul></li>
<li><strong>Géron, A.</strong> (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. O’Reilly Media.
<ul>
<li>A practical guide with hands-on code examples, including PCA implementation in Python.</li>
</ul></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/pca/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/pca/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742008464950" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Dimensionality {Reduction:} {Principle} {Component}
    {Analysis} {(PCA)}},
  date = {2024-09-24},
  url = {https://mrislambd.github.io/posts/pca/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Dimensionality Reduction: Principle Component
Analysis (PCA).”</span> September 24, 2024. <a href="https://mrislambd.github.io/posts/pca/">https://mrislambd.github.io/posts/pca/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/pca/</guid>
  <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/pca/pca.png" medium="image" type="image/png" height="108" width="144"/>
</item>
<item>
  <title>Model Fine Tuning: Regularization</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/regularization/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align:justify">
Regularization is a key concept in machine learning that helps prevent overfitting, improve model generalization, and make models more robust to new data. It adds a penalty to the loss function to discourage the model from fitting the noise in the training data, which leads to <strong>overfitting</strong>.
</p>
<ul>
<li><p><strong>Overfitting</strong> occurs when a model performs well on the training data but fails to generalize to new, unseen data. This happens when the model is too complex and captures both the signal and the noise in the data.</p></li>
<li><p><strong>Underfitting</strong>, on the other hand, happens when a model is too simple to capture the underlying patterns in the data, resulting in poor performance even on the training set.</p></li>
</ul>
<p style="text-align:justify">
Regularization helps strike a balance between overfitting and underfitting by controlling model complexity and encouraging simpler models that generalize better.
</p>
</section>
<section id="types-of-regularization" class="level2">
<h2 class="anchored" data-anchor-id="types-of-regularization">Types of Regularization</h2>
<p>There are several types of regularization techniques used in machine learning, with the most common being:</p>
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?L_2"> Regularization (Ridge Regression)</strong></li>
<li><strong><img src="https://latex.codecogs.com/png.latex?L_1"> Regularization (Lasso Regression)</strong></li>
<li><strong>Elastic Net Regularization</strong></li>
<li><strong>Dropout (for neural networks)</strong></li>
</ul>
<p>Here we will discus the first two kind only.</p>
<hr>
</section>
<section id="l_2-regularization-ridge-regression" class="level2">
<h2 class="anchored" data-anchor-id="l_2-regularization-ridge-regression"><img src="https://latex.codecogs.com/png.latex?L_2"> Regularization (Ridge Regression)</h2>
<p style="text-align: justify">
<strong><img src="https://latex.codecogs.com/png.latex?L_2"> regularization</strong> (also known as <strong>Ridge regression</strong> in linear models) adds a penalty term to the loss function proportional to the sum of the squared coefficients (weights) of the model. The goal is to minimize both the original loss function and the magnitude of the coefficients.
</p>
<p>For a linear regression model, the objective is to minimize the following regularized loss function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Ctheta)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By_i%7D)%5E2%20+%20%5Clambda%20%5Csum_%7Bj=1%7D%5E%7Bp%7D%20%5Ctheta_j%5E2%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7By_i%7D"> is the model’s predicted output for input <img src="https://latex.codecogs.com/png.latex?x_i">.</li>
<li><img src="https://latex.codecogs.com/png.latex?y_i"> is the true target value.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctheta_j"> are the model parameters (coefficients).</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda"> is the regularization strength, controlling the magnitude of the penalty (higher <img src="https://latex.codecogs.com/png.latex?%5Clambda"> increases regularization).</li>
</ul>
<p><strong>More about <img src="https://latex.codecogs.com/png.latex?%5Clambda"></strong></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda"> is a continuous non-negative scaler value, typically a floating-point number.<br>
</li>
<li>Minimum <img src="https://latex.codecogs.com/png.latex?%5Clambda=0">, model becomes the standard linear regression model. For smaller <img src="https://latex.codecogs.com/png.latex?%5Clambda"> the regularization effect is minimal, allowing the model to fit the training data more closely.</li>
<li>In theory, there is no upper bound for <img src="https://latex.codecogs.com/png.latex?%5Clambda">. However, as <img src="https://latex.codecogs.com/png.latex?%5Clambda"> increases, the model becomes more regularized, and the coefficients tend to shrink toward zero.</li>
</ul>
<p style="text-align:justify">
Selecting the optimal value of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is crucial. Typically, it’s done via cross-validation, where different values of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> are tried, and the model is evaluated based on its performance on the validation set. The value that results in the best generalization is selected.
</p>
<p><img src="https://latex.codecogs.com/png.latex?L_2"> regularization shrinks the coefficients towards zero but doesn’t force them to be exactly zero, thus retaining all features in the model.</p>
<div id="889229c1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Ridge,LinearRegression</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic data</span></span>
<span id="cb1-9">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-10">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-11">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split the data into training and test sets</span></span>
<span id="cb1-14">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LinearRegression model </span></span>
<span id="cb1-17">linear_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb1-18">linear_model.fit(X_train,y_train)</span>
<span id="cb1-19">y_pred_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> linear_model.predict(X_test)</span>
<span id="cb1-20">mse_linear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_linear)</span>
<span id="cb1-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error (Linear Regression): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse_linear<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb1-22"></span>
<span id="cb1-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train Ridge regression model (L2 Regularization)</span></span>
<span id="cb1-24">sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb1-25">X_train_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sc.fit_transform(X_train)</span>
<span id="cb1-26">X_test_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sc.transform(X_test)</span>
<span id="cb1-27">ridge_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Ridge(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># alpha is the regularization strength (lambda)</span></span>
<span id="cb1-28">ridge_model.fit(X_train_sc, y_train)</span>
<span id="cb1-29"></span>
<span id="cb1-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions and evaluation</span></span>
<span id="cb1-31">y_pred_ridge <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ridge_model.predict(X_test_sc)</span>
<span id="cb1-32">mse_ridge <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_ridge)</span>
<span id="cb1-33"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error (Ridge Regression): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse_ridge<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb1-34"></span>
<span id="cb1-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the results</span></span>
<span id="cb1-36">plt.scatter(X_test, y_test, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'True Data'</span>)</span>
<span id="cb1-37">plt.plot(X_test, y_pred_linear, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Prediction'</span>)</span>
<span id="cb1-38">plt.plot(X_test, y_pred_ridge, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ridge Prediction'</span>)</span>
<span id="cb1-39">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>)</span>
<span id="cb1-40">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb1-41">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ridge Regularization'</span>)</span>
<span id="cb1-42">plt.legend()</span>
<span id="cb1-43">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb1-44">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-45">plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rg.png'</span>)</span>
<span id="cb1-46">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error (Linear Regression): 0.92
Mean Squared Error (Ridge Regression): 0.92</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/regularization/index_files/figure-html/cell-2-output-2.png" width="588" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>In this example, <code>alpha</code> corresponds to <img src="https://latex.codecogs.com/png.latex?%5Clambda">, the regularization strength. A higher value of <code>alpha</code> will result in stronger regularization, shrinking the model coefficients more.</p>
<hr>
</section>
<section id="l_1-regularization-lasso-regression" class="level2">
<h2 class="anchored" data-anchor-id="l_1-regularization-lasso-regression"><img src="https://latex.codecogs.com/png.latex?L_1"> Regularization (Lasso Regression)</h2>
<p><strong><img src="https://latex.codecogs.com/png.latex?L_1"> regularization</strong> (also known as <strong>Lasso regression</strong>) adds a penalty term proportional to the sum of the absolute values of the coefficients. This type of regularization can force some coefficients to be exactly zero, effectively performing feature selection.</p>
<p>The objective function for L1 regularization is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Ctheta)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By_i%7D)%5E2%20+%20%5Clambda%20%5Csum_%7Bj=1%7D%5E%7Bp%7D%20%7C%5Ctheta_j%7C%0A"></p>
<p>Where:</p>
<ul>
<li>The terms are the same as those for <img src="https://latex.codecogs.com/png.latex?L_2"> regularization.</li>
<li>The penalty is the absolute value of the coefficients instead of the squared value.</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?L_1"> regularization has the effect of making some coefficients exactly zero, which means it can be used to reduce the number of features in the model.</p>
<div id="e2fc15c0" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Lasso</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error (Linear Regression): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse_linear<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train Lasso regression model (L1 Regularization)</span></span>
<span id="cb3-6">lasso_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Lasso(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.5</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># alpha is the regularization strength (lambda)</span></span>
<span id="cb3-7">lasso_model.fit(X_train_sc, y_train)</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predictions and evaluation</span></span>
<span id="cb3-10">y_pred_lasso <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lasso_model.predict(X_test_sc)</span>
<span id="cb3-11">mse_lasso <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y_test, y_pred_lasso)</span>
<span id="cb3-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error (Lasso Regression): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse_lasso<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-13"></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the results</span></span>
<span id="cb3-15">plt.scatter(X_test, y_test, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data'</span>)</span>
<span id="cb3-16">plt.plot(X_test, y_pred_linear, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Linear Prediction'</span>)</span>
<span id="cb3-17">plt.plot(X_test, y_pred_lasso, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Lasso Prediction'</span>)</span>
<span id="cb3-18">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>)</span>
<span id="cb3-19">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb3-20">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Lasso Regularization'</span>)</span>
<span id="cb3-21">plt.legend()</span>
<span id="cb3-22">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb3-23">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-24">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error (Linear Regression): 0.92
Mean Squared Error (Lasso Regression): 1.02</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/regularization/index_files/figure-html/cell-3-output-2.png" width="588" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="choosing-the-right-lambda" class="level3">
<h3 class="anchored" data-anchor-id="choosing-the-right-lambda">Choosing the Right <img src="https://latex.codecogs.com/png.latex?%5Clambda"></h3>
<p>Selecting the optimal value of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is crucial. Typically, it’s done via cross-validation, where different values of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> are tried, and the model is evaluated based on its performance on the validation set. The value that results in the best generalization is selected.</p>
</section>
<section id="impact-of-lambda-on-bias-variance-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-lambda-on-bias-variance-trade-off">Impact of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> on Bias-Variance Trade-off</h3>
<ul>
<li>Low <img src="https://latex.codecogs.com/png.latex?%5Clambda">: Leads to a low bias and high variance model because the model closely fits the training data.</li>
<li>High <img src="https://latex.codecogs.com/png.latex?%5Clambda">: Leads to a high bias and low variance model, as the regularization prevents the model from fitting the training data too closely, reducing the variance but increasing the bias.</li>
</ul>
</section>
<section id="facts" class="level3">
<h3 class="anchored" data-anchor-id="facts">Facts</h3>
<p>Scaling is required for both Ridge and Lasso regression as they are not scale invariant due to the different norms in the definition.</p>
<table class="caption-top table" data-quarto-postprocess="true" data-border="1" data-cellpadding="10" data-cellspacing="0">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Criteria</th>
<th data-quarto-table-cell-role="th">L1 Regularization (Lasso)</th>
<th data-quarto-table-cell-role="th">L2 Regularization (Ridge)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Feature Selection</strong></td>
<td>Can set some coefficients exactly to zero, effectively performing feature selection.</td>
<td>Does not set coefficients to zero; shrinks them but retains all features.</td>
</tr>
<tr class="even">
<td><strong>Handling Multicollinearity</strong></td>
<td>Not ideal for handling highly correlated features, as it may arbitrarily select one feature and discard the others.</td>
<td>Works better in the presence of multicollinearity, as it tends to spread the penalty across correlated features.</td>
</tr>
<tr class="odd">
<td><strong>Effect on Coefficients</strong></td>
<td>Sparse solutions; coefficients are either zero or relatively large, favoring simpler models with fewer features.</td>
<td>Coefficients are small and distributed more evenly across all features, leading to less sparse solutions.</td>
</tr>
<tr class="even">
<td><strong>Interpretability</strong></td>
<td>Easier to interpret, as some features are removed, simplifying the model.</td>
<td>All features remain in the model, making it harder to interpret when there are many features.</td>
</tr>
<tr class="odd">
<td><strong>Computational Complexity</strong></td>
<td>Can be computationally intensive with a large number of features due to the non-smooth nature of the L1 penalty.</td>
<td>Less computationally expensive due to its smooth penalty term (squared coefficients).</td>
</tr>
<tr class="even">
<td><strong>Best Suited For</strong></td>
<td>When you want a sparse model with feature selection, and when the number of irrelevant features is large.</td>
<td>When you want to retain all features, especially in cases of multicollinearity, and avoid overfitting by shrinking coefficients.</td>
</tr>
<tr class="odd">
<td><strong>When to Use</strong></td>
<td><ul>
<li>When you expect only a few features to be important.</li>
<li>When you want automatic feature selection.</li>
<li>When you need a simple, interpretable model.</li>
</ul></td>
<td><li>
When you believe all features contribute to the target.
</li>
<li>
When dealing with multicollinear data.
</li>
<li>
When you want to prevent overfitting but don’t want feature elimination.
</li></td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><p><strong>Tibshirani, R.</strong> (1996). Regression shrinkage and selection via the lasso. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, 58(1), 267-288.</p></li>
<li><p><strong>Hoerl, A. E., &amp; Kennard, R. W.</strong> (1970). Ridge regression: Biased estimation for nonorthogonal problems. <em>Technometrics</em>, 12(1), 55-67.</p></li>
<li><p><strong>Zou, H., &amp; Hastie, T.</strong> (2005). Regularization and variable selection via the elastic net. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 67(2), 301-320.</p></li>
<li><p><strong>Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp; Salakhutdinov, R.</strong> (2014). Dropout: A simple way to prevent neural networks from overfitting. <em>Journal of Machine Learning Research</em>, 15(1), 1929-1958.</p></li>
<li><p><strong>Goodfellow, I., Bengio, Y., &amp; Courville, A.</strong> (2016). <em>Deep Learning</em>. MIT Press.</p></li>
<li><p><strong>Murphy, K. P.</strong> (2012). <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</p></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/regularization/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/regularization/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742008464950" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Model {Fine} {Tuning:} {Regularization}},
  date = {2024-09-24},
  url = {https://mrislambd.github.io/posts/regularization/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Model Fine Tuning: Regularization.”</span>
September 24, 2024. <a href="https://mrislambd.github.io/posts/regularization/">https://mrislambd.github.io/posts/regularization/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/regularization/</guid>
  <pubDate>Tue, 24 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/regularization/rg.png" medium="image" type="image/png" height="103" width="144"/>
</item>
<item>
  <title>Model Fine Tuning: Bias-Variance Trade Off</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/biasvariance/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
The bias-variance tradeoff is a fundamental concept in machine learning that helps us understand the balance between underfitting and overfitting. It describes how different sources of error contribute to a model’s overall prediction error and how we can optimize model complexity for better generalization. <br> <br> To understand the bias-variance tradeoff, let’s first define <strong>bias</strong> and <strong>variance</strong> in the context of machine learning models: <br> <br> <strong>Bias</strong> is the error introduced by approximating a real-world problem (often complex) by a simplified model. High bias occurs when a model is too simple and can’t capture the underlying patterns, leading to underfitting. <br> <br> <strong>Variance</strong> is the model’s sensitivity to small fluctuations in the training data. High variance indicates that the model is too complex, fitting the noise in the training data rather than the actual signal, leading to overfitting. <br> <br> The goal is to strike a balance between bias and variance to minimize the overall error, often called the <strong>expected prediction error</strong>.
</p>
</section>
<section id="mathematical-derivation" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-derivation">Mathematical Derivation</h2>
<p>The expected mean squared error (MSE) between the true function <img src="https://latex.codecogs.com/png.latex?f(x)"> and the model’s predictions <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Ctext%7BMSE%7D(x)%20&amp;=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(f(x)%20-%20%5Chat%7Bf%7D(x)%5Cright)%5E2%5Cright%5D%5C%5C%0A&amp;%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20+%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)%5Cright)%5E2%5Cright%5D%5C%5C%0A&amp;%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%5Cright)%5E2+2%5Cleft(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%5Cright)%5Cleft(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)%5Cright)+%5Cleft(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)%5Cright)%5E2%5Cright%5D%5C%5C%0A&amp;%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%5Cright)%5E2%5Cright%5D%20+%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)%5Cright)%5E2%5Cright%5D%20+%202%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%5Cright)%5Cleft(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)%5Cright)%5Cright%5D%0A%5Cend%7Balign*%7D"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)"> is the true function.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7Bf%7D(x)"> is the estimated function (the model).</li>
</ul>
<p>The third term, <img src="https://latex.codecogs.com/png.latex?2%5Cmathbb%7BE%7D%5B(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D)(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x))%5D">, <strong>vanishes</strong> because the errors <img src="https://latex.codecogs.com/png.latex?f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)"> are independent. This is a key step in the decomposition.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D"> is the bias-related error.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x)"> is the variance-related error.</li>
</ul>
<p>Since these two terms are uncorrelated, their cross-product expectation equals zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A2%5Cmathbb%7BE%7D%5B(f(x)%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D)(%5Cmathbb%7BE%7D%5B%5Chat%7Bf%7D(x)%5D%20-%20%5Chat%7Bf%7D(x))%5D%20=%200%0A"></p>
<p><strong>What is <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">?</strong></p>
<p>Now, <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, the irreducible error, is the variance of the noise in the data:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csigma%5E2%20=%20%5Cmathbb%7BE%7D%5B(y%20-%20f(x))%5E2%5D%20=%20%5Cmathbb%7BE%7D%5B%5Cepsilon%5E2%5D%0A"></p>
<p style="text-align: justify">
where <img src="https://latex.codecogs.com/png.latex?y%20=%20f(x)%20+%20%5Cepsilon">, and <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is the noise term with variance <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">. This noise is independent of both the bias and variance components and does not interact with them in the decomposition. It is the part of the error that remains no matter how good the model is.
</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BMSE%7D(x)%20=%20(%5Ctext%7BBias%7D%5B%5Chat%7Bf%7D(x)%5D)%5E2%20+%20%5Ctext%7BVariance%7D%5B%5Chat%7Bf%7D(x)%5D%20+%20%5Csigma%5E2%0A"></p>
</section>
<section id="bias-variance-tradeoff-intuition" class="level2">
<h2 class="anchored" data-anchor-id="bias-variance-tradeoff-intuition">Bias-Variance Tradeoff Intuition</h2>
<ul>
<li>A <strong>high bias</strong> model makes strong assumptions about the data and fails to capture the underlying patterns, resulting in underfitting.</li>
</ul>
<div id="a60e9233" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-4">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-5">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-7">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb1-8">model.fit(X.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),y)</span>
<span id="cb1-9">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb1-10"></span>
<span id="cb1-11">plt.scatter(X,y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data Points'</span>)</span>
<span id="cb1-12">plt.plot(X,y_pred, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Bias Model (linear)'</span>)</span>
<span id="cb1-13">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>)</span>
<span id="cb1-14">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb1-15">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Bias Model Overfitting the Data'</span>)</span>
<span id="cb1-16">plt.legend()</span>
<span id="cb1-17">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb1-18">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-19">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/biasvariance/index_files/figure-html/cell-2-output-1.png" width="587" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<ul>
<li>A <strong>high variance</strong> model is highly flexible, capturing not only the signal but also the noise in the data, leading to overfitting.</li>
</ul>
<div id="fe40e2be" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeRegressor</span>
<span id="cb2-2"></span>
<span id="cb2-3">model2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DecisionTreeRegressor(max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb2-4">model2.fit(X.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),y)</span>
<span id="cb2-5">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model2.predict(X.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb2-6"></span>
<span id="cb2-7">plt.scatter(X,y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data Points'</span>)</span>
<span id="cb2-8">plt.plot(X,y_pred, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Variance Model (linear)'</span>)</span>
<span id="cb2-9">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>)</span>
<span id="cb2-10">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb2-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'High Variance Model Overfitting the Data'</span>)</span>
<span id="cb2-12">plt.legend()</span>
<span id="cb2-13">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb2-14">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb2-15">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-3-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/biasvariance/index_files/figure-html/cell-3-output-1.png" width="587" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<ul>
<li>The tradeoff arises because increasing model complexity reduces bias but increases variance, while simplifying the model reduces variance but increases bias.</li>
</ul>
<p>The key is to find a sweet spot where the model has low enough bias and variance to generalize well to unseen data.</p>
</section>
<section id="more-visualization-of-bias-variance-tradeoff" class="level2">
<h2 class="anchored" data-anchor-id="more-visualization-of-bias-variance-tradeoff">More Visualization of Bias-Variance Tradeoff</h2>
<p>Now let’s use Python to visualize the bias-variance tradeoff by generating models of varying complexity on a synthetic dataset.</p>
<div id="06673bb5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PolynomialFeatures</span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb3-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error</span>
<span id="cb3-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate synthetic data</span></span>
<span id="cb3-9">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb3-10">n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb3-11">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(n_samples, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb3-12">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sin(X).ravel() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(n_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb3-13"></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Function to plot the results</span></span>
<span id="cb3-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_bias_variance(X, y, degrees):</span>
<span id="cb3-16">    X_plot <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-17">    fig, axs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">8.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.5</span>))</span>
<span id="cb3-18">    fig.patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-19"></span>
<span id="cb3-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, degree <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(degrees):</span>
<span id="cb3-21">        poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PolynomialFeatures(degree)</span>
<span id="cb3-22">        X_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> poly.fit_transform(X)</span>
<span id="cb3-23">        X_plot_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> poly.transform(X_plot)</span>
<span id="cb3-24">        </span>
<span id="cb3-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train a linear regression model</span></span>
<span id="cb3-26">        model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb3-27">        model.fit(X_poly, y)</span>
<span id="cb3-28">        </span>
<span id="cb3-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict on the plot points</span></span>
<span id="cb3-30">        y_plot_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_plot_poly)</span>
<span id="cb3-31">        </span>
<span id="cb3-32">        ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> axs[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb3-33">        ax.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb3-34">        ax.scatter(X,y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data'</span>)</span>
<span id="cb3-35">        ax.plot(X_plot, y_plot_pred, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Polynomial degree </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>degree<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb3-36">        ax.set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Polynomial Degree </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>degree<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb3-37">        ax.legend()</span>
<span id="cb3-38">        </span>
<span id="cb3-39">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate and display training error</span></span>
<span id="cb3-40">        y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_poly)</span>
<span id="cb3-41">        mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y, y_pred)</span>
<span id="cb3-42">        ax.text(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'MSE: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb3-43"></span>
<span id="cb3-44">    plt.tight_layout()</span>
<span id="cb3-45">    plt.savefig(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bv.png'</span>)</span>
<span id="cb3-46">    plt.show()</span>
<span id="cb3-47"></span>
<span id="cb3-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize bias-variance tradeoff</span></span>
<span id="cb3-49">degrees <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>]</span>
<span id="cb3-50">plot_bias_variance(X, y, degrees)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/biasvariance/index_files/figure-html/cell-4-output-1.png" width="777" height="518" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We create a synthetic dataset where <img src="https://latex.codecogs.com/png.latex?y%20=%20%5Csin(x)"> with added Gaussian noise.</p>
<ul>
<li>For <strong>low-degree polynomials</strong> (e.g., degree 1), the model has high bias. It is too simple to capture the nonlinear relationship in the data, leading to underfitting.</li>
<li>For <strong>high-degree polynomials</strong> (e.g., degree 9), the model has high variance. It fits the training data too closely, even capturing the noise, leading to overfitting.</li>
<li>A <strong>moderate-degree polynomial</strong> (e.g., degree 3 or 5) balances bias and variance, achieving the lowest error on unseen data.</li>
</ul>
<p style="text-align:justify">
The bias-variance tradeoff is a crucial concept for building machine learning models that generalize well. By understanding how bias and variance contribute to the total error, we can make informed decisions about model complexity. In practice, techniques like cross-validation and regularization are often used to find the optimal balance between bias and variance. <br> <br> Understanding and visualizing this tradeoff helps machine learning practitioners fine-tune their models to achieve the best possible performance.
</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>Hastie, T., Tibshirani, R., &amp; Friedman, J.</strong> (2009). <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer.</li>
<li><strong>Bishop, C. M.</strong> (2006). <em>Pattern Recognition and Machine Learning</em>. Springer.</li>
<li><strong>Géron, A.</strong> (2019). <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>. O’Reilly Media.</li>
<li><strong>Kohavi, R. &amp; Wolpert, D.</strong> (1996). Bias plus variance decomposition for zero-one loss functions. <em>Proceedings of the 13th International Conference on Machine Learning</em>.</li>
<li><strong>James, G., Witten, D., Hastie, T., &amp; Tibshirani, R.</strong> (2013). <em>An Introduction to Statistical Learning with Applications in R</em>. Springer.</li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/biasvariance/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/biasvariance/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Model {Fine} {Tuning:} {Bias-Variance} {Trade} {Off}},
  date = {2024-09-23},
  url = {https://mrislambd.github.io/posts/biasvariance/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Model Fine Tuning: Bias-Variance Trade
Off.”</span> September 23, 2024. <a href="https://mrislambd.github.io/posts/biasvariance/">https://mrislambd.github.io/posts/biasvariance/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <category>Data Engineering</category>
  <guid>https://mrislambd.github.io/posts/biasvariance/</guid>
  <pubDate>Mon, 23 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/biasvariance/bv.png" medium="image" type="image/png" height="97" width="144"/>
</item>
<item>
  <title>Polynomial Regression</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/polyreg/</link>
  <description><![CDATA[ 




<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
Polynomial regression is an extension of linear regression that captures the relationship between the dependent and independent variables by fitting a polynomial equation. Unlike linear regression, where the model assumes a straight-line relationship, polynomial regression allows for more complex relationships, enabling the model to fit non-linear data more accurately.
</p>
<section id="what-is-polynomial-regression" class="level3">
<h3 class="anchored" data-anchor-id="what-is-polynomial-regression">What is Polynomial Regression?</h3>
<p>Polynomial regression is a type of regression where the relationship between the independent variable <img src="https://latex.codecogs.com/png.latex?X"> and the dependent variable <img src="https://latex.codecogs.com/png.latex?y"> is modeled as an <img src="https://latex.codecogs.com/png.latex?n">th degree polynomial. The general form of a polynomial regression model is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20%5Cbeta_0%20+%20%5Cbeta_1%20X%20+%20%5Cbeta_2%20X%5E2%20+%20%5Cbeta_3%20X%5E3%20+%20%5Cdots%20+%20%5Cbeta_n%20X%5En%20+%20%5Cepsilon%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y"> is the predicted output (dependent variable),</li>
<li><img src="https://latex.codecogs.com/png.latex?X"> is the input feature (independent variable),</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta_0,%20%5Cbeta_1,%20%5Cdots,%20%5Cbeta_n"> are the coefficients to be learned,</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is the error term (the difference between the actual and predicted values),</li>
<li><img src="https://latex.codecogs.com/png.latex?n"> is the degree of the polynomial.</li>
</ul>
<p style="text-align:justify">
Polynomial regression can model non-linear data by introducing polynomial terms (such as <img src="https://latex.codecogs.com/png.latex?X%5E2,%20X%5E3">, etc.), but the model is still linear in terms of the coefficients, which is why it is often treated as a type of linear regression.
</p>
</section>
<section id="mathematical-derivation-of-polynomial-regression" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-derivation-of-polynomial-regression">Mathematical Derivation of Polynomial Regression</h3>
<p style="text-align: justify">
The objective of polynomial regression, like linear regression, is to minimize the <strong>sum of squared errors (SSE)</strong> between the observed values <img src="https://latex.codecogs.com/png.latex?y_i"> and the predicted values <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i">. This can be done by applying the <strong>ordinary least squares (OLS)</strong> method.
</p>
<p>For simplicity, let’s assume a second-degree polynomial regression model:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D%20=%20%5Cbeta_0%20+%20%5Cbeta_1%20X%20+%20%5Cbeta_2%20X%5E2%0A"></p>
<p>The error for each data point is the difference between the actual value <img src="https://latex.codecogs.com/png.latex?y_i"> and the predicted value <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_i">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ae_i%20=%20y_i%20-%20%5Chat%7By%7D_i%20=%20y_i%20-%20(%5Cbeta_0%20+%20%5Cbeta_1%20X_i%20+%20%5Cbeta_2%20X_i%5E2)%0A"></p>
<p>We aim to minimize the sum of squared errors (SSE):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0ASSE%20=%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20(y_i%20-%20%5Chat%7By%7D_i)%5E2%20=%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20(y_i%20-%20(%5Cbeta_0%20+%20%5Cbeta_1%20X_i%20+%20%5Cbeta_2%20X_i%5E2))%5E2%0A"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?m"> is the number of data points.</p>
<p>We can represent this problem in matrix form to generalize for higher-degree polynomials and simplify the calculation:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?X"> represent the <strong>design matrix</strong>, where each column corresponds to a power of the independent variable <img src="https://latex.codecogs.com/png.latex?X">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%20X_1%20&amp;%20X_1%5E2%20%5C%5C%0A1%20&amp;%20X_2%20&amp;%20X_2%5E2%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cvdots%20%5C%5C%0A1%20&amp;%20X_m%20&amp;%20X_m%5E2%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> be the <strong>coefficient vector</strong>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta%20=%0A%5Cbegin%7Bbmatrix%7D%0A%5Cbeta_0%20%5C%5C%0A%5Cbeta_1%20%5C%5C%0A%5Cbeta_2%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>And <img src="https://latex.codecogs.com/png.latex?y"> be the <strong>output vector</strong>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%0A%5Cbegin%7Bbmatrix%7D%0Ay_1%20%5C%5C%0Ay_2%20%5C%5C%0A%5Cvdots%20%5C%5C%0Ay_m%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>The predicted values can be written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D%20=%20X%20%5Cbeta%0A"></p>
<p>To find the optimal coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we minimize the SSE, which can be rewritten in matrix form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0ASSE%20=%20(y%20-%20X%5Cbeta)%5ET(y%20-%20X%5Cbeta)%0A"></p>
<p>To minimize this, we take the derivative of the SSE with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and set it to zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Cbeta%7D%20(y%20-%20X%5Cbeta)%5ET(y%20-%20X%5Cbeta)%20=%20-2X%5ET(y%20-%20X%5Cbeta)%20=%200%0A"></p>
<p>Solving for <img src="https://latex.codecogs.com/png.latex?%5Cbeta">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta%20=%20(X%5ET%20X)%5E%7B-1%7D%20X%5ET%20y%0A"></p>
<p>This gives the optimal solution for the coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, which can be used to predict the output <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D">. The detail proof of this parameter <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D"> can be found in the <a href="../../dsandml/multiplelinreg/index.qmd" style="text-decoration:none" target="_blank"> multiple linear regression </a> page.</p>
</section>
<section id="python-implementation-of-polynomial-regression-one-variable" class="level3">
<h3 class="anchored" data-anchor-id="python-implementation-of-polynomial-regression-one-variable">Python Implementation of Polynomial Regression (One Variable)</h3>
<p>We use <code>PolynomialFeatures</code> from <code>Scikit-learn</code> to transform our input data <img src="https://latex.codecogs.com/png.latex?X"> to include polynomial terms (e.g., <img src="https://latex.codecogs.com/png.latex?X%5E2,%20X%5E3">, etc.).</p>
<div id="d475d8b4" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PolynomialFeatures</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error</span>
<span id="cb1-6">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb1-7">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-8">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-9">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:, np.newaxis]</span>
<span id="cb1-10">plt.scatter(X, y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>)</span>
<span id="cb1-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Sample Data"</span>)</span>
<span id="cb1-12">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>)</span>
<span id="cb1-13">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb1-14">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb1-15">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb1-16">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-2-output-1.png" width="604" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="33f87998" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PolynomialFeatures(degree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, interaction_only<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, include_bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-2">X_poly <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> poly.fit_transform(X)</span></code></pre></div>
</div>
<p>Now we fit a linear regression model on the transformed polynomial features.</p>
<div id="9d85c464" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb3-2">model.fit(X_poly, y)</span>
<span id="cb3-3"></span>
<span id="cb3-4">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_poly)</span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Coefficients: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>coef_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Intercept: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>intercept_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mean_squared_error(y, y_pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients: [ 0.          0.96597113 -2.02225052]
Intercept: -2.414835667353632
Mean Squared Error: 9.44744195245028</code></pre>
</div>
</div>
<p>Finally, let’s plot the polynomial curve that fits the data.</p>
<div id="7cc6f192" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> operator</span>
<span id="cb5-2">sort_axis <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> operator.itemgetter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb5-3">sorted_zip <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sorted</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(X, y_pred), key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sort_axis)</span>
<span id="cb5-4">X_sorted, y_pred_sorted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>sorted_zip)</span>
<span id="cb5-5"></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the polynomial curve</span></span>
<span id="cb5-7">plt.scatter(X, y, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>)</span>
<span id="cb5-8">plt.plot(X_sorted, y_pred_sorted, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>)</span>
<span id="cb5-9">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>)</span>
<span id="cb5-10">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>)</span>
<span id="cb5-11">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Polynomial Regression Fit"</span>)</span>
<span id="cb5-12">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb5-13">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb5-14">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-5-output-1.png" width="604" height="449" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can evaluate the performance of the model by comparing the <strong>mean squared error (MSE)</strong> between the actual and predicted values:</p>
<div id="efa18c82" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(y, y_pred)</span>
<span id="cb6-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Mean Squared Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 9.44744195245028</code></pre>
</div>
</div>
</section>
<section id="python-implementation-of-polynomial-regression-two-variables" class="level3">
<h3 class="anchored" data-anchor-id="python-implementation-of-polynomial-regression-two-variables">Python Implementation of Polynomial Regression (Two Variables)</h3>
<p>We’ll generate some non-linear data and try to fit a polynomial regression model to it.</p>
<div id="e906b9a1" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pandas.plotting <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> scatter_matrix</span>
<span id="cb8-4">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb8-5">x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb8-6">x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.random.normal(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb8-7">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>x1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb8-8">df<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{</span>
<span id="cb8-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1'</span>:x1,</span>
<span id="cb8-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x2'</span>:x2,</span>
<span id="cb8-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>:y</span>
<span id="cb8-12">}</span>
<span id="cb8-13">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(df)</span>
<span id="cb8-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(df.head())</span>
<span id="cb8-15">scatter_matrix(df)</span>
<span id="cb8-16">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb8-17">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb8-18">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         x1         x2           y
0 -3.292157   7.065206  -41.206797
1  0.799528 -18.782072  -39.440680
2 -0.936214 -18.163880  -40.343409
3 -4.722680  -0.244826 -102.906711
4 -3.602674 -17.384987  -96.574641</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-7-output-2.png" width="597" height="450" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Since it’s clear that the relationships are not linear. So if we fit a linear regression model, it won’t be a good fit.</p>
<div id="741d228a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb10-2">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.y</span>
<span id="cb10-3">model1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb10-4">model1.fit(X,y)</span>
<span id="cb10-5">pred1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model1.predict(X)</span>
<span id="cb10-6">residual1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred1</span>
<span id="cb10-7">sns.scatterplot(residual1)</span>
<span id="cb10-8">plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>)</span>
<span id="cb10-9">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb10-10">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb10-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-8-output-1.png" width="604" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Therefore, we generate some non linear features from the given data.</p>
<div id="30679423" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x1_squared'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.x1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb11-2">scatter_matrix(df)</span>
<span id="cb11-3">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb11-4">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb11-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-9-output-1.png" width="597" height="450" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>From this plot, we see that <img src="https://latex.codecogs.com/png.latex?x1"> is parabolic and <img src="https://latex.codecogs.com/png.latex?x2"> is linear in relationship with <img src="https://latex.codecogs.com/png.latex?y">. So, how about a model that combines a linear and quadratic model?</p>
<div id="dd78ae60" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb12-2">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.y</span>
<span id="cb12-3">model2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb12-4">model2.fit(X,y)</span>
<span id="cb12-5">pred2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model2.predict(X)</span>
<span id="cb12-6">residual2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> pred2</span>
<span id="cb12-7">sns.scatterplot(residual2)</span>
<span id="cb12-8">plt.axhline(y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>)</span>
<span id="cb12-9">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>) </span>
<span id="cb12-10">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb12-11">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://mrislambd.github.io/posts/polyreg/index_files/figure-html/cell-10-output-1.png" width="587" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>This one is much better.</p>
<p style="text-align:justify">
Polynomial regression is a powerful technique that extends the basic linear regression model to capture non-linear relationships between variables. By transforming the input data into polynomial terms, the model becomes more flexible, allowing it to better fit data that doesn’t follow a linear pattern.<br> <br> The mathematical derivation shows that polynomial regression is still linear in terms of its parameters, allowing us to use simple optimization techniques like ordinary least squares (OLS) for parameter estimation.<br> <br> In Python, using Scikit-learn makes it easy to implement polynomial regression. We can increase the degree of the polynomial to improve model accuracy, but we need to be careful of <strong>overfitting</strong>, where the model becomes too complex and fits the noise in the data rather than the underlying pattern.
</p>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/polyreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/polyreg/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742008464950" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="11" data-listing-word-count-sort="2195">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
11 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Polynomial {Regression}},
  date = {2024-09-20},
  url = {https://mrislambd.github.io/posts/polyreg/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Polynomial Regression.”</span> September 20,
2024. <a href="https://mrislambd.github.io/posts/polyreg/">https://mrislambd.github.io/posts/polyreg/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/polyreg/</guid>
  <pubDate>Fri, 20 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/polyreg/poly.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>How do we treat categorical features for our data science project?</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/dataengineering/</link>
  <description><![CDATA[ 




<p align="center">
<img src="https://mrislambd.github.io/_assets/images/uc.jpeg" alt="Post under construction" width="400" height="400">
</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p style="text-align: justify">
<img src="https://mrislambd.github.io/posts/dataengineering/sm.png" align="right" width="400" height="450" style="align-right; margin-left:20px"> Suppose we are working on a data science project and the data contains both contineous and categorical variables. For example, we want to build a predictive model for a life insurance company. The model will predict the annual company spending on individuals depending on their age, bmi, sex, smoking habit, number of children, and region in the US where the belong. So here, our target variable is a contineous variable and the feature variables contain both contineous and categorical variables.<br> <br> To understand how important each feature is, there are many possible ways. For example, when we do the exploratory data analysis (EDA) we can do some plotting to see how each feature inteacts with the target variable, or maybe calculating correlations of the features and target variables. However, when the feature is contineous it is not a big issue to calculate the correlation matrix. But when the feature is categorical or ordinal, for example, in this predictive modeling case, how do we know if the number of children or smoking habit have impact on insurance charges? Plotting <code>boxplot</code> or <code>countplot</code> from the <code>seaborn</code> or any other library may help, give some primary idea. But how do we quantify the correlations?<br> <br> Here comes the statistical method one-way <strong><em>Analysis of Variances (ANOVA)</em></strong> among many other alternatives. Machine libraries like <code>scipy</code> has built-in functions that can compute the ANOVA’s for each categorical feature. We will see the implementation of this at the end of this post. This blog post is about the simple explanation of the mathematics behind the ANOVA method.
</p>
</section>
<section id="anova" class="level2">
<h2 class="anchored" data-anchor-id="anova">ANOVA</h2>
<p>This is the 5 random sample <a href="[www.kaggle.com/datasets/mirichoi0218/insurance/data](https://www.kaggle.com/datasets/harshsingh2209/medical-insurance-payout)" target="_blank" style="text-decoration:none">data</a> that we are talking about. We will use this data to explain the mathematical formulation of the model.</p>
<div id="6b8a0b27" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'insurance.csv'</span>)</span>
<span id="cb1-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(data.sample(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">111</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      age   sex    bmi  children smoker     region     charges
1000   30  male  22.99         2    yes  northwest  17361.7661
53     36  male  34.43         0    yes  southeast  37742.5757
432    42  male  26.90         0     no  southwest   5969.7230
162    54  male  39.60         1     no  southwest  10450.5520
1020   51  male  37.00         0     no  southwest   8798.5930</code></pre>
</div>
</div>
<p>We will explain the method using the feature <code>children</code>.</p>
<div id="8c2ec2f7" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">child <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.children.value_counts().sort_index()</span>
<span id="cb3-2">c0<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].charges.values.tolist()</span>
<span id="cb3-3">c1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].charges.values.tolist()</span>
<span id="cb3-4">c2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>].charges.values.tolist()</span>
<span id="cb3-5">c3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>].charges.values.tolist()</span>
<span id="cb3-6">c4<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>].charges.values.tolist()</span>
<span id="cb3-7">c5<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data[data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'children'</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>].charges.values.tolist()</span></code></pre></div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Children 0</th>
<th>Children 1</th>
<th>Children 2</th>
<th>Children 3</th>
<th>Children 4</th>
<th>Children 5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>[16884.924, 21984.47061, 3866.8552, 3756.6216, 28923.13692, 2721.3208]</td>
<td>[1725.5523, 8240.5896, 1837.237, 10797.3362]</td>
<td>[6406.4107, 6203.90175, 12268.63225]</td>
<td>[4449.462, 7281.5056]</td>
<td>[4504.6624, 11033.6617, 10407.08585]</td>
<td>[4687.797, 6799.458]</td>
</tr>
<tr class="even">
<td>Total 574</td>
<td>Total 324</td>
<td>Total 240</td>
<td>Total 157</td>
<td>Total 25</td>
<td>Total 18</td>
</tr>
</tbody>
</table>
<p>A one-way analysis of variance is a method to compare <img src="https://latex.codecogs.com/png.latex?k"> homogenous groups when the experiment has <img src="https://latex.codecogs.com/png.latex?n_i"> response values for each each group <img src="https://latex.codecogs.com/png.latex?i">. Therefore, total data <img src="https://latex.codecogs.com/png.latex?n=%5Csum_%7Bi%7D%20n_i"> and <img src="https://latex.codecogs.com/png.latex?y_%7Bij%7D"> represent the <img src="https://latex.codecogs.com/png.latex?j">th observation of the <img src="https://latex.codecogs.com/png.latex?i">th group. For our example above, we have <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5E%7B6%7Dn_i=">(574+324+240+157+25+18)= 1338 and <img src="https://latex.codecogs.com/png.latex?y_%7B12%7D="> 21984.47061 meaning, group 1 and second element.</p>
<p>Now let’s define <img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_i%20=%20%5Cfrac%7B1%7D%7Bn_i%7D%5Csum_%7Bj=1%7D%5E%7Bn_i%7D%5Cfrac%7By_%7Bij%7D%7D%7Bn_i%7D;%5Chspace%7B4mm%7D%5Ctext%7Bfor%20%7D%20i=1,2,%5Ccdots,%206%0A"></p>
<p>Since all the groups are coming from the same sample/population, we must assume that they all have common variance. This <img src="https://latex.codecogs.com/png.latex?%5Ctextcolor%7Bred%7D%7B%5Ctext%7Bhomogeneity%20assumption%20is%20crucial%7D%7D"> for ANOVA analysis. So, irrespective of their group assignment, each <img src="https://latex.codecogs.com/png.latex?y_%7Bij%7D%5Csim%20(%5Cmu_i,%20%5Csigma%5E2)"></p>
<section id="what-does-one-sided-anova-do" class="level3">
<h3 class="anchored" data-anchor-id="what-does-one-sided-anova-do">What does one-sided ANOVA do?</h3>
<p style="text-align: justify">
The main purpose of one-sided ANOVA is to act as a judge like in a court house. It assumes that there is no variation in any group. All group has the same mean. So it sets a null hypthesis and declares that there is no difference in the groups whereas the alternative is set to the opposite. Let’s see what happens to our data
</p>
<div id="6356170e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np </span></code></pre></div>
</div>
<table class="caption-top table">
<thead>
<tr class="header">
<th><img src="https://latex.codecogs.com/png.latex?%5Cmu"></th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_1"></td>
<td>12365.98</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_2"></td>
<td>12731.17</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_3"></td>
<td>15073.56</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_4"></td>
<td>15355.32</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_5"></td>
<td>13850.66</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Cmu_6"></td>
<td>8786.04</td>
</tr>
</tbody>
</table>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/dataengineering/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/dataengineering/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {How Do We Treat Categorical Features for Our Data Science
    Project?},
  date = {2024-09-12},
  url = {https://mrislambd.github.io/posts/dataengineering/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“How Do We Treat Categorical Features for Our
Data Science Project?”</span> September 12, 2024. <a href="https://mrislambd.github.io/posts/dataengineering/">https://mrislambd.github.io/posts/dataengineering/</a>.
</div></div></section></div> ]]></description>
  <category>Statistics</category>
  <category>Data Science</category>
  <category>Data Engineering</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/dataengineering/</guid>
  <pubDate>Thu, 12 Sep 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/dataengineering/sm.png" medium="image" type="image/png" height="180" width="144"/>
</item>
<item>
  <title>K Nearest Neighbors Regression</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/knn/</link>
  <description><![CDATA[ 




<section id="introduction-non-parametric-models" class="level2">
<h2 class="anchored" data-anchor-id="introduction-non-parametric-models">Introduction: Non-parametric Models</h2>
<p style="text-align: justify">
Non-parametric model is a statistical model that does not make any assumptions about the underlying data distributions, meaning it does not require specifying functional form for the relationships between variables, instead learning directly from the data points without pre-defined parameters.
</p>
</section>
<section id="k-nearest-neighbors-knn-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors-knn-algorithm"><img src="https://latex.codecogs.com/png.latex?K-">Nearest Neighbors (KNN) Algorithm</h2>
<p style="text-align:justify">
K-Nearest Neighbors (KNN) is one of the simplest yet effective algorithms used in supervised learning for both classification and regression problems. It’s a <strong>lazy learner</strong>—meaning it does not perform any specific training of a model but memorizes the training dataset and makes predictions based on proximity in feature space.
</p>
<p>We are given a set of data points <img src="https://latex.codecogs.com/png.latex?(%5Cbar%7Bx%7D_i,y_i)"> with <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D_i%5Cin%20%5Cmathbb%7BR%7D%5Ed"> and <img src="https://latex.codecogs.com/png.latex?y_i%5Cin%20%5Cmathbb%7BR%7D"><br>
1. Choose the number of neighbors <img src="https://latex.codecogs.com/png.latex?K"><br>
2. Compute the distance between the new data point and all the training samples<br>
3. Select the <img src="https://latex.codecogs.com/png.latex?K"> nearest neighbors based on distance.<br>
4. For <strong>classification</strong>, the output is the most common class among the <img src="https://latex.codecogs.com/png.latex?K"> neighbors.<br>
5. For <strong>regression</strong>, the output is the average of the target values of <img src="https://latex.codecogs.com/png.latex?K"> neighbors</p>
<section id="k-nearest-neighbors-classification" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors-classification"><img src="https://latex.codecogs.com/png.latex?K-">Nearest Neighbors Classification</h3>
<p>The KNN classification algorithm can be summarized with the following steps:</p>
<p>Given:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X_%7Btrain%7D%20=%20%5Bx_1,%20x_2,%20%5Cldots,%20x_n%5D"> (the training data features)<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?y_%7Btrain%7D%20=%20%5By_1,%20y_2,%20%5Cldots,%20y_n%5D"> (the training data labels)<br>
</li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Btest%7D"> (the new data point for which we want to predict the class)</li>
</ul>
<p><strong>Steps</strong></p>
<p><strong>1. Compute Distance</strong>: For each training point <img src="https://latex.codecogs.com/png.latex?x_i">, calculate the distance <img src="https://latex.codecogs.com/png.latex?d(x_i,%20x_%7Btest%7D)"> using a distance metric like <strong>Euclidean distance</strong>: <img src="https://latex.codecogs.com/png.latex?%0A%20%20%20d(x_i,%20x_%7Btest%7D)%20=%20%5Csqrt%7B%5Csum_%7Bj=1%7D%5E%7Bm%7D%20(x_%7Bi,j%7D%20-%20x_%7Btest,j%7D)%5E2%7D%0A%20%20%20"> where <img src="https://latex.codecogs.com/png.latex?m"> is the number of features.</p>
<p><strong>2. Find K Nearest Neighbors</strong>: Sort the distances and pick the <strong>K</strong> closest points.</p>
<p><strong>3. Majority Voting</strong>: Look at the labels <img src="https://latex.codecogs.com/png.latex?y_i"> of the <strong>K</strong> nearest neighbors. The predicted label for <img src="https://latex.codecogs.com/png.latex?x_%7Btest%7D"> is the most frequent label (majority vote) among the neighbors.</p>
<p>For example, let’s say our data looks like this</p>
<div>

</div>
<div id="tb1-panel" class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Training Data</caption>
<thead>
<tr class="header">
<th style="text-align: center;">area</th>
<th style="text-align: center;">bedroom</th>
<th style="text-align: center;">bathroom</th>
<th style="text-align: center;">price</th>
<th style="text-align: center;">condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">7420</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1300000</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">7520</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1450000</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">6420</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1110000</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">5423</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1363400</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5423</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1263400</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Test Data</caption>
<thead>
<tr class="header">
<th style="text-align: center;">area</th>
<th style="text-align: center;">bedroom</th>
<th style="text-align: center;">bathroom</th>
<th style="text-align: center;">price</th>
<th style="text-align: center;">condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5420</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">1302000</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">7120</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1453000</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>For the data points <img src="https://latex.codecogs.com/png.latex?x_i"> from the training set and a single test data point <img src="https://latex.codecogs.com/png.latex?xt=%5B5420,3,2.5,1302000%5D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20d(x_1,%20xt)%20&amp;%20=%20%5Csqrt%7B(x_%7B11%7D-xt_1)%5E2%20+%20(x_%7B12%7D-xt_2)%5E2%20+%20(x_%7B13%7D-xt_3)%5E2%20+%20(x_%7B14%7D-xt_4)%5E2%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20=%20%5Csqrt%7B(7420-5420)%5E2%20+%20(4-5)%5E2%20+%20(2-2.5)%5E2%20+%20(1300000-1302000)%5E2%7D%20%5Capprox%202828.43%5C%5C%0A%20%20%20%20d(x_2,xt)%20%20&amp;%20=%20%5Csqrt%7B(x_%7B21%7D-xt_1)%5E2%20+%20(x_%7B22%7D-xt_2)%5E2%20+%20(x_%7B23%7D-xt_3)%5E2%20+%20(x_%7B24%7D-xt_4)%5E2%7D%20%5C%5C%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20=%20%5Csqrt%7B(7520-5420)%5E2%20+%20(3-5)%5E2%20+%20(3-2.5)%5E2%20+%20(1450000-1302000)%5E2%7D%20%5Capprox%2014805.92%5C%5C%0A%20%20%20%20d(x_3,xt)%20%20&amp;%20=%20%5Csqrt%7B(x_%7B31%7D-xt_1)%5E2%20+%20(x_%7B32%7D-xt_2)%5E2%20+%20(x_%7B33%7D-xt_3)%5E2%20+%20(x_%7B34%7D-xt_4)%5E2%7D%20%20%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20=%20%5Csqrt%7B(6420-5420)%5E2%20+%20(2-5)%5E2%20+%20(1-2.5)%5E2%20+%20(1110000-1302000)%5E2%7D%20%5Capprox%2019209.38%5C%5C%0A%20%20%20%20d(x_4,xt)%20%20&amp;%20=%20%5Csqrt%7B(x_%7B41%7D-xt_1)%5E2%20+%20(x_%7B42%7D-xt_2)%5E2%20+%20(x_%7B43%7D-xt_3)%5E2%20+%20(x_%7B44%7D-xt_4)%5E2%7D%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20=%20%5Csqrt%7B(6420-5420)%5E2%20+%20(2-5)%5E2%20+%20(1-2.5)%5E2%20+%20(1110000-1302000)%5E2%7D%20%5Capprox%2019209.38%5C%5C%0A%20%20%20%20d(x_5,xt)%20%20&amp;%20=%20%5Csqrt%7B(x_%7B51%7D-xt_1)%5E2%20+%20(x_%7B52%7D-xt_2)%5E2%20+%20(x_%7B53%7D-xt_3)%5E2%20+%20(x_%7B54%7D-xt_4)%5E2%7D%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20=%20%5Csqrt%7B(5423-5420)%5E2%20+%20(3-5)%5E2%20+%20(1-2.5)%5E2%20+%20(1263400-1302000)%5E2%7D%20%5Capprox%2038602.95%0A%5Cend%7Balign*%7D"></p>
<p>So the distances</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?d_1=d(x_1,%20xt)%20%5Capprox%202828.43"></li>
<li><img src="https://latex.codecogs.com/png.latex?d_2=d(x_2,%20xt)%20%5Capprox%2014805.92"></li>
<li><img src="https://latex.codecogs.com/png.latex?d_3=d(x_3,%20xt)%20%5Capprox%2019209.38"></li>
<li><img src="https://latex.codecogs.com/png.latex?d_4=d(x_4,%20xt)%20%5Capprox%2061405.03"></li>
<li><img src="https://latex.codecogs.com/png.latex?d_5=d(x_5,%20xt)%20%5Capprox%2038602.95"></li>
</ul>
<p>If we sort the above distances, we get <img src="https://latex.codecogs.com/png.latex?d_1%3Cd_2%3Cd_3%3Cd_5%3Cd_4"> and if we choose <img src="https://latex.codecogs.com/png.latex?K=3"> nearest neighbors, then <img src="https://latex.codecogs.com/png.latex?d_1%3Cd_2%3Cd_3"> and</p>
<ul>
<li>Data point <img src="https://latex.codecogs.com/png.latex?x_1"> has class label <code>condition</code><img src="https://latex.codecogs.com/png.latex?=1"><br>
</li>
<li>Data point <img src="https://latex.codecogs.com/png.latex?x_2"> has class label <code>condition</code><img src="https://latex.codecogs.com/png.latex?=1"><br>
</li>
<li>Data point <img src="https://latex.codecogs.com/png.latex?x_3"> has class label <code>condition</code><img src="https://latex.codecogs.com/png.latex?=0"></li>
</ul>
<p>We can clearly see that the majority class (2 out of 3) is <code>condition</code><img src="https://latex.codecogs.com/png.latex?=1">. Therefore, for the given test data, the label would be also <code>condition</code><img src="https://latex.codecogs.com/png.latex?=1">.</p>
<section id="knn-classifier-using-python" class="level4">
<h4 class="anchored" data-anchor-id="knn-classifier-using-python">KNN Classifier Using Python</h4>
<p>Here’s how to implement KNN for classification in Python from scratch:</p>
<div id="893eab04" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> collections <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Counter</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CustomKNNclassifier:</span>
<span id="cb1-6"></span>
<span id="cb1-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb1-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k</span>
<span id="cb1-9">    </span>
<span id="cb1-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, Y):</span>
<span id="cb1-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X</span>
<span id="cb1-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Y</span>
<span id="cb1-13">    </span>
<span id="cb1-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb1-15">        predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> X.to_numpy()] </span>
<span id="cb1-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.array(predictions)</span>
<span id="cb1-17">    </span>
<span id="cb1-18">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb1-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the Euclidean distances </span></span>
<span id="cb1-20">        distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [np.linalg.norm(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> X_train) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> X_train <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X.to_numpy()]</span>
<span id="cb1-21"></span>
<span id="cb1-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the indices of the k nearest neighbors</span></span>
<span id="cb1-23">        k_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(distances)[:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k]</span>
<span id="cb1-24"></span>
<span id="cb1-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the labels of k nearest neighbors</span></span>
<span id="cb1-26">        k_nearest_neighbors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Y[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> k_indices]</span>
<span id="cb1-27"></span>
<span id="cb1-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the most common label</span></span>
<span id="cb1-29">        common_label <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Counter(k_nearest_neighbors).most_common(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> common_label</span>
<span id="cb1-31"></span>
<span id="cb1-32"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example usage</span></span>
<span id="cb1-33">train_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb1-34">    {</span>
<span id="cb1-35">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'area'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7420</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7520</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6420</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5423</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5423</span>],</span>
<span id="cb1-36">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bedroom'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>],</span>
<span id="cb1-37">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bathroom'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb1-38">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1300000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1450000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1110000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1363400</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1263400</span>],</span>
<span id="cb1-39">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'condition'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb1-40">    }</span>
<span id="cb1-41">)</span>
<span id="cb1-42">test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb1-43">    {</span>
<span id="cb1-44">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'area'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5420</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7120</span>],</span>
<span id="cb1-45">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bedroom'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb1-46">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bathroom'</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>],</span>
<span id="cb1-47">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1302000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1453000</span>]</span>
<span id="cb1-48">    }</span>
<span id="cb1-49">)</span>
<span id="cb1-50"></span>
<span id="cb1-51">X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_data.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'condition'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-52">y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'condition'</span>]</span>
<span id="cb1-53"></span>
<span id="cb1-54">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_data</span>
<span id="cb1-55"></span>
<span id="cb1-56"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize and train the KNN model</span></span>
<span id="cb1-57">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomKNNclassifier(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb1-58">classifier.fit(X_train, y_train)</span>
<span id="cb1-59"></span>
<span id="cb1-60"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict on test data</span></span>
<span id="cb1-61">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.predict(X_test)</span>
<span id="cb1-62"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(predictions)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1 1]</code></pre>
</div>
</div>
<p>So the complete test set would be</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">area</th>
<th style="text-align: center;">bedroom</th>
<th style="text-align: center;">bathroom</th>
<th style="text-align: center;">price</th>
<th style="text-align: center;">condition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5420</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">1302000</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">7120</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1453000</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p><span style="color:red">Note: We did not scale the data before applying the classifier. If we scaled, the result might have been different (?). In practice, we need to scale the data before applying KNN algorithm. Because computing a large number of distances with big numbers may get us wrong order and also time cosuming.</span></p>
</section>
</section>
<section id="k-nearest-neighbors-regression" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors-regression"><img src="https://latex.codecogs.com/png.latex?K-">Nearest Neighbors Regression</h3>
<p>KNN regression is slightly different from classification. Instead of taking a majority vote, we predict the output by averaging the values of the <strong>K</strong> nearest neighbors.</p>
<p>Given:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X_%7Btrain%7D%20=%20%5Bx_1,%20x_2,%20%5Cldots,%20x_n%5D"> (the training data features)</li>
<li><img src="https://latex.codecogs.com/png.latex?y_%7Btrain%7D%20=%20%5By_1,%20y_2,%20%5Cldots,%20y_n%5D"> (the continuous target values)</li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Btest%7D"> (the new data point for which we want to predict the value)</li>
</ul>
<p><strong>Step-by-Step:</strong></p>
<p><strong>1. Compute Distance</strong>: Calculate the Euclidean distance between <img src="https://latex.codecogs.com/png.latex?x_%7Btest%7D"> and each training point <img src="https://latex.codecogs.com/png.latex?x_i">.<br>
<strong>2. Find K Nearest Neighbors</strong>: Sort the distances and select the <strong>K</strong> nearest points.<br>
<strong>3. Averaging</strong>: The predicted value for <img src="https://latex.codecogs.com/png.latex?x_%7Btest%7D"> is the average of the target values <img src="https://latex.codecogs.com/png.latex?y_i"> of the <strong>K</strong> nearest neighbors:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7By%7D_%7Btest%7D%20=%20%5Cfrac%7B1%7D%7BK%7D%20%5Csum_%7Bi=1%7D%5E%7BK%7D%20y_i%0A"></p>
<section id="knn-regressor-using-python" class="level4">
<h4 class="anchored" data-anchor-id="knn-regressor-using-python">KNN Regressor Using Python</h4>
<p>Now we use the same training data and test data for this regression. But this time, our target variable is <code>price</code> and test data looks like this</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">area</th>
<th style="text-align: center;">bedroom</th>
<th style="text-align: center;">bathroom</th>
<th style="text-align: center;">Condition</th>
<th style="text-align: center;">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5420</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">7120</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>After scaling the data looks like this</p>
<div>

</div>
<div id="tb1-panel" class="quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Training Data</caption>
<thead>
<tr class="header">
<th style="text-align: left;">area</th>
<th style="text-align: left;">bedroom</th>
<th style="text-align: left;">bathroom</th>
<th style="text-align: left;">condition</th>
<th style="text-align: left;">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1.213</td>
<td style="text-align: left;">1.414</td>
<td style="text-align: left;">0.267</td>
<td style="text-align: left;">0.730</td>
<td style="text-align: left;">1300000</td>
</tr>
<tr class="even">
<td style="text-align: left;">1.336</td>
<td style="text-align: left;">0.000</td>
<td style="text-align: left;">1.603</td>
<td style="text-align: left;">0.730</td>
<td style="text-align: left;">1450000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-0.026</td>
<td style="text-align: left;">-1.414</td>
<td style="text-align: left;">-1.336</td>
<td style="text-align: left;">-1.095</td>
<td style="text-align: left;">1110000</td>
</tr>
<tr class="even">
<td style="text-align: left;">-1.261</td>
<td style="text-align: left;">0.000</td>
<td style="text-align: left;">0.267</td>
<td style="text-align: left;">-1.095</td>
<td style="text-align: left;">1363400</td>
</tr>
<tr class="odd">
<td style="text-align: left;">-1.261</td>
<td style="text-align: left;">0.000</td>
<td style="text-align: left;">-1.336</td>
<td style="text-align: left;">0.730</td>
<td style="text-align: left;">1263400</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="caption-top table">
<caption>Test Data</caption>
<thead>
<tr class="header">
<th style="text-align: left;">area</th>
<th style="text-align: left;">bedroom</th>
<th style="text-align: left;">bathroom</th>
<th style="text-align: left;">condition</th>
<th style="text-align: left;">price</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">-1.266</td>
<td style="text-align: left;">0.000</td>
<td style="text-align: left;">0.803</td>
<td style="text-align: left;">0.730</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">0.854</td>
<td style="text-align: left;">2.828</td>
<td style="text-align: left;">3.876</td>
<td style="text-align: left;">0.730</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Now we see that</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%20%20%20%20d_1=d(x_1,%20x_t)%20&amp;%20=%20%5Csqrt%7B(1.213%20-%20(-1.266))%5E2%20+%20(1.414%20-%200)%5E2%20+%20(0.267%20-%200.803)%5E2%20+%20(0.730%20-%200.730)%5E2%7D%20%20%5Capprox%202.904%5C%5C%0A%20%20%20%20d_2=d(x_2,%20x_t)%20&amp;%20=%20%5Csqrt%7B(1.336%20-%20(-1.266))%5E2%20+%20(0.000%20-%200)%5E2%20+%20(1.603%20-%200.803)%5E2%20+%20(0.730%20-%200.730)%5E2%7D%20%5Capprox%202.721%5C%5C%0A%20%20%20%20d_3=d(x_3,%20x_t)%20&amp;%20=%20%5Csqrt%7B(-0.026%20-%20(-1.266))%5E2%20+%20(-1.414%20-%200)%5E2%20+%20(-1.336%20-%200.803)%5E2%20+%20(-1.095%20-%200.730)%5E2%7D%20%20%5Capprox%203.382%5C%5C%0A%20%20%20%20d_4=d(x_4,%20x_t)%20&amp;%20=%20%5Csqrt%7B(-1.261%20-%20(-1.266))%5E2%20+%20(0.000%20-%200)%5E2%20+%20(0.267%20-%200.803)%5E2%20+%20(-1.095%20-%200.730)%5E2%7D%20%20%5Capprox%201.902%5C%5C%0A%20%20%20%20d_5=d(x_5,%20x_t)%20&amp;%20=%20%5Csqrt%7B(-1.261%20-%20(-1.266))%5E2%20+%20(0.000%20-%200)%5E2%20+%20(-1.336%20-%200.803)%5E2%20+%20(0.730%20-%200.730)%5E2%7D%20%5Capprox%202.140%0A%5Cend%7Balign*%7D"></p>
<p>But this time, the order is <img src="https://latex.codecogs.com/png.latex?d_4%3Cd_5%3Cd_2%3Cd_1%3Cd_3"> and for <img src="https://latex.codecogs.com/png.latex?k=3"> we have <img src="https://latex.codecogs.com/png.latex?d_4%3Cd_5%3Cd_2">. The price for this distances</p>
<ul>
<li>For data point <img src="https://latex.codecogs.com/png.latex?x_4">, the <code>price</code><img src="https://latex.codecogs.com/png.latex?=1363400"><br>
</li>
<li>For data point <img src="https://latex.codecogs.com/png.latex?x_5">, the <code>price</code><img src="https://latex.codecogs.com/png.latex?=1263400"><br>
</li>
<li>For data point <img src="https://latex.codecogs.com/png.latex?x_2">, the <code>price</code><img src="https://latex.codecogs.com/png.latex?=1450000"></li>
</ul>
<p>So the predicted price should be the average of this three prices, that for <img src="https://latex.codecogs.com/png.latex?xt=%5B5420,3,2.5,1%5D"> the price we expect<br>
<img src="https://latex.codecogs.com/png.latex?%0Aprice%20=%20%5Cfrac%7B1363400+1263400+1450000%7D%7B3%7D=1358933.33%0A"></p>
<p>Here’s how to implement KNN for regression in Python from scratch and we see if we get the same as the hand calculation.</p>
<div id="61041102" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CustomKNNRegressor:</span>
<span id="cb3-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb3-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k</span>
<span id="cb3-6"></span>
<span id="cb3-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X_train, y_train):</span>
<span id="cb3-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train</span>
<span id="cb3-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train.to_numpy()</span>
<span id="cb3-10"></span>
<span id="cb3-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X_test):</span>
<span id="cb3-12">        predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._predict(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> X_test]</span>
<span id="cb3-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.array(predictions)</span>
<span id="cb3-14">    </span>
<span id="cb3-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb3-16">        distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [np.linalg.norm(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>x_train) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x_train <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.X_train]</span>
<span id="cb3-17">        k_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(distances)[:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k]</span>
<span id="cb3-18">        k_nearest_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.y_train[i] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> k_indices]</span>
<span id="cb3-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.mean(k_nearest_values)</span>
<span id="cb3-20"></span>
<span id="cb3-21">X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_data.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-22">y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>]</span>
<span id="cb3-23"></span>
<span id="cb3-24">test_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb3-25">    {</span>
<span id="cb3-26">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'area'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5420</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7120</span>],</span>
<span id="cb3-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bedroom'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb3-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bathroom'</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>],</span>
<span id="cb3-29">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'condition'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb3-30">    }</span>
<span id="cb3-31">)</span>
<span id="cb3-32"></span>
<span id="cb3-33">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_data</span>
<span id="cb3-34"></span>
<span id="cb3-35">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb3-36"></span>
<span id="cb3-37">X_train_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X_train)</span>
<span id="cb3-38">X_test_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(X_test)</span>
<span id="cb3-39"></span>
<span id="cb3-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize and train the KNN regressor</span></span>
<span id="cb3-41">regressor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomKNNRegressor(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb3-42">regressor.fit(X_train_sc, y_train)</span>
<span id="cb3-43"></span>
<span id="cb3-44"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Predict on test data</span></span>
<span id="cb3-45">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> regressor.predict(X_test_sc)</span>
<span id="cb3-46"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(predictions,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1358933.33 1371133.33]</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="choosing-the-value-of-k" class="level3">
<h3 class="anchored" data-anchor-id="choosing-the-value-of-k">Choosing the Value of <strong>K</strong></h3>
<p>The value of <strong>K</strong> significantly affects the performance of the KNN algorithm:</p>
<ul>
<li><strong>Small K</strong>: If <strong>K</strong> is too small, the model is sensitive to noise, and the predictions can be unstable.<br>
</li>
<li><strong>Large K</strong>: If <strong>K</strong> is too large, the model becomes more biased, and the predictions may be overly smoothed.</li>
</ul>
<p>A typical way to choose <strong>K</strong> is by trying different values and using cross-validation to see which value yields the best performance.</p>
<hr>
</section>
<section id="distance-metrics" class="level3">
<h3 class="anchored" data-anchor-id="distance-metrics">Distance Metrics</h3>
<p>The default metric for KNN is <strong>Euclidean distance</strong>, but depending on the dataset, other metrics like <strong>Manhattan distance</strong> or <strong>Minkowski distance</strong> might be more suitable.</p>
<ul>
<li><p><strong>Euclidean Distance</strong> (L2 Norm): <img src="https://latex.codecogs.com/png.latex?%0Ad(x_i,%20x_j)%20=%20%5Csqrt%7B%5Csum_%7Bk=1%7D%5E%7Bm%7D%20(x_%7Bi,k%7D%20-%20x_%7Bj,k%7D)%5E2%7D%0A"></p></li>
<li><p><strong>Manhattan Distance</strong> (L1 Norm): <img src="https://latex.codecogs.com/png.latex?%0Ad(x_i,%20x_j)%20=%20%5Csum_%7Bk=1%7D%5E%7Bm%7D%20%7Cx_%7Bi,k%7D%20-%20x_%7Bj,k%7D%7C%0A"></p></li>
</ul>
</section>
<section id="knn-implementation" class="level3">
<h3 class="anchored" data-anchor-id="knn-implementation">KNN Implementation</h3>
<p>In this section we use KNN regression for <code>Boston Housing</code> dataset and find the optimal <img src="https://latex.codecogs.com/png.latex?K"> using the <code>KFold</code> cross-validation.</p>
<div id="3a28ec2a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HousingData.csv'</span>)</span></code></pre></div>
</div>
<p>Next we see if there is any missing values. If we have any, we will skip those observations.</p>
<div id="49a47ef5" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(df.isnull().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>())</span>
<span id="cb6-2">df.dropna(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CRIM       20
ZN         20
INDUS      20
CHAS       20
NOX         0
RM          0
AGE        20
DIS         0
RAD         0
TAX         0
PTRATIO     0
B           0
LSTAT      20
MEDV        0
dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">NOX</th>
<th data-quarto-table-cell-role="th">RM</th>
<th data-quarto-table-cell-role="th">DIS</th>
<th data-quarto-table-cell-role="th">RAD</th>
<th data-quarto-table-cell-role="th">TAX</th>
<th data-quarto-table-cell-role="th">PTRATIO</th>
<th data-quarto-table-cell-role="th">B</th>
<th data-quarto-table-cell-role="th">MEDV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.538</td>
<td>6.575</td>
<td>4.0900</td>
<td>1</td>
<td>296</td>
<td>15.3</td>
<td>396.90</td>
<td>24.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.469</td>
<td>6.421</td>
<td>4.9671</td>
<td>2</td>
<td>242</td>
<td>17.8</td>
<td>396.90</td>
<td>21.6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.469</td>
<td>7.185</td>
<td>4.9671</td>
<td>2</td>
<td>242</td>
<td>17.8</td>
<td>392.83</td>
<td>34.7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.458</td>
<td>6.998</td>
<td>6.0622</td>
<td>3</td>
<td>222</td>
<td>18.7</td>
<td>394.63</td>
<td>33.4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.458</td>
<td>7.147</td>
<td>6.0622</td>
<td>3</td>
<td>222</td>
<td>18.7</td>
<td>396.90</td>
<td>36.2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p style="text-align:justify">
The data looks clean and ready to implement to the KNNRegressor. Note that, for predictive modeling we need a lot of things, such as exporatory data analysis (EDA), feature engineering, preprocessing and others. However, we will simply apply the <code>KNNRegressor</code> that we built from scratch and built-in library function from <code>scikit-learn</code> to explore the algorithm and find the optimal <img src="https://latex.codecogs.com/png.latex?K">.
</p>
<div id="865cb1d1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KFold, train_test_split</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error,r2_score</span>
<span id="cb8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt </span>
<span id="cb8-4"></span>
<span id="cb8-5"></span>
<span id="cb8-6">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MEDV'</span>,axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-7">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MEDV'</span>]</span>
<span id="cb8-8"></span>
<span id="cb8-9">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(</span>
<span id="cb8-10">    X,y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.30</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span></span>
<span id="cb8-11">)</span>
<span id="cb8-12">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb8-13">X_train_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(X_train)</span>
<span id="cb8-14">X_test_sc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.transform(X_test)</span>
<span id="cb8-15"></span>
<span id="cb8-16">k_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>]</span>
<span id="cb8-17"></span>
<span id="cb8-18">kfold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KFold(n_splits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb8-19">mses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb8-20"></span>
<span id="cb8-21"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i,(train_index,test_index) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(kfold.split(X_train_sc)):</span>
<span id="cb8-22">    X_train_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_sc[train_index]</span>
<span id="cb8-23">    X_train_holdout <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_sc[test_index]</span>
<span id="cb8-24"></span>
<span id="cb8-25">    y_train_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train.iloc[train_index]</span>
<span id="cb8-26">    y_train_holdout <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train.iloc[test_index]</span>
<span id="cb8-27"></span>
<span id="cb8-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j,k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(k_values):</span>
<span id="cb8-29">        regressor1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomKNNRegressor(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>k)</span>
<span id="cb8-30">        regressor1.fit(X_train_train, y_train_train)</span>
<span id="cb8-31">        preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> regressor1.predict(X_train_holdout)</span>
<span id="cb8-32">        mses[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(preds, y_train_holdout)</span>
<span id="cb8-33"></span>
<span id="cb8-34">plt.scatter(np.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Single Split'</span>)</span>
<span id="cb8-35">plt.scatter(np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb8-36">plt.scatter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb8-37">plt.scatter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb8-38">plt.scatter([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], np.mean(mses, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>,c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mean'</span>)</span>
<span id="cb8-39">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>)</span>
<span id="cb8-40">plt.xticks([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>],[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=5'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=15'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=30'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=40'</span>])</span>
<span id="cb8-41">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MSE'</span>)</span>
<span id="cb8-42">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb8-43">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb8-44">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://mrislambd.github.io/posts/knn/index_files/figure-html/cell-6-output-1.png" width="585" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>So, <img src="https://latex.codecogs.com/png.latex?K=5"> seems optimal based on our custom built regressor. Now if we do the same thing using the <code>scikit-learn</code> library</p>
<div id="f30065f6" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KNeighborsRegressor</span>
<span id="cb9-2"></span>
<span id="cb9-3"></span>
<span id="cb9-4">mses <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i,(train_index,test_index) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(kfold.split(X_train_sc)):</span>
<span id="cb9-7">    X_train_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_sc[train_index]</span>
<span id="cb9-8">    X_train_holdout <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_sc[test_index]</span>
<span id="cb9-9"></span>
<span id="cb9-10">    y_train_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train.iloc[train_index]</span>
<span id="cb9-11">    y_train_holdout <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train.iloc[test_index]</span>
<span id="cb9-12"></span>
<span id="cb9-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j,k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(k_values):</span>
<span id="cb9-14">        regressor2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KNeighborsRegressor(k)</span>
<span id="cb9-15">        regressor2.fit(X_train_train, y_train_train)</span>
<span id="cb9-16">        preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> regressor2.predict(X_train_holdout)</span>
<span id="cb9-17">        mses[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(preds, y_train_holdout)</span>
<span id="cb9-18"></span>
<span id="cb9-19">plt.scatter(np.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Single Split'</span>)</span>
<span id="cb9-20">plt.scatter(np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb9-21">plt.scatter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb9-22">plt.scatter(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.ones(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>),mses[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>],s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)</span>
<span id="cb9-23">plt.scatter([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], np.mean(mses, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>,c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mean'</span>)</span>
<span id="cb9-24">plt.legend(loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper right'</span>)</span>
<span id="cb9-25">plt.xticks([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>],[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=5'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=15'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=30'</span>,<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'K=40'</span>])</span>
<span id="cb9-26">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MSE'</span>)</span>
<span id="cb9-27">plt.gca().set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb9-28">plt.gcf().patch.set_facecolor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#f4f4f4'</span>)</span>
<span id="cb9-29">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://mrislambd.github.io/posts/knn/index_files/figure-html/cell-7-output-1.png" width="585" height="411" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>In both method, we got <img src="https://latex.codecogs.com/png.latex?K=5"> is the optimal number of neighbors for KNN regression. Let’s apply this in our test dataset</p>
<div id="c479b80a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">regressor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CustomKNNRegressor(k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb10-2">regressor.fit(X_train_sc, y_train)</span>
<span id="cb10-3"></span>
<span id="cb10-4">predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> regressor.predict(X_test_sc)</span>
<span id="cb10-5"></span>
<span id="cb10-6">mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(predictions,y_test)</span>
<span id="cb10-7">rsquared <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r2_score(predictions,y_test)</span>
<span id="cb10-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MSE = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(mse,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)),<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' and R-square = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(rsquared,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MSE = 41.26  and R-square = 0.23</code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p style="text-align: justify">
K-Nearest Neighbors is a simple, intuitive algorithm that can be highly effective in both classification and regression problems. Its simplicity comes from the fact that it doesn’t make any assumptions about the underlying data distribution (it’s non-parametric). However, its performance can be sensitive to the choice of <strong>K</strong> and the distance metric. <br> <br> Although it’s easy to implement, KNN can become computationally expensive for large datasets, as it requires calculating distances between the test point and all training samples. <br> <br> If you need an efficient version, it’s always possible to use optimized libraries like scikit-learn, but writing the algorithm from scratch helps build a solid understanding.
</p>
</section>
<section id="when-to-use-knn-over-linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-knn-over-linear-regression">When to Use KNN Over Linear Regression?</h3>
<p>We would consider using KNN regression over linear regression in the following situations:</p>
<ul>
<li><strong>Non-linear relationships</strong>: When the data shows non-linear patterns or complex relationships between features and target variables that cannot be captured by a straight line.<br>
</li>
<li><strong>Local behavior</strong>: When data has local patterns or clusters, and you believe that predictions should rely on the nearest data points.<br>
</li>
<li><strong>Minimal assumptions</strong>: If you do not want to assume a specific relationship between the features and target, KNN’s non-parametric nature might be more appropriate.<br>
</li>
<li><strong>Smaller datasets</strong>: KNN works well with smaller datasets and lower-dimensional data where calculating distances is feasible and efficient.</li>
</ul>
<p>However, KNN becomes less efficient and struggles in high dimensions or when the dataset is large. In those cases, linear regression or other more scalable models may be more appropriate</p>
<hr>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><strong>KNN Regressor Overview:</strong>
<ul>
<li>Géron, Aurélien. <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</em>. O’Reilly Media, 2019. This book provides an in-depth explanation of KNN, including its behavior in non-linear data and high-dimensionality challenges.</li>
<li>Bishop, Christopher M. <em>Pattern Recognition and Machine Learning</em>. Springer, 2006. This book covers non-parametric methods like KNN, highlighting the “curse of dimensionality” and distance-based approaches.</li>
</ul></li>
<li><strong>KNN vs.&nbsp;Linear Regression (Model Assumptions &amp; Complexity of Data):</strong>
<ul>
<li>Hastie, Trevor, Tibshirani, Robert, and Friedman, Jerome. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer, 2009. This source discusses the assumptions behind linear regression and the flexibility of non-parametric models like KNN.</li>
<li>Kuhn, Max, and Johnson, Kjell. <em>Applied Predictive Modeling</em>. Springer, 2013. The comparison between parametric (like linear regression) and non-parametric models (like KNN) is elaborated in this book.</li>
</ul></li>
<li><strong>Interpretability:</strong>
<ul>
<li>Molnar, Christoph. <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>. 2019. This book emphasizes the trade-offs between interpretable models like linear regression and more black-box models like KNN.</li>
<li>Murdoch, W. James, et al.&nbsp;“Definitions, methods, and applications in interpretable machine learning.” <em>Proceedings of the National Academy of Sciences</em> 116.44 (2019): 22071-22080.</li>
</ul></li>
<li><strong>Sensitivity to Outliers:</strong>
<ul>
<li>Aggarwal, Charu C. <em>Data Classification: Algorithms and Applications</em>. Chapman and Hall/CRC, 2014. This discusses the impact of outliers on different models, including linear regression and KNN.</li>
<li>Friedman, Jerome, et al.&nbsp;<em>The Elements of Statistical Learning</em>. Springer Series in Statistics, 2001. Sensitivity to outliers is compared across various regression techniques, including KNN.</li>
</ul></li>
<li><strong>Handling High-Dimensional Data:</strong>
<ul>
<li>Domingos, Pedro. “A few useful things to know about machine learning.” <em>Communications of the ACM</em> 55.10 (2012): 78-87. This paper discusses challenges like the curse of dimensionality in models like KNN.</li>
<li>Verleysen, Michel, and François, Damien. “The curse of dimensionality in data mining and time series prediction.” <em>International Work-Conference on Artificial Neural Networks</em>. Springer, 2005.</li>
</ul></li>
<li><strong>Training and Prediction Time:</strong>
<ul>
<li>Shalev-Shwartz, Shai, and Ben-David, Shai. <em>Understanding Machine Learning: From Theory to Algorithms</em>. Cambridge University Press, 2014. Provides insights into the computational cost differences between linear and non-parametric models like KNN.</li>
<li>Li, Zhe, et al.&nbsp;“Fast k-nearest neighbor search using GPU.” <em>International Conference on Image and Graphics</em>. Springer, 2015. This paper discusses computational complexity related to KNN.</li>
</ul></li>
<li><strong>Overfitting and Flexibility:</strong>
<ul>
<li>Yao, Ying, et al.&nbsp;“Overfitting and Underfitting: A Visual Explanation.” Towards Data Science, 2019. Offers a visual and intuitive explanation of the bias-variance tradeoff in KNN and linear models.</li>
<li>Rasmussen, Carl E., and Williams, Christopher KI. <em>Gaussian Processes for Machine Learning</em>. MIT Press, 2006. Discusses overfitting in KNN due to small values of <code>k</code> and regularization techniques for linear models.</li>
</ul></li>
</ol>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/knn/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/knn/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {K {Nearest} {Neighbors} {Regression}},
  date = {2024-08-29},
  url = {https://mrislambd.github.io/posts/knn/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“K Nearest Neighbors Regression.”</span>
August 29, 2024. <a href="https://mrislambd.github.io/posts/knn/">https://mrislambd.github.io/posts/knn/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/knn/</guid>
  <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/knn/knn.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Multiple Liear Regression</title>
  <dc:creator>Rafiq Islam</dc:creator>
  <link>https://mrislambd.github.io/posts/multiplelinreg/</link>
  <description><![CDATA[ 




<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h2>
<p>The multiple linear regression takes the form<br>
<img src="https://latex.codecogs.com/png.latex?%0Ay=%5Cbeta_0+%5Cbeta_1%20x_1+%5Cbeta_2%20x_2+%5Ccdots%20+%5Cbeta_d%20x_d+%5Cxi=%5Cvec%7Bx%7D%5Ccdot%20%5Cvec%7B%5Cbeta%7D+%5Cxi%0A"></p>
<p>with <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Cbeta_i%5C%7D_%7Bi=0%7D%5E%7Bd%7D%5Cin%20%5Cmathbb%7BR%7D"> constants or parameters of the model. In vector notation, <img src="https://latex.codecogs.com/png.latex?%5Cvec%7B%5Cbeta%7D%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd+1%7D">,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cvec%7B%5Cbeta%7D=%5Cbegin%7Bpmatrix%7D%5Cbeta_0%5C%5C%20%5Cbeta_1%5C%5C%20%5Cvdots%20%5C%5C%20%5Cbeta_d%20%5Cend%7Bpmatrix%7D;%5Chspace%7B4mm%7D%5Cvec%7Bx%7D=%5Cbegin%7Bpmatrix%7D1%5C%5C%20x_1%5C%5C%20x_2%5C%5C%20%5Cvdots%5C%5C%20x_d%5Cend%7Bpmatrix%7D%0A"></p>
<p>For <img src="https://latex.codecogs.com/png.latex?n"> data points, in matrix algebra notation, we can write <img src="https://latex.codecogs.com/png.latex?y=X%5Cvec%7B%5Cbeta%7D+%5Cxi"> where <img src="https://latex.codecogs.com/png.latex?X%5Cin%20%5Cmathcal%7BM%7D_%7Bn%5Ctimes%20(d+1)%7D"> and <img src="https://latex.codecogs.com/png.latex?y%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd+1%7D"> with</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX=%5Cbegin%7Bpmatrix%7D1&amp;x_%7B11%7D&amp;x_%7B12%7D&amp;%5Ccdots&amp;x_%7B1d%7D%5C%5C1&amp;x_%7B21%7D&amp;x_%7B22%7D&amp;%5Ccdots&amp;x_%7B2d%7D%5C%5C%20%5Cvdots&amp;%20%5Cvdots%20&amp;%5Cvdots&amp;%5Cddots%20&amp;%5Cvdots%5C%5C1&amp;x_%7Bn1%7D&amp;x_%7Bn2%7D&amp;%5Ccdots&amp;x_%7Bnd%7D%20%5Cend%7Bpmatrix%7D;%5Chspace%7B4mm%7D%20y=%5Cbegin%7Bpmatrix%7Dy_1%5C%5Cy_2%5C%5C%20%5Cvdots%5C%5C%20y_n%5Cend%7Bpmatrix%7D;%5Chspace%7B4mm%7D%20%5Cxi=%5Cbegin%7Bpmatrix%7D%5Cxi_1%5C%5C%20%5Cxi_2%5C%5C%20%5Cvdots%5C%5C%20%5Cxi_n%5Cend%7Bpmatrix%7D%0A"></p>
<p>We fit the <img src="https://latex.codecogs.com/png.latex?n"> data points with the objective to minimize the loss function, mean squared error</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AMSE(%5Cvec%7B%5Cbeta%7D)=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cleft(y_i-f_%7B%5Cvec%7B%5Cbeta%7D%7D(%5Cvec%7Bx%7D_i)%5Cright)%5E2=%5Cfrac%7B1%7D%7Bn%7D%5Cleft%7C%5Cvec%7By%7D-X%5Cvec%7B%5Cbeta%7D%5Cright%7C%5E2%0A"></p>
</section>
<section id="ordinary-least-square-method" class="level2">
<h2 class="anchored" data-anchor-id="ordinary-least-square-method">Ordinary Least Square Method</h2>
<p style="text-align: justify">
The <code>scikit-learn</code> library uses <strong><em>Ordinary Least Squares (OLS)</em></strong> method to find the parameters. This method is good for a simple and relatively smaller dataset. Here is a short note on this method. However, when the dimension is very high and the dataset is bigger, <code>scikit-learn</code> uses another method called <strong><em>Stochastic Gradient Descent</em></strong> for optimization which is discussed in the next section.
</p>
<p>The goal of OLS is to find the parameter vector <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D"> that minimizes the sum of squared errors (SSE) between the observed target values <img src="https://latex.codecogs.com/png.latex?y"> and the predicted values <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSSE%7D%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By%7D_i)%5E2%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20X_i%5Cbeta)%5E2%0A"></p>
<p>This can be expressed in matrix form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSSE%7D%20=%20(y%20-%20X%5Cbeta)%5ET(y%20-%20X%5Cbeta)%0A"></p>
<p>To minimize the SSE, let’s first expand the expression:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign%7D%0A%5Ctext%7BSSE%7D%20&amp;=%20(y%20-%20X%5Cbeta)%5ET(y%20-%20X%5Cbeta)%5C%5C%0A&amp;=(y%5ET-%5Cbeta%5ETX%5ET)(y-X%5Cbeta)%5C%5C%0A&amp;%20=%20y%5ET%20y%20-%20y%5ET%20X%5Cbeta%20-%20%5Cbeta%5ET%20X%5ET%20y%20+%20%5Cbeta%5ET%20X%5ET%20X%20%5Cbeta%0A%5Cend%7Balign%7D"></p>
<p>Since <img src="https://latex.codecogs.com/png.latex?%5Cbeta%5ET%20X%5ET%20y"> is a scalar (a 1x1 matrix), it is equal to its transpose. That is</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Balign*%7D%0A%5Cbeta%5ETX%5ETy&amp;=%5Cleft(%5Cbeta%5ETX%5ETy%5Cright)%5ET%5C%5C%0A&amp;=%20%5Cleft((%5Cbeta%5ETX%5ET)y%5Cright)%5ET%5C%5C%0A&amp;=y%5ET(%5Cbeta%5ETX%5ET)%5ET%5C%5C%0A&amp;=y%5ET(%5Cbeta%5ETX%5ET)%5ET%5C%5C%0A&amp;=y%5ET%5Cleft(X%5ET%5Cright)%5ET%5Cleft(%5Cbeta%5ET%5Cright)%5ET%5C%5C%0A&amp;=y%5ETX%5Cbeta%0A%5Cend%7Balign*%7D"></p>
<p>and therefore,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSSE%7D%20=%20y%5ET%20y%20-%202%5Cbeta%5ET%20X%5ET%20y%20+%20%5Cbeta%5ET%20X%5ET%20X%20%5Cbeta%0A"></p>
<p>To find the minimum of the SSE, we take the derivative with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and set it to zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20%5Ctext%7BSSE%7D%7D%7B%5Cpartial%20%5Cbeta%7D%20=%20-2X%5ET%20y%20+%202X%5ET%20X%20%5Cbeta%20=%200%0A"></p>
<p>Now, solve for <img src="https://latex.codecogs.com/png.latex?%5Cbeta">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%5ET%20X%20%5Cbeta%20=%20X%5ET%20y%0A"></p>
<p>To isolate <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we multiply both sides by <img src="https://latex.codecogs.com/png.latex?(X%5ET%20X)%5E%7B-1%7D"> (assuming <img src="https://latex.codecogs.com/png.latex?X%5ET%20X"> is invertible):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta%20=%20(X%5ET%20X)%5E%7B-1%7D%20X%5ET%20y%0A"></p>
<p style="text-align: justify">
The vector <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D%20=%20(X%5ET%20X)%5E%7B-1%7D%20X%5ET%20y"> gives the estimated coefficients that minimize the sum of squared errors between the observed target values <img src="https://latex.codecogs.com/png.latex?y"> and the predicted values <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D%20=%20X%5Chat%7B%5Cbeta%7D">. This method is exact and works well when <img src="https://latex.codecogs.com/png.latex?X%5ET%20X"> is invertible and the dataset size is manageable. <br> <br> This method is very efficient for small to medium-sized datasets but can become computationally expensive for very large datasets due to the inversion of the matrix <img src="https://latex.codecogs.com/png.latex?X%5ETX">.
</p>
</section>
<section id="iterative-method" class="level2">
<h2 class="anchored" data-anchor-id="iterative-method">Iterative Method</h2>
<section id="gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h3>
<p style="text-align: justify">
<img align="right" height="350" width="450" src="https://mrislambd.github.io/posts/multiplelinreg/gradient_descent.gif" alt="Collected from gbhat.com" style="margin-left: 20px; margin-bottom: 20px"> <br> GIF Credit: <a href="https://gbhat.com/machine_learning/gradient_descent_anim.html" target="_blank" style="text-decoration:none">gbhat.com</a><br>
<br> Gradient Descent is an optimization algorithm used to minimize the cost function. The cost function <img src="https://latex.codecogs.com/png.latex?f(%5Cbeta)"> measures how well a model with parameters <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> fits the data. The goal is to find the values of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> that minimize this cost function. In terms of the iterative method, we want to find <img src="https://latex.codecogs.com/png.latex?%5Cbeta_%7Bk+1%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k"> such that <img src="https://latex.codecogs.com/png.latex?f(%5Cbeta_%7Bk+1%7D)%3Cf(%5Cbeta_k)">. <br> <br> For a small change in <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we can approximate <img src="https://latex.codecogs.com/png.latex?f(%5Cbeta)"> using Taylor series expansion<br>
<img src="https://latex.codecogs.com/png.latex?f(%5Cbeta_%7Bk+1%7D)=f(%5Cbeta_k%20+%5CDelta%5Cbeta_k)%5Capprox%20f(%5Cbeta_k)+%5Cnabla%20f(%5Cbeta_k)%5ET%20%5CDelta%20%5Cbeta_k+%5Ctext%7Bhigher-order%20terms%7D">
</p>
<p>The update rule for vanilla gradient descent is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7Bk+1%7D%20=%20%5Cbeta_k%20-%20%5Ceta%20%5Cnabla%20f(%5Cbeta_k)%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta_k"> is the current estimate of the parameters at iteration <img src="https://latex.codecogs.com/png.latex?k">.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate, a small positive scalar that controls the step size.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cnabla%20f(%5Cbeta_k)"> is the gradient of the cost function <img src="https://latex.codecogs.com/png.latex?f"> with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> at the current point <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k">.</li>
</ul>
<p style="text-align: justify">
</p><p>The update rule comes from the idea of moving the parameter vector <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> in the direction that decreases the cost function the most.</p>
<ol type="1">
<li><p><strong>Gradient</strong>: The gradient <img src="https://latex.codecogs.com/png.latex?%5Cnabla%20f(%5Cbeta_k)"> represents the direction and magnitude of the steepest ascent of the function <img src="https://latex.codecogs.com/png.latex?f"> at the point <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k">. Since we want to minimize the function, we move in the opposite direction of the gradient.</p></li>
<li><p><strong>Step Size</strong>: The term <img src="https://latex.codecogs.com/png.latex?%5Ceta%20%5Cnabla%20f(%5Cbeta_k)"> scales the gradient by the learning rate <img src="https://latex.codecogs.com/png.latex?%5Ceta">, determining how far we move in that direction. If <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is too large, the algorithm may overshoot the minimum; if it’s too small, the convergence will be slow.</p></li>
<li><p><strong>Iterative Update</strong>: Starting from an initial guess <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0">, we repeatedly apply the update rule until the algorithm converges, meaning that the changes in <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k"> become negligible, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k"> is close to the optimal value <img src="https://latex.codecogs.com/png.latex?%5Cbeta%5E*">.</p></li>
</ol>
</section>
<section id="stochastic-gradient-descent-sgd" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h3>
<p style="text-align: justify">
Stochastic Gradient Descent is a variation of the vanilla gradient descent. Instead of computing the gradient using the entire dataset, SGD updates the parameters using only a single data point or a small batch of data points at each iteration. The later one we call it mini batch SGD.
</p>
<p>Suppose our cost function is defined as the average over a dataset of size <img src="https://latex.codecogs.com/png.latex?n">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(%5Cbeta)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20f_i(%5Cbeta)%0A"></p>
<p>Where <img src="https://latex.codecogs.com/png.latex?f_i(%5Cbeta)"> represents the contribution of the <img src="https://latex.codecogs.com/png.latex?i">-th data point to the total cost function. The gradient of the cost function with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%20f(%5Cbeta)%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Cnabla%20f_i(%5Cbeta)%0A"></p>
<p>Vanilla gradient descent would update the parameters as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7Bk+1%7D%20=%20%5Cbeta_k%20-%20%5Ceta%20%5Cnabla%20f(%5Cbeta_k)%0A"></p>
<p>Instead of using the entire dataset to compute the gradient, SGD approximates the gradient by using only a single data point (or a small batch). The update rule for SGD is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7Bk+1%7D%20=%20%5Cbeta_k%20-%20%5Ceta%20%5Cnabla%20f_%7Bi_k%7D(%5Cbeta_k)%0A"></p>
<p>Where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?i_k"> is the index of a randomly selected data point at iteration <img src="https://latex.codecogs.com/png.latex?k">.</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cnabla%20f_%7Bi_k%7D(%5Cbeta_k)"> is the gradient of the cost function with respect to the parameter <img src="https://latex.codecogs.com/png.latex?%5Cbeta_k">, evaluated only at the data point indexed by <img src="https://latex.codecogs.com/png.latex?i_k">.</li>
</ul>
</section>
</section>
<section id="python-execution" class="level2">
<h2 class="anchored" data-anchor-id="python-execution">Python Execution</h2>
<section id="synthetic-data" class="level3">
<h3 class="anchored" data-anchor-id="synthetic-data">Synthetic Data</h3>
<div id="358a062d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-3">X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb1-4">y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span></code></pre></div>
</div>
<p>So for this project, our known relationship is <img src="https://latex.codecogs.com/png.latex?y=1+3x_1+2x_2+%5Cxi">.</p>
</section>
<section id="fit-the-data-using-scikit-learn-library" class="level3">
<h3 class="anchored" data-anchor-id="fit-the-data-using-scikit-learn-library">Fit the data: Using scikit-learn Library</h3>
<div id="79a82125" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">mlr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>LinearRegression()</span>
<span id="cb2-2">mlr.fit(X,y)</span>
<span id="cb2-3">coefficients<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr.coef_.tolist()</span>
<span id="cb2-4">slope<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr.intercept_.tolist()</span></code></pre></div>
</div>
<p>So the model parameters: slope <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0="> 1.0398 and coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta_1="> 3.0251, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_2="> 1.956</p>
</section>
<section id="fit-the-data-using-custom-library-ols" class="level3">
<h3 class="anchored" data-anchor-id="fit-the-data-using-custom-library-ols">Fit the data: Using Custom Library OLS</h3>
<p>First we create our custom <code>NewLinearRegression</code> using the OLS formula above and save this <code>python</code> class as <code>mlreg.py</code></p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb3-2"></span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> NewLinearRegression:</span>
<span id="cb3-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb3-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb3-7"></span>
<span id="cb3-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y):</span>
<span id="cb3-9">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([np.ones((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(X), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), X], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-10">        X_transpose_X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X.transpose(), X)</span>
<span id="cb3-11">        X_transpose_X_inverse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linalg.inv(X_transpose_X)</span>
<span id="cb3-12">        X_transpose_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X.transpose(), y)</span>
<span id="cb3-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X_transpose_X_inverse, X_transpose_y)</span>
<span id="cb3-14"></span>
<span id="cb3-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb3-16">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([np.ones((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(X), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), X], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.dot(X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta)</span>
<span id="cb3-18"></span>
<span id="cb3-19">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> coeff_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:].tolist()</span>
<span id="cb3-21"></span>
<span id="cb3-22">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> interceptt_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb3-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.beta[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].tolist()</span></code></pre></div>
<p>Now it’s time to use the new class</p>
<div id="fa12dd8a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mlreg <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> NewLinearRegression</span>
<span id="cb4-2">mlr1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NewLinearRegression()</span>
<span id="cb4-3">mlr1.fit(X,y)</span>
<span id="cb4-4">coefficients1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr1.coeff_()</span>
<span id="cb4-5">slope1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr1.interceptt_()</span></code></pre></div>
</div>
<p>So the model parameters: slope <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0="> 1.0398 and coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta_1="> 3.0251, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_2="> 1.956</p>
</section>
<section id="fit-the-data-using-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="fit-the-data-using-gradient-descent">Fit the data: Using Gradient Descent</h3>
<p>We create the class</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> GDLinearRegression:</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, number_of_iteration<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb5-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learning_rate</span>
<span id="cb5-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.number_of_iteration <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> number_of_iteration</span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb5-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb5-7"></span>
<span id="cb5-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y):</span>
<span id="cb5-9">        num_of_samples, num_of_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape</span>
<span id="cb5-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(num_of_features)</span>
<span id="cb5-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb5-12"></span>
<span id="cb5-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.number_of_iteration):</span>
<span id="cb5-14">            y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias</span>
<span id="cb5-15"></span>
<span id="cb5-16">            d_weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> num_of_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.dot(X.T, (y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y))</span>
<span id="cb5-17">            d_bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> num_of_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y)</span>
<span id="cb5-18"></span>
<span id="cb5-19">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> d_weights</span>
<span id="cb5-20">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> d_bias</span>
<span id="cb5-21"></span>
<span id="cb5-22">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb5-23">        y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias</span>
<span id="cb5-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> y_predicted</span>
<span id="cb5-25"></span>
<span id="cb5-26">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> coefff_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.weights.tolist()</span>
<span id="cb5-28"></span>
<span id="cb5-29">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> intercepttt_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bias</span></code></pre></div>
<p>Now we use this similarly as before,</p>
<div id="2bd79bc8" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mlreg <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GDLinearRegression</span>
<span id="cb6-2">mlr2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GDLinearRegression(learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.008</span>)</span>
<span id="cb6-3">mlr2.fit(X,y)</span>
<span id="cb6-4">coefficients2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr2.coefff_()</span>
<span id="cb6-5">slope2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>mlr2.intercepttt_()</span></code></pre></div>
</div>
<p>So the model parameters: slope <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0="> 1.0396 and coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta_1="> 3.0239, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_2="> 1.9555</p>
</section>
<section id="fit-the-data-using-stochastic-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="fit-the-data-using-stochastic-gradient-descent">Fit the data: Using Stochastic Gradient Descent</h3>
<p>First we define the class</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> SGDLinearRegression:</span>
<span id="cb7-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, num_iterations<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb7-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learning_rate</span>
<span id="cb7-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_iterations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> num_iterations</span>
<span id="cb7-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> batch_size</span>
<span id="cb7-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb7-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mse_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize mse_list as an instance attribute</span></span>
<span id="cb7-8"></span>
<span id="cb7-9">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _loss_function(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y, beta):</span>
<span id="cb7-10">        num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)</span>
<span id="cb7-11">        y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.dot(beta)</span>
<span id="cb7-12">        mse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>num_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(np.square(y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y))</span>
<span id="cb7-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> mse</span>
<span id="cb7-14"></span>
<span id="cb7-15">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _gradient_function(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y, beta):</span>
<span id="cb7-16">        num_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)</span>
<span id="cb7-17">        y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.dot(beta)</span>
<span id="cb7-18">        grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>num_samples) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X.T.dot(y_predicted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y)</span>
<span id="cb7-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> grad</span>
<span id="cb7-20"></span>
<span id="cb7-21">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> fit(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X, y):</span>
<span id="cb7-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding the intercept term (bias) as a column of ones</span></span>
<span id="cb7-23">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([np.ones((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(X), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), X], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-24">        num_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb7-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((num_features, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb7-26"></span>
<span id="cb7-27">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mse_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_iterations)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize mse_list</span></span>
<span id="cb7-28"></span>
<span id="cb7-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_iterations):</span>
<span id="cb7-30">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Randomly select a batch of data points</span></span>
<span id="cb7-31">            indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.choice(</span>
<span id="cb7-32">                <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y), size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.batch_size, replace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-33">            X_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[indices]</span>
<span id="cb7-34">            y_i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y[indices].reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-35"></span>
<span id="cb7-36">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compute the gradient and update the weights</span></span>
<span id="cb7-37">            gradient <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._gradient_function(X_i, y_i, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta)</span>
<span id="cb7-38">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> gradient</span>
<span id="cb7-39"></span>
<span id="cb7-40">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Calculate loss for the entire dataset (optional)</span></span>
<span id="cb7-41">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mse_list[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._loss_function(X, y, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta)</span>
<span id="cb7-42"></span>
<span id="cb7-43">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mse_list</span>
<span id="cb7-44"></span>
<span id="cb7-45">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, X):</span>
<span id="cb7-46">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding the intercept term (bias) as a column of ones</span></span>
<span id="cb7-47">        X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate([np.ones((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(X), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), X], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb7-48">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X.dot(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta)</span>
<span id="cb7-49"></span>
<span id="cb7-50">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> coef_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-51">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the coefficients (excluding the intercept term)</span></span>
<span id="cb7-52">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:].flatten().tolist()</span>
<span id="cb7-53"></span>
<span id="cb7-54">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> intercept_(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-55">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the intercept term</span></span>
<span id="cb7-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.theta[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].item()</span>
<span id="cb7-57"></span>
<span id="cb7-58">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> mse_losses(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-59">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return the mse_list</span></span>
<span id="cb7-60">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mse_list.tolist()</span></code></pre></div>
<p>Now</p>
<div id="8b71f236" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mlreg <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SGDLinearRegression</span>
<span id="cb8-3">mlr3<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>SGDLinearRegression(learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, num_iterations<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb8-4">theta, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mlr3.fit(X, y)</span></code></pre></div>
</div>
<p>So the model parameters: slope <img src="https://latex.codecogs.com/png.latex?%5Cbeta_0="> array([1.07525686]) and coefficients <img src="https://latex.codecogs.com/png.latex?%5Cbeta_1="> array([3.02412508]), and <img src="https://latex.codecogs.com/png.latex?%5Cbeta_2="> array([1.96354577])</p>
<p>Up next <a href="../../posts/knn/index.html">knn regression</a></p>
<hr>
<p><strong>Share on</strong></p>
<div class="columns">
<div class="column" style="width:33%;">
<p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1877F2; text-decoration: none;">
<p><i class="fa-brands fa-facebook fa-3x" aria-label="facebook"></i></p>
</a><p><a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1877F2; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#0077B5; text-decoration: none;">
<p><i class="fa-brands fa-linkedin fa-3x" aria-label="linkedin"></i></p>
</a><p><a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#0077B5; text-decoration: none;"></a></p>
</div><div class="column" style="width:33%;">
<p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
<p><i class="fa-brands fa-twitter fa-3x" aria-label="twitter"></i></p>
</a><p><a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/multiplelinreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;"></a></p>
</div>
</div>
<script src="https://giscus.app/client.js" data-repo="mrislambd/mrislambd.github.io" data-repo-id="R_kgDOMV8crA" data-category="Announcements" data-category-id="DIC_kwDOMV8crM4CjbQW" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<div id="fb-root">

</div>
<script async="" defer="" crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&amp;version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/multiplelinreg/" data-width="750" data-numposts="5">

</div>
<p><strong>You may also like</strong></p>



<!-- -->

</section>
</section>

<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1729569600000" data-listing-file-modified-sort="1742008558898" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2300">
<a href="../../posts/bayesianclassification/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian Probabilistic Models for Classification
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Tuesday, October 22, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Machine Learning,Data Science,Bayesian Inference,Bayesian Statistics,Statistics" data-listing-date-sort="1733115600000" data-listing-file-modified-sort="1742007975516" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="7" data-listing-word-count-sort="1271">
<a href="../../posts/adaboost/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img loading="lazy" src="https://mrislambd.github.io/posts/adaboost/ada1.png" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Boosting Algorithm: Adaptive Boosting Method (AdaBoost)
</h5>
<div class="listing-reading-time card-text text-muted">
7 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Monday, December 2, 2024
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics,Data Science,Data Engineering,Machine Learning,Artificial Intelligence" data-listing-date-sort="1728532800000" data-listing-file-modified-sort="1742010218456" data-listing-date-modified-sort="NaN" data-listing-reading-time-sort="12" data-listing-word-count-sort="2365">
<a href="../../posts/naivebayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top"><img src="https://mrislambd.github.io/posts/bayesianclassification/Bayeslearn.png" style="height: 150px;" class="thumbnail-image card-img"></p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Classification using Naive Bayes algorithm
</h5>
<div class="listing-reading-time card-text text-muted">
12 min
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Rafiq Islam
</div>
<div class="listing-date">
Thursday, October 10, 2024
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div><a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{islam2024,
  author = {Islam, Rafiq},
  title = {Multiple {Liear} {Regression}},
  date = {2024-08-29},
  url = {https://mrislambd.github.io/posts/multiplelinreg/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-islam2024" class="csl-entry quarto-appendix-citeas">
Islam, Rafiq. 2024. <span>“Multiple Liear Regression.”</span> August 29,
2024. <a href="https://mrislambd.github.io/posts/multiplelinreg/">https://mrislambd.github.io/posts/multiplelinreg/</a>.
</div></div></section></div> ]]></description>
  <category>Data Science</category>
  <category>Machine Learning</category>
  <category>Artificial Intelligence</category>
  <guid>https://mrislambd.github.io/posts/multiplelinreg/</guid>
  <pubDate>Thu, 29 Aug 2024 04:00:00 GMT</pubDate>
  <media:content url="https://mrislambd.github.io/posts/multiplelinreg/mlr.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
