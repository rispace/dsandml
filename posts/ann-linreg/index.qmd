---
title: "Artificial Neural Network (ANN) - Regression"
date: "2025-03-25"
author: Rafiq Islam
categories: [Data Science, Machine Learning, Artificial Intelligence]
citation: true
search: true
lightbox: true
image: lin.png
listing: 
    contents: "/../../posts"
    max-items: 3
    type: grid
    categories: true
    date-format: full
    fields: [image, date, title, author, reading-time]  
format: 
    html: default
    ipynb: default
    docx: 
      toc: true
      adsense:
        enable-ads: false
    epub:
      toc: true
      adsense:
        enable-ads: false
    pdf: 
      toc: true
      pdf-engine: pdflatex
      adsense:
        enable-ads: false
      number-sections: false
      colorlinks: true
      cite-method: biblatex
toc-depth: 4
---  

## Simple Linear Regression Using ANN  

The simple linear regression equation is given as  

$$
y_i = \beta_0+\beta_1 x_i + \xi_i = \sigma (w_0+\mathbf{x}^T\mathbf{w})=\sigma (\mathbf{x}^T\mathbf{w})
$$  

```{python}
#| echo: false
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from mywebstyle import plot_style
plot_style('#f4f4f4')

# Create figure and axis
fig, ax = plt.subplots(figsize=(8, 4))
ax.set_xlim(0, 12)
ax.set_ylim(0, 5)
ax.axis('off')


# Define node positions
nodes = {
    'x0': (0.5, 4),
    'x1': (0.5, 2),
    'sum': (2.5, 3),
    'sigma': (4.5, 3),
    'hidden': (6.5, 3),
    'output': (8.5, 3),
    'y': (8.5, 3)
}

# Draw arrows
def draw_arrow(start, end, label=None, color='black'):
    ax.annotate('', xy=end, xytext=start,
                arrowprops=dict(arrowstyle='->', color=color, lw=2))
    if label:
        mx, my = (start[0]+end[0])/2, (start[1]+end[1])/2
        ax.text(mx, my+0.3, label, ha='center', fontsize=12)

# Draw nodes
def draw_node(center, text, color='lightgray', edge_color='black'):
    circle = patches.Circle(center, radius=0.5, facecolor=color, edgecolor=edge_color, linewidth=2)
    ax.add_patch(circle)
    ax.text(center[0], center[1], text, fontsize=16, ha='center', va='center')

# Input labels
ax.text(*nodes['x0'], '$X_0$', fontsize=16, ha='right', va='center')
ax.text(*nodes['x1'], '$X_1$', fontsize=16, ha='right', va='center')

# Draw all arrows with labels
draw_arrow((0.5, 4), (2,3), '$w_0$', color='red')
draw_arrow((0.5, 2), (2,3), '$w_1$', color='red')
draw_arrow((3,3), (4,3))
draw_arrow((5,3), (6,3), '$w_2$', color='green')
draw_arrow((7,3), nodes['y'])

# Draw all nodes
draw_node(nodes['sum'], '∑', color='lightgray')
draw_node(nodes['sigma'], 'σ', color='honeydew', edge_color='darkgreen')
draw_node((6.5,3), '', color='mistyrose', edge_color='red')

# Output label
ax.text(*nodes['y'], 'y', fontsize=16, ha='left', va='center')

plt.tight_layout()
plt.savefig('lin.png')
plt.show()
```

The loss function in this case MSE: Mean Squared Error  

```{python}
import torch 
n = 50 
# Creating n=50 random X values from the standard normal distribution
X = torch.randn(n,1) 
# y = mX + c + noise. Here m=1, c = 0, noise = N(0,1)/2
y = X + torch.randn(n,1)/2 

plt.plot(X,y, 'ro')
plt.xlabel('X')
plt.ylabel('y')
plt.show()
```  

Now the model  

```{python}
import numpy as np
import torch.nn as nn 

ANN_regressor = nn.Sequential(
    nn.Linear(1,1), # Input Layer 
    nn.ReLU(),      # Rectified Linear Unit (ReLU) activation function
    nn.Linear(1,1)  # Output Layer
) 
ANN_regressor
``` 

Next we want to train our model using *Stochastic Gradient Descent* optimizer

```{python}
lr = 0.05                              # Learning rate/stepsize
loss_function = nn.MSELoss()           # MSE loss function  
optimizer = torch.optim.SGD(           # SGD Optimizer
    ANN_regressor.parameters(), 
    lr=lr
)

training_epochs = 500                  # Epochs
losses = torch.zeros(training_epochs)  # Creating 1D zero vector of size 500

# Train the model 

for epoch in range(training_epochs):

    # forward pass 
    pred = ANN_regressor(X)

    # compute the loss
    loss = loss_function(pred, y)
    losses[epoch] = loss

    # back propagation 
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

predictions = ANN_regressor(X)
test_loss = (predictions - y).pow(2).mean()

plt.plot(losses.detach())
plt.plot(training_epochs, test_loss.detach(), 'ro')
plt.title('Final Loss = %g' %test_loss.item())
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()
```  

Now let's calculate the predictions  

```{python}
plt.plot(X,y, 'ro', label = 'Data')
plt.plot(X,predictions.detach(), 'bs', label='Predictions')
plt.legend()
plt.show()
```  

Putting all together  

```{python}
#| warning: false
def ann_reg(X,y):
    model = nn.Sequential(
        nn.Linear(1,1),
        nn.ReLU(),
        nn.Linear(1,1)
    )
    loss_function = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.05)
    training_epochs = 500

    losses = torch.zeros(training_epochs)

    for epoch in range(training_epochs):
        pred = model(X)

        loss = loss_function(pred, y)
        losses[epoch] = loss 

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    return model(X), losses

def data(m):
    X = torch.randn(50,1)
    y = m*X + torch.randn(50,1)/2

    return X, y 

slopes = np.linspace(-2,2,21)

train = 30

results = np.zeros((len(slopes), train,2))

for m in range(len(slopes)):
    for t in range(train):
        X,y = data(slopes[m])
        prediction,loss = ann_reg(X,y)
        results[m, t, 0] = loss[-1]
        results[m, t, 1] = np.corrcoef(y.T,prediction.detach().T)[0,1]

results[np.isnan(results)]=0

fig, ax = plt.subplots(1,2, figsize=(8,4))

ax[0].plot(slopes, np.mean(results[:,:,0], axis=1),'ko-')
ax[0].set_xlabel('Slope')
ax[0].set_title('Loss')

ax[1].plot(slopes, np.mean(results[:,:,1],axis=1),'ms-')
ax[1].set_xlabel('Slope')
ax[1].set_ylabel('Real vs Predicted correlation')
ax[1].set_title('Model Performance')
plt.show()
```  

---  

**Share on**  

::::{.columns}
:::{.column width="33%"}
<a href="https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/ann-linreg/" target="_blank" style="color:#1877F2; text-decoration: none;">
 
{{< fa brands facebook size=3x >}}
</a>
 
:::
 
:::{.column width="33%"}
<a href="https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/ann-linreg/" target="_blank" style="color:#0077B5; text-decoration: none;">
 
{{< fa brands linkedin size=3x >}}
</a>
 
:::
 
:::{.column width="33%"}
<a href="https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/ann-linreg/" target="_blank" style="color:#1DA1F2; text-decoration: none;">
 
{{< fa brands twitter size=3x >}}
</a>
 
:::
::::
 
<script src="https://giscus.app/client.js"
        data-repo="mrislambd/mrislambd.github.io" 
        data-repo-id="R_kgDOMV8crA"
        data-category="Announcements"
        data-category-id="DIC_kwDOMV8crM4CjbQW"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
 
<div id="fb-root"></div>
<script async defer crossorigin="anonymous"
 src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v20.0"></script>
<div class="fb-comments" data-href="https://mrislambd.github.io/dsandml/posts/ann-linreg/" data-width="750" data-numposts="5"></div>  

**You may also like**