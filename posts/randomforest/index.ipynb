{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble Methods: Random Forest - A detailed overview\n",
        "\n",
        "Rafiq Islam  \n",
        "2024-10-07\n",
        "\n",
        "## Introduction"
      ],
      "id": "53f24a60-e64b-4c97-a5e2-1f97dd051718"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<p style=\"text-align: justify\">"
      ],
      "id": "04f7824b-9153-470b-b17f-673310b1c8bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest is one of the most popular machine learning algorithms,\n",
        "known for its simplicity, versatility, and ability to perform both\n",
        "classification and regression tasks. It operates by constructing a\n",
        "multitude of decision trees during training and outputs the mode of the\n",
        "classes (for classification) or the mean prediction (for regression) of\n",
        "the individual trees."
      ],
      "id": "18b3b9e3-9673-4715-b9d0-04497ba24c33"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</p>"
      ],
      "id": "f6bedbf3-7b52-4602-a308-2a2d3d0b94f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Random Forest?"
      ],
      "id": "f71c64d7-fea4-419e-b04a-acda262f75df"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<p style=\"text-align: justify\">"
      ],
      "id": "122cb11c-1c63-45d8-b0d5-f4c90000314f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest is an ensemble learning method that builds multiple\n",
        "decision trees and combines their predictions to obtain a more accurate\n",
        "and stable result. Each tree is built using a different random subset of\n",
        "the data, and at each node, a random subset of features is considered\n",
        "when splitting the data."
      ],
      "id": "f5b2d78f-a046-4d5e-8b76-bb183c39cc19"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "</p>"
      ],
      "id": "8cc498c7-ab94-4ef4-886b-ec57e89962e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Classification:** The final output is determined by majority\n",
        "    voting from all the decision trees\n",
        "-   **Regression:** The output is the average of all tree predictions.\n",
        "\n",
        "## Mathematics Behind Random Forest\n",
        "\n",
        "To understand Random Forest, we first need to recap how a decision tree\n",
        "works and then explore how Random Forest extends this idea.\n",
        "\n",
        "### <a href=\"../../posts/decisiontree/index.qmd\" target=\"_blank\"\n",
        "style=\"text-decoration:none\">Decision Tree Recap</a>\n",
        "\n",
        "A decision tree is a tree-structured model where each internal node\n",
        "represents a “test” on an attribute (e.g., whether the feature value is\n",
        "above or below a threshold), each branch represents the outcome of the\n",
        "test, and each leaf node represents a class label (classification) or a\n",
        "value (regression).\n",
        "\n",
        "-   For **classification**, the goal is to partition the data such that\n",
        "    the class labels in each partition are as homogeneous as possible.  \n",
        "-   For **regression**, the goal is to minimize the variance of the\n",
        "    predicted values.\n",
        "\n",
        "Mathematically, the decision tree makes decisions by minimizing the\n",
        "**Gini Index** or **Entropy** for classification tasks and minimizing\n",
        "the **Mean Squared Error (MSE)** for regression tasks.\n",
        "\n",
        "### Random Forest Algorithm\n",
        "\n",
        "Random Forest enhances decision trees by employing two key concepts:\n",
        "\n",
        "-   **Random Sampling (Bootstrap Sampling):** From the training set of\n",
        "    size $N$, randomly draw $N$ samples with replacement.  \n",
        "-   **Feature Subsampling:** At each node of the decision tree, a random\n",
        "    subset of the features is selected, and the best split is chosen\n",
        "    only from these features.\n",
        "\n",
        "The process for building a Random Forest can be summarized as follows:\n",
        "\n",
        "1.  Draw $B$ bootstrap samples from the original dataset.\n",
        "2.  For each bootstrap sample, grow an unpruned decision tree using a\n",
        "    random subset of features at each node.\n",
        "3.  For **classification**, combine the predictions of all the trees by\n",
        "    majority voting.\n",
        "4.  For **regression**, combine the predictions by averaging the outputs\n",
        "    of all trees.\n",
        "\n",
        "### Random Forest for Classification\n",
        "\n",
        "For classification tasks, Random Forest works by constructing multiple\n",
        "decision trees, each built on a different subset of the data and a\n",
        "random subset of the features.\n",
        "\n",
        "Given a dataset $D = \\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\\}$, where\n",
        "$x_i$ is a feature vector and $y_i$ is the class label, Random Forest\n",
        "generates $B$ decision trees $T_1, T_2, ..., T_B$.\n",
        "\n",
        "For each test point $x$, each tree $T_b$ gives a class prediction: $$\n",
        "\\hat{y}_b(x) = T_b(x)\n",
        "$$ The final prediction is determined by majority voting: $$\n",
        "\\hat{y}(x) = \\text{argmax}_k \\sum_{b=1}^{B} I(\\hat{y}_b(x) = k)\n",
        "$$ where $I(\\cdot)$ is an indicator function that equals 1 if the\n",
        "condition is true and 0 otherwise.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### Random Forest for Regression\n",
        "\n",
        "In regression tasks, Random Forest builds trees that predict continuous\n",
        "values and averages the results.\n",
        "\n",
        "Given a dataset $D = \\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\\}$, where\n",
        "$x_i$ is a feature vector and $y_i$ is the continuous target variable,\n",
        "Random Forest generates $B$ decision trees $T_1, T_2, ..., T_B$.\n",
        "\n",
        "For each test point $x$, each tree $T_b$ gives a predicted value: $$\n",
        "\\hat{y}_b(x) = T_b(x)\n",
        "$$ The final prediction is the average of all the tree predictions: $$\n",
        "\\hat{y}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{y}_b(x)\n",
        "$$\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Assumptions of Random Forest\n",
        "\n",
        "Random Forest makes few assumptions about the data, making it highly\n",
        "flexible. Some assumptions include:\n",
        "\n",
        "-   **Independent Features:** While Random Forest does not explicitly\n",
        "    assume that features are independent, correlated features can reduce\n",
        "    its performance slightly.  \n",
        "-   **Noisy Data:** Random Forest is robust to noise due to its ensemble\n",
        "    nature.  \n",
        "-   **Non-linearity:** Random Forest can handle non-linear relationships\n",
        "    between features and the target.\n",
        "\n",
        "## Advantages of Random Forest\n",
        "\n",
        "-   **Reduction of Overfitting:** Random Forest reduces overfitting by\n",
        "    averaging the predictions of multiple trees.\n",
        "-   **Handles Missing Data:** It can handle missing values by assigning\n",
        "    them to the most frequent class (classification) or mean value\n",
        "    (regression).\n",
        "-   **Robust to Noise:** It is relatively resistant to outliers and\n",
        "    noise due to its ensemble nature.\n",
        "-   **Works with Categorical & Continuous Variables:** Random Forest can\n",
        "    handle both categorical and continuous data types.\n",
        "-   **Feature Importance:** It provides an estimate of feature\n",
        "    importance, allowing for better interpretability of models.\n",
        "\n",
        "## Disadvantages of Random Forest\n",
        "\n",
        "-   **Complexity:** The algorithm is computationally intensive,\n",
        "    especially with a large number of trees.\n",
        "-   **Interpretability:** While decision trees are interpretable, Random\n",
        "    Forest is a “black-box” model where it’s hard to understand\n",
        "    individual predictions.\n",
        "-   **Memory Usage:** Random Forest can require more memory to store\n",
        "    multiple decision trees.\n",
        "-   **Bias in Imbalanced Data:** For classification tasks with\n",
        "    imbalanced data, Random Forest may be biased toward the majority\n",
        "    class.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Python Implementation\n",
        "\n",
        "Here is a Python code example of how to implement Random Forest for both\n",
        "classification and regression using `scikit-learn`."
      ],
      "id": "72ef7184-22e5-46a8-8899-d28e9fa9a761"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 1.0\n",
            "Regression Mean Squared Error: 19.715794117647054"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Classification Example: Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize RandomForest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Classification Accuracy: {accuracy}\")\n",
        "\n",
        "# Regression Example: Boston Housing dataset\n",
        "df_raw = pd.read_csv(\"HousingData.csv\")\n",
        "df = df_raw.dropna()\n",
        "X = df.drop(columns=['MEDV'])\n",
        "y = df['MEDV']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize RandomForest Regressor\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Regression Mean Squared Error: {mse}\")"
      ],
      "id": "9d9bae52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning for Random Forest\n",
        "\n",
        "Tuning the hyperparameters of a Random Forest can significantly improve\n",
        "its performance. Here are some important hyperparameters to consider:\n",
        "\n",
        "### Important Hyperparameters\n",
        "\n",
        "-   **`n_estimators`:** This is the number of trees in the forest.\n",
        "    Increasing this number usually improves performance but also\n",
        "    increases computational cost.\n",
        "    -   **Tip:** Start with a default value of 100 and increase as\n",
        "        needed.  \n",
        "-   **`max_depth`:** The maximum depth of each tree. Deeper trees can\n",
        "    model more complex relationships, but they also increase the risk of\n",
        "    overfitting.\n",
        "    -   **Tip:** Use cross-validation to find the optimal depth that\n",
        "        balances bias and variance  \n",
        "-   **`min_samples_split`:** The minimum number of samples required to\n",
        "    split an internal node. Higher values prevent the tree from becoming\n",
        "    too specific (overfitting).\n",
        "    -   **Tip:** Use higher values (e.g., 5 or 10) to reduce overfitting\n",
        "        in noisy datasets.\n",
        "-   **`min_samples_leaf`:** The minimum number of samples required to be\n",
        "    at a leaf node. Larger leaf sizes reduce model complexity and can\n",
        "    help generalization.\n",
        "-   **`max_features`:** The number of features to consider when looking\n",
        "    for the best split. Randomly selecting fewer features can reduce\n",
        "    correlation between trees and improve generalization.\n",
        "    -   **Tip:** For classification, a common choice is\n",
        "        `sqrt(number_of_features)`. For regression,\n",
        "        `max_features = number_of_features / 3` is often effective.\n",
        "-   **`bootstrap`:** Whether to use bootstrap samples when building\n",
        "    trees. Set this to `True` for Random Forest (default) or `False` for\n",
        "    extremely randomized trees (also known as ExtraTrees).\n",
        "\n",
        "### Grid Search for Hyperparameter Tuning\n",
        "\n",
        "To fine-tune the hyperparameters of a Random Forest, we can use\n",
        "**GridSearchCV** or **RandomizedSearchCV** in `scikit-learn`. Here’s an\n",
        "example of how to use `GridSearchCV` for tuning a Random Forest\n",
        "Classifier:"
      ],
      "id": "3db3e400-b0ef-4855-9b71-40d5cd31d451"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Accuracy with Best Parameters: 1.0"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters from grid search\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate with best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with Best Parameters: {accuracy}\")"
      ],
      "id": "1ceeaa57"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this technique, we can find the combination of hyperparameters\n",
        "that yields the best model performance.\n",
        "\n",
        "## Feature Importance in Random Forest\n",
        "\n",
        "One of the appealing aspects of Random Forest is that it provides a\n",
        "measure of **feature importance**, which indicates how much each feature\n",
        "contributes to the model’s predictions.\n",
        "\n",
        "### Computing Feature Importance\n",
        "\n",
        "In Random Forest, feature importance is computed by measuring the\n",
        "**average reduction in impurity** (e.g., Gini impurity or MSE) brought\n",
        "by each feature across all trees. Features that lead to larger\n",
        "reductions are considered more important."
      ],
      "id": "b6eb24f2-d64b-4e93-abf9-0764ac26ec70"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAI2CAYAAABkPRT0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAO\nxAAADsQBlSsOGwAARBJJREFUeJzt3XmcVXXBP/DPIIjDvqqAy+CegYFrqZgpgrmgVLaoaZpYYvqI\nkWXag4E+6u8xzRY0FxQtbVFBKwU1zaXMNMXE3FAQd2XfBpiB+/vDl/M0AcoIeO/B9/v1Oq/X3O85\n997PDB7nfuac8z1VpVKpFAAAACioZuUOAAAAAGtCsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACk2x\nBQAAoNAUWwAAAApNsQUAAKDQFFsAAAAKTbEF4ENx7bXXpqqqaqXL3Xffvdbf789//nPOOeecLF++\nfK2/9pp49+cwZcqUckdpskr9mQKAYgvAh+p3v/tdHnrooUbL7rvvvtbf589//nN++MMfKmFrkZ8p\nAJWqebkDAPDR0qdPn2yzzTbljvGBlEql1NXVZcMNNyx3lA9VXV1dmjf3kQGAyuWILQAVY9GiRfnu\nd7+bnj17ZsMNN0zPnj1z3nnnNTpCuHjx4gwbNiy9evVKmzZtsummm+bQQw/NM88807DNOeeckx/+\n8IdJkhYtWjSc8py8c9Sxqqoqf/7znxu997unCE+bNq1hrKamJkcffXTGjBmTHXbYIRtuuGH++Mc/\nJkmeeOKJDBo0KB07dkx1dXX22muvPPDAAx/o+953332z9957Z8KECenTp0+qq6vTt2/fPPzww6mv\nr8/3v//9dOvWLZ06dcrXvva1LFy4sOG506ZNS1VVVUaPHp3TTz89G2+8cVq1apVDDjmk0feSvFNQ\nzz777NTU1GTDDTdMTU1Nzj777NTV1a309c4444x07949LVu2zGmnnbbKn2mSjBgxIjvvvHPatWuX\nLl26ZL/99svf/va3Ru//7s/+tttuy7e+9a106dIlXbp0ydFHH505c+Y02ra+vj4XXnhhdtxxx2y0\n0Ubp2rVrDjzwwEb/zm+//Xa++c1vpkePHmnZsmV22GGHXHHFFR/o3wCAYvPnVwA+VMuWLUt9fX3D\n46qqqmywwQapr6/PwIED869//Ss/+MEP0rt37/ztb3/LqFGjMmvWrPzoRz9KkixZsiTz58/P2Wef\nnW7dumXWrFkZPXp0PvWpT+Xpp5/OpptumhNOOCGvvPJKrr766jz44IPZYIMNPnDee++9N5MmTcqI\nESOy8cYbp6amJo899lj69euXvn375sorr0yrVq1y+eWXp3///vnrX/+aXXbZpcnvM2XKlHznO9/J\nWWedlTZt2uSMM87IoEGDMmjQoNTX1+faa6/N008/ne985zvZeOON8//+3/9r9Pzzzz8/ffr0yTXX\nXJO33nor3//+9zNgwIA89dRTadGiRZLk2GOPzW9/+9t8//vfz957752//vWvOe+88/Liiy/mhhtu\naPR65513XnbbbbdcccUVWbZsWXbeeecsXLhwlT/TV199NcOGDctmm22WhQsX5pe//GX22Wef/OMf\n/0jv3r0bbftf//VfOeSQQ3LDDTfk2WefzRlnnJENNtggY8eObdjmy1/+csaPH5/TTjst/fv3z+LF\ni3P//ffn9ddfzw477JB58+Zl7733Tm1tbc4555z07NkzEydOzEknnZQlS5bklFNOafK/AQAFVgKA\nD8E111xTSrLCstdee5VKpVLpuuuuKyUp3XfffY2ed+6555ZatGhRevPNN1f6uvX19aWFCxeW2rRp\nU7r44osbxkeMGFFKUqqrq2u0/b333ltKUrr33ntXmm/q1KkNY1tuuWWpurq69Prrrzfadr/99ivt\nsMMOpSVLljTKscMOO5QOO+yw1fo5PP/88w1jn/70p0vNmzcvvfDCCw1jt956aylJaf/992/0/MGD\nB5dqamoaHk+dOrWUpPSxj32stGzZsobxBx98sJSkdNVVV5VKpVLpySefLCUpjRgxotHrjRo1qpSk\n9MQTTzR6vb59+5aWL1/eaNtV/Uz/U319famurq603XbblU499dSG8Xd/9sccc0yj7U8++eRSy5Yt\nG97vT3/6UylJ6dJLL13le4wcObLUsmXL0nPPPddo/IQTTih17tz5fTMCsH5xKjIAH6px48blkUce\naViuvvrqJMmECROy5ZZbZs8990x9fX3DMmDAgNTV1TU6rfW3v/1t9thjj3To0CHNmzdP69ats2DB\ngjz77LNrPe8nP/nJbLrppg2Pa2trc9999+WII45Is2bNGnKWSqX0798/999//wd6n+222y5bbbVV\nw+MddtghSTJw4MBG2+2www555ZVXUiqVGo1/4QtfSLNm//drfa+99spmm22Whx56KEkach199NGN\nnvfu4/vuu6/R+OGHH97oVOP3c/fdd+czn/lMOnfunObNm6dFixZ57rnnVvpvcvDBBzd63Lt37yxZ\nsiRvvvlmkuTOO+9MVVVVhgwZssr3mzBhQvbYY4/07Nmz0X8vAwcOzMyZM/Ovf/1rtbMDUHxORQbg\nQ9WrV6+VTh711ltv5aWXXmo4bfY/zZw5M0ny+9//Pl/60pdy7LHHZsSIEenSpUuaNWuWgw46KIsX\nL17rebt169bo8axZs7Js2bKMGjUqo0aNWulzli9f3qhkro6OHTs2evzuBFUrG6+vr8+yZcsaTei0\nySabrPCam2yySV599dWG3Cv7ft4t7e+uf9d/bvdeHnvssRx00EEZOHBgrr766nTr1i0bbLBBTjjh\nhJX+m3Tq1KnR45YtWyZJw7YzZ85Mp06dUl1dvcr3fOuttzJlypT3/e8FgI8GxRaAitC5c+f07Nkz\nv/3tb1e6vqamJkny61//Ottss02uvfbahnV1dXUrFLNV2WijjZIkS5cubTS+qiL0n0ctO3TokGbN\nmuXkk0/OMcccs9LnNLXUrg3vHu38z7E+ffok+b8y+cYbb2Trrbdu2OaNN95otP5dTTlae/PNN6d5\n8+a55ZZbGhXN2bNnp0OHDqv9Ou/q0qVLZs2aldra2lWW286dO2fjjTfOpZdeutL122+/fZPfF4Di\nUmwBqAgHHnhgbr755rRp06bhNNyVWbRo0Qq3nrn++uuzbNmyRmPvHgWsra1N27ZtG8a33HLLJMnk\nyZMzYMCAhvF3Zzt+P61bt06/fv3yxBNPZOeddy5LiV2Zm266Keecc05Dnr/85S955ZVX8qlPfSpJ\nss8++yR55w8DZ511VsPzfvWrXyV5Z2bm97Oqn+miRYuywQYbNCrD99xzT6ZPn56ePXs2+XsZMGBA\nLrjgglx11VWrnATqwAMPzE9/+tNsscUW2XjjjZv8HgCsXxRbACrCUUcdlWuuuSb7779/vv3tb+cT\nn/hEli5dmhdeeCG33XZbxo8fn1atWuXAAw/M+PHjM2zYsBxyyCF59NFH89Of/nSFI4M77rhjkuRH\nP/pRPvvZz2aDDTbIrrvumm7duuXTn/50zj///HTp0iUbb7xxfvnLX+bFF19c7awXX3xx9tlnnwwc\nODBf//rX061bt8yYMSOPPfZYli1blgsuuGBt/mhWy/z583P44YfnG9/4Rt5+++2ceeaZ2XbbbRuO\nKvfq1Stf+cpXcs4556S+vj577rlnHnrooYwaNSpf+cpXVpi5eGVW9TM98MAD8+Mf/zhf+9rXctxx\nx+W5557LqFGj0qNHjw/0vXzmM5/J5z//+Zx++ul5+eWXs99++6Wuri73339/Dj744Oy7774ZNmxY\nfvOb36Rfv34ZNmxYtt9++yxcuDDPPPNMHnjggdx6660f6L0BKCbFFoCK0KJFi0ycODEXXHBBrrji\nikydOjWtW7fO1ltvnYMPPrjhmtMhQ4bk5ZdfzpgxY/KLX/wiu+22W37/+99n8ODBjV7vkEMOydCh\nQzN69OiMHDkypVKpYcKlX/7ylznppJNy6qmnZqONNsrxxx+fs88++z0nK/p3O++8cx555JH88Ic/\nzKmnnpq5c+ema9eu2XnnnfPNb35z7f5gVtOZZ56ZKVOmNNzn9jOf+Ux+9rOfNTo1+Nprr81WW22V\nMWPG5Nxzz0337t3z3e9+NyNGjFit91jVz3TgwIH5yU9+kosvvjg333xzevXqleuuuy7nnnvuB/5+\nfv3rX+fCCy/M2LFj8+Mf/zjt27fPbrvtlhNOOCFJ0r59+/z1r3/NyJEjc+GFF+bVV19Nhw4dsv32\n2+fzn//8B35fAIqpqvSf0yoCAIUxbdq09OzZM1deeWVD6QOAj5rKuDAIAAAAPiDFFgAAgEJzKjIA\nAACF5ogtAAAAhabYAgAAUGgVfbuf5cuXZ86cOdloo40a3fQdAACA9V+pVMrixYvToUOHNGu26uOy\nFV1s58yZk86dO5c7BgAAAGU0c+bMdOrUaZXrK7rYbrTRRkne+Saqq6vLnAYAAIAPU21tbTp37tzQ\nDVeloovtu6cfV1dXK7YAAAAfUe93aarJowAAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTF\nFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBC\nU2wBAAAoNMUWAACAQmte7gDrg5rv/bHcEaBJpl1wcLkjAADAWuOILQAAAIWm2AIAAFBoii0AAACF\nptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAA\nUGiKLQAAAIWm2AIAAFBozcsdAOC91Hzvj+WOAKtt2gUHlzsCAHwkOWILAABAoSm2AAAAFJpiCwAA\nQKEptgAAABSaYgsAAEChKbYAAAAUmmILAABAoSm2AAAAFJpiCwAAQKEptgAAABRak4ttqVTKiBEj\n0r1797Ru3Tr77LNPJk+e/L7PmzdvXmpqalJVVZX6+voPFBYAAAD+U5OL7UUXXZQxY8Zk4sSJmTFj\nRvbaa68MHDgwCxYseM/nnXbaadl+++0/cFAAAABYmSYX29GjR2f48OHp3bt3qqurM2rUqCxdujTj\nxo1b5XN+//vf58knn8x3vvOdNQoLAAAA/6lJxXbu3LmZNm1adt9994ax5s2bp2/fvnn88cdX+pyZ\nM2fmW9/6Vq655po0b978PV+/rq4utbW1jRYAAAB4L00qtvPmzUuSdOjQodF4x44dG9b9p5NOOilD\nhgxJr1693vf1zzvvvLRq1aph6dy5c1PiAQAA8BHUpGLbrl27JMmcOXMajc+ePbth3b/79a9/nRde\neCHf+973Vuv1zzrrrCxatKhhmTlzZlPiAQAA8BHUpGLbvn371NTU5JFHHmkYq6+vz6RJk9K3b98V\ntp8wYUKeeeaZbLrppunSpUsOO+ywJMmmm26asWPHrrB9ixYtUl1d3WgBAACA99LkyaOGDh2aiy66\nKJMnT05tbW1GjBiRFi1aZPDgwStse8kll+TZZ5/NpEmTMmnSpFx11VVJkn/84x/5whe+sObpAQAA\n+Mh779mcVmL48OGZP39++vfvn3nz5mXXXXfNhAkT0qZNm0yfPj077rhj7rjjjvTr1y8dO3ZMx44d\nG57btWvXJEmPHj3edyIpAAAAWB1NbpdVVVUZOXJkRo4cucK6LbbY4j3vZ7vvvvumVCo19S0BAABg\nlZp8KjIAAABUEsUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNs\nAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0\nxRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACA\nQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEA\nACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUW\nAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJT\nbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAo\nNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAA\ngEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCa3Kx\nLZVKGTFiRLp3757WrVtnn332yeTJk1e5/aBBg9KjR4+0a9cu3bp1y3HHHZeZM2euUWgAAAB4V5OL\n7UUXXZQxY8Zk4sSJmTFjRvbaa68MHDgwCxYsWOn2o0aNypQpUzJv3rz861//Sm1tbU488cQ1Dg4A\nAADJByi2o0ePzvDhw9O7d+9UV1dn1KhRWbp0acaNG7fS7T/xiU+kurr6/96wWbM8++yzHzwxAAAA\n/JsmFdu5c+dm2rRp2X333RvGmjdvnr59++bxxx9f5fPOPPPMtG3bNp06dcr48eMzYsSIlW5XV1eX\n2traRgsAAAC8lyYV23nz5iVJOnTo0Gi8Y8eODetW5vzzz8/8+fPz/PPP5/TTT89222230u3OO++8\ntGrVqmHp3LlzU+IBAADwEdSkYtuuXbskyZw5cxqNz549u2Hde9lmm20yaNCgDBw4MHV1dSusP+us\ns7Jo0aKGxSRTAAAAvJ8mFdv27dunpqYmjzzySMNYfX19Jk2alL59+67Wa9TV1eXNN9/M3LlzV1jX\nokWLVFdXN1oAAADgvTR58qihQ4fmoosuyuTJk1NbW5sRI0akRYsWGTx48ArbPvfcc7nlllsyb968\nlEqlPPvss/nOd76T3XbbLV26dFkr3wAAAAAfbU0utsOHD8/Xvva19O/fP507d84DDzyQCRMmpE2b\nNpk+fXratGmTBx54IMk797y9+OKLs8UWW6Rt27YZOHBgevfundtuu22tfyMAAAB8NFWVSqVSuUOs\nSm1tbVq1apVFixZV9GnJNd/7Y7kjQJNMu+DgckdYbfYviqRI+xYAFMHqdsImH7EFAACASqLYAgAA\nUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0A\nAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabY\nAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBo\nii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAA\nhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIA\nAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIot\nAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm\n2AIAAFBoii0AAACFptgCAABQaIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQ\naIotAAAAhabYAgAAUGiKLQAAAIWm2AIAAFBoii0AAACFptgCAABQaE0qtqVSKSNGjEj37t3TunXr\n7LPPPpk8efJKt33rrbdy7LHHpmfPnmnTpk1qampy5plnZsmSJWslOAAAACRNLLYXXXRRxowZk4kT\nJ2bGjBnZa6+9MnDgwCxYsGCFbRcsWJDtt98+d999d+bNm5e77747f/zjH/Pd7353rYUHAACAJhXb\n0aNHZ/jw4endu3eqq6szatSoLF26NOPGjVth26222irf//73s/XWW6dZs2bZZpttcvzxx+fee+9d\na+EBAABgtYvt3LlzM23atOy+++4NY82bN0/fvn3z+OOPr9Zr3Hnnnenbt+8q19fV1aW2trbRAgAA\nAO9ltYvtvHnzkiQdOnRoNN6xY8eGde9l1KhRefzxx3PuueeucpvzzjsvrVq1alg6d+68uvEAAAD4\niFrtYtuuXbskyZw5cxqNz549u2HdqvzgBz/IFVdckT//+c/ZbLPNVrndWWedlUWLFjUsM2fOXN14\nAAAAfEStdrFt3759ampq8sgjjzSM1dfXZ9KkSas8vbhUKuXkk0/OjTfemAceeCDbb7/9e75HixYt\nUl1d3WgBAACA99KkyaOGDh2aiy66KJMnT05tbW1GjBiRFi1aZPDgwStsW19fn6OPPjp//vOf88AD\nD6SmpmZtZQYAAIAGzZuy8fDhwzN//vz0798/8+bNy6677poJEyakTZs2mT59enbcccfccccd6dev\nX/7yl7/khhtuSMuWLbPttts2ep2V3R4IAAAAPogmFduqqqqMHDkyI0eOXGHdFlts0aiwfvrTn06p\nVFrzhAAAAPAemnQqMgAAAFQaxRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0\nxRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACA\nQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEA\nACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUW\nAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJT\nbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAo\nNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAA\ngEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wB\nAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTF\nFgAAgEJr3tQnlEqlnHPOObnyyiszd+7c7LLLLhk9enR69eq10u3PPvvs/PGPf8xTTz2V3XffPQ8+\n+OAahwYA1kzN9/5Y7giw2qZdcHC5IwAVrslHbC+66KKMGTMmEydOzIwZM7LXXntl4MCBWbBgwUq3\n33rrrTNy5MiceOKJaxwWAAAA/lOTi+3o0aMzfPjw9O7dO9XV1Rk1alSWLl2acePGrXT74447Loce\nemi6dOnyvq9dV1eX2traRgsAAAC8lyYV27lz52batGnZfffdG8aaN2+evn375vHHH1/jMOedd15a\ntWrVsHTu3HmNXxMAAID1W5OK7bx585IkHTp0aDTesWPHhnVr4qyzzsqiRYsalpkzZ67xawIAALB+\na9LkUe3atUuSzJkzp9H47Nmz06NHjzUO06JFi7Ro0WKNXwcAAICPjiYdsW3fvn1qamryyCOPNIzV\n19dn0qRJ6du371oPBwAAAO+nyZNHDR06NBdddFEmT56c2trajBgxIi1atMjgwYNXun1dXV0WL16c\n+vr6lEqlLF68OIsXL17j4AAAAJB8gPvYDh8+PPPnz0///v0zb9687LrrrpkwYULatGmT6dOnZ8cd\nd8wdd9yRfv36JUmGDBmSsWPHNjy/uro6yTv3wwUAAIA11eQjtlVVVRk5cmTeeOONLFq0KPfff396\n9+6dJNliiy2yYMGChlKbJNdee21KpdIKCwAAAKwNTS62AAAAUEkUWwAAAApNsQUAAKDQFFsAAAAK\nTbEFAACg0BRbAAAACk2xBQAAoNAUWwAAAApNsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACk2xBQAA\noNAUWwAAAApNsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACk2xBQAAoNAUWwAAAApNsQUAAKDQFFsA\nAAAKTbEFAACg0BRbAAAACk2xBQAAoNAUWwAAAApNsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACk2x\nBQAAoNAUWwAAAApNsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACk2xBQAAoNAUWwAAAApNsQUAAKDQ\nFFsAAAAKTbEFAACg0BRbAAAACq15uQMAAMD6pOZ7fyx3BFht0y44uNwR1gpHbAEAACg0xRYAAIBC\nU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAA\nKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYA\nAIBCU2wBAAAoNMUWAACAQlNsAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNs\nAQAAKDTFFgAAgEJTbAEAACg0xRYAAIBCU2wBAAAoNMUWAACAQlNsAQAAKLQmF9tSqZQRI0ake/fu\nad26dfbZZ59Mnjx5ldvPnj07Rx11VNq3b58OHTrkqKOOypw5c9YkMwAAADRocrG96KKLMmbMmEyc\nODEzZszIXnvtlYEDB2bBggUr3f7oo4/Om2++mRdeeCFTpkzJm2++mWOPPXaNgwMAAECSNG/qE0aP\nHp3hw4end+/eSZJRo0blqquuyrhx4/LVr3610bYvvfRSbr/99kyaNCldunRJkvzoRz9Knz59Mn36\n9GyxxRaNtq+rq0t9fX3D40WLFiVJamtrmxrzQ7W8bkm5I0CTVPo+9e/sXxSJfQvWjSLtW4n9i2Kp\n9P3r3XylUum9Nyw1wZw5c0pJSn/9618bjR9wwAGlYcOGrbD9+PHjSy1btlxhfMMNNyzdeuutK4yP\nGDGilMRisVgsFovFYrFYLJaGZebMme/ZVZt0xHbevHlJkg4dOjQa79ixY8O6/9y+ffv2K4x36NBh\npdufddZZ+e53v9vwePny5VmwYEHatm2bqqqqpkSl4Gpra9O5c+fMnDkz1dXV5Y4D6xX7F6wb9i1Y\nd+xfH12lUimLFy9eoYP+pyYV23bt2iXJCpM/zZ49Oz169Fjp9nPnzl1hfM6cOQ2v9e9atGiRFi1a\nNBpr3bp1UyKynqmurvY/L1hH7F+wbti3YN2xf300tWrV6n23adLkUe3bt09NTU0eeeSRhrH6+vpM\nmjQpffv2XWH7Pn36ZMmSJfnnP//ZMPbPf/4zS5cuTZ8+fZry1gAAALBSTZ4VeejQobnooosyefLk\n1NbWZsSIEWnRokUGDx68wrZbbrllDjrooAwfPjwzZszIjBkzMnz48Bx66KErTBwFAAAAH0STi+3w\n4cPzta99Lf3790/nzp3zwAMPZMKECWnTpk2mT5+eNm3a5IEHHmjY/vrrr0+XLl2y9dZbZ+utt07X\nrl1z3XXXrdVvgvVP8+bNM2LEiDRv3uSJu4H3Yf+CdcO+BeuO/Yv3U1V633mTAQAAoHI1+YgtAAAA\nVBLFFgAAgEJTbAEAACg0xRYAAIBCM60YAMAHtHz58jzzzDOZNWtWOnXqlB122CHNmjluAPBhU2yp\nCFOmTMm4cePyyCOPNHw42HXXXXP44Ydnu+22K3c8KKQlS5bkl7/8ZW655ZY88sgjmT17djp27Jhd\nd901gwcPzle/+tVstNFG5Y4JhfTYY4/l4osvzh/+8IfMmzevYbxt27Y55JBD8u1vfzs777xzGRNC\ncZVKpTz66KMrfC7cbbfdUlVVVe54VCh/UqSspkyZkkGDBmWnnXbKH/7wh2yyySb55Cc/mU022SS3\n3357+vTpk0GDBmXKlCnljgqFMnbs2Gy55Za54oorsuuuu+ayyy7LHXfckcsuuyy77757rr766tTU\n1LivOHwAxx13XA499ND06NEj48aNy9tvv52lS5fm7bffzq233prNN988hx56aI477rhyR4VCqa+v\nzyWXXJKampr069cvl112WSZMmJDLLrss++yzT2pqanLJJZekrq6u3FGpQO5jS1nV1NTk29/+dr76\n1a+mQ4cOK6yfO3duxo4dmx//+Md58cUXP/yAUFCDBg3Kueeem5122mmV2/zzn//MD37wg9x6660f\nYjIovosvvjjf+ta3suGGG65ym6VLl+bnP/95hg0b9iEmg2L72Mc+lh133DEnnHBC9ttvv7Rs2bJh\n3ZIlS3LPPffkqquuyr/+9a88/fTTZUxKJVJsKatFixalVatWa207AACK6R//+Ed22WWX993uscce\nc6o/K1BsAQDW0Pz58zN//vxGY927dy9TGoCPHpNHUTFKpVJ++9vf5u9///sKHw6uuOKKMqWC4nvr\nrbcyYsSIle5bzz33XJlSwfrhb3/7W772ta/l+eefbxgrlUqpqqrKsmXLypgMiu/VV1/NY489tsLv\nriOPPLJMiahkii0V46STTspvfvOb9OvXL61bty53HFhvHH300Vm4cGGOOuoo+xasZSeccEIOPPDA\n3HDDDfYvWIuuuOKKfOtb30p1dXWjy9GqqqoUW1bKqchUjE6dOuWRRx7J1ltvXe4osF5p3759Xnvt\nNR+6YR1o165d5s6d6xYksJb16NEjP/nJT/L5z3++3FEoCLf7oWK0a9cuW2yxRbljwHqnpqYmS5Ys\nKXcMWC/tueeeZmeFdWDJkiX53Oc+V+4YFIgjtlSMn//853nllVfyP//zP/7yDWvRfffdl5/+9Kc5\n44wzsummmzZa549JsGZeeeWVHHvssRk4cOAK+9cxxxxTplRQfEOHDs3AgQNz2GGHlTsKBaHYUjFe\nffXV7L///nn11VfTtWvXRuvcwxY+uHvvvTdHHXVU3nzzzYYxk9vA2nHppZfm9NNPT/v27Rud7l9V\nVZXp06eXMRkU24IFC/LJT34ym2++ebp169Zo3ZgxY8qUikpm8igqxle+8pV07do1Q4cOdS0grEXf\n/OY3c+SRR+aYY46xb8Fadt5552XcuHEZNGhQuaPAeuXUU0/N66+/nu222y51dXXljkMBOGJLxWjT\npk3eeuutRjPfAWuubdu2mTdvnlP8YR3o0qVL3n77bfsXrGVt27bNk08+mZqamnJHoSBMHkXF2Hrr\nrVNbW1vuGLDe2WuvvfLUU0+VOwasl774xS9m/Pjx5Y4B653OnTune/fu5Y5BgTgVmYpx2mmn5aij\njsp///d/rzABx1ZbbVWmVFB8n/rUp3LooYdmyJAhK+xbxx9/fJlSwfph1qxZOfLII7P33nuvcB3g\nddddV6ZUUHzf/e53c/bZZ+f888/PBhtsUO44FIBTkakYzZr93wkE757SZYIbWHM9e/Zc6XhVVZWJ\n2WANHXfccatcd80113yISWD9svnmm+eNN95IixYt0qVLl0brTMzGyii2VIyXXnppleu23HLLDzEJ\nAADlNHbs2FWuO/bYYz/EJBSFYguwnluyZEmaNWuWFi1aNIzV1dVl+fLladmyZRmTQfFNmjQpnTt3\nzuabb94w9vLLL2fWrFn5xCc+UcZkAB8tJo+iYgwbNiwPPPBAo7H7778/3/72t8uUCNYPBx10UB56\n6KFGYw899FAOOeSQMiWC9cfxxx+fhQsXNhpbsGCB69dhDV1//fWZNGlSo7HHH388v/rVr8oTiIrn\niC0Vo1u3bpkyZUqj+2wuWLAg2223XV577bUyJoNi69KlS9544400b/5/8wXW19dn0003zYwZM8qY\nDIqvQ4cOmTNnzmqPA6tnm222yYMPPtho0sM33ngje++9d6ZMmVLGZFQqR2ypGLW1tamurm401qpV\nqxX+Eg40TVVVVerr6xuN1dfXx981Yc21bds2s2fPbjQ2c+ZM92SHNfTWW2+tMJP/pptumjfffLNM\niah0ii0Vo2fPnrnvvvsajd13331uzA1raKeddsq1117baOy6665L7969yxMI1iOf/vSn853vfKfh\nj0f19fU588wzs++++5Y3GBRct27d8txzzzUae+6557LxxhuXKRGVzn1sqRinnXZavvzlL+d73/te\ntttuuzz33HO58MILc/7555c7GhTaueeem/333z+33357tt9++zz33HO56667cvfdd5c7GhTehRde\nmP322y/dunVLTU1Npk2blo4dO+aee+4pdzQotCOOOCLHHHNMLrvssobPhSeffHK++MUvljsaFco1\ntlSUq666KpdeemmmTp2ampqa/Nd//VeGDBlS7lhQeE899VQuv/zyhn3rpJNOysc//vFyx4L1wuLF\ni/OHP/wh06ZNS01NTQ455JBstNFG5Y4FhbZ48eKccMIJueGGG1JVVZUk+cpXvpIrr7xyhUvXIFFs\nAQCACjVz5syGP8p26dKl3HGoYK6xBVgPvfrqq6u13SuvvLKOk8D65+abb16r2wGr1rlz5+y6665K\nLe9LsaWs+vTpk9///vernJ21VCrl1ltvTd++fT/kZFBse++9d04//fQ8++yzK13/7LPPZtiwYenX\nr9+HnAyK74orrsguu+zScHr/v5s2bVp+8YtfZOedd86VV15ZpoRQTKecckpmzpz5ntu8/fbbOeWU\nUz6kRBSJyaMoq5///Oc59dRTc9JJJ2X//fdPr1690r59+8ydOzdPPfVU/vSnP2XjjTfOz372s3JH\nhUKZNGlSRo4cmd122y0dO3ZcYd+aNWtWTjjhhDz++OPljgqFM3HixNx22225+OKLc/LJJ2ejjTZq\n2L+WLFmSvfbaKyNGjMhhhx1W7qhQKN26dcu2226bAQMGZODAgSv87po4cWLuvPPODB8+vNxRqUCu\nsaUi3Hvvvbnlllvy6KOPZtasWenUqVN22WWXfO5zn8t+++1X7nhQWPPnz8+dd965wr41YMCAtGvX\nrtzxoPBmzJiRf/zjHw37184775yuXbuWOxYU1htvvJHLL788N998c5566qmG8R133DGf+9znMnTo\n0BXubwuJYgsAAFSgxYsXZ/bs2enYsaOZxnlfii0AAACFZvIoAAAACk2xBQAAoNAUWwAAAArN7X4A\nANbQ22+/nfnz5zca22qrrcqUBuCjR7GlYixfvjzXX399/v73v6/w4eC6664rUyoovtdffz3f//73\nV7pvTZ8+vUypYP3wl7/8JUcffXSjfalUKqWqqirLli0rYzIovhdffDH/+Mc/Vvjddfzxx5cpEZVM\nsaViDB06NL/73e+y//77p3Xr1uWOA+uNY489NosWLcrJJ59s34K1bOjQoTn88MMzZMgQ+xesRZdf\nfnm+9a1vpVOnTo32raqqKsWWlXK7HypGly5d8tBDD2XbbbctdxRYr7Rv3z6vvPJK2rZtW+4osN5p\n27Zt5s6dm2bNTFsCa9OWW26ZSy65JJ/73OfKHYWC8H9hKsaGG26Ynj17ljsGrHc23XTTVFVVlTsG\nrJc+8YlP5KWXXip3DFjvzJ07V6mlSRyxpWKMHDkybdu2zbBhw8odBQpv+fLlDV+PGzcu48ePzwUX\nXJBu3bo12s5RJmi6e+65p+Hrf/3rX7n66qszfPjwFfav/fbb78OOBuuNo446KieeeGI+/elPlzsK\nBaHYUlb9+vVrOJJUKpXy8MMPZ4sttkj37t0bbXf//feXIx4UVrNmzRodpX13Mpv/ZHIbaLrV+YOQ\nyaOg6f77v/+74et58+Zl7Nix+fznP7/C58KRI0d+2NEoAJNHUVb9+/d/z8fAB3PvvfeWOwKst/79\njAhg7XnggQcaPe7Tp09eeOGFvPDCCw1jLq1hVRyxBVjPvfLKK9lss81WexxYfTfeeGO+8pWvrDD+\n61//Ol/+8pfLkAjgo8nFVVSM3r17r3S8T58+H24QWM/suOOOKx3faaedPuQksP75xje+sdLxoUOH\nfshJYP2yqn3oW9/61oechKJQbKkY06ZNW+m42SZhzazsxBynUsLasbL9a9asWSZmgzX0y1/+cqXj\nN9xww4echKJwjS1lN2bMmCTvTGJzzTXXNPqQ8Oyzz2aTTTYpVzQotGOOOSZJsnTp0oav3/XCCy/k\nYx/7WDliwXph8803T1VVVWpra7PFFls0WjdjxowcdthhZUoGxfbiiy8meeePRlOnTl3hc+FGG21U\nrmhUOMWWshs1alSSZMmSJY1muWvWrFk23XTTXHrppeWKBoW2wQYbJHnnw8G7Xyfv7Fv77rtvTjzx\nxHJFg8I799xzUyqVctJJJzX8Hkv+73eXW/3AB7PNNts0TBC1zTbbNIy/+7vsf/7nf8oVjQpn8igq\nxkEHHZTbb7+93DFgvXP++efnzDPPLHcMWC89+OCD2XvvvcsdA9YbL730UkqlUnr16pWnnnqqYbxZ\ns2bp2rWrI7askmILAPABTZ8+faXjG220UTbeeOMPOQ3AR5diS8U4/vjjVzq+0UYbZcstt8wRRxyR\nrbba6kNOBcXUs2fP1brX37vXMgEfTLNmzVa5r7Vs2TJHHXVULr744rRt2/ZDTgbFc911163Wdv85\nbwQkii0V5Etf+lLGjRuXT3ziE6mpqclLL72USZMm5dBDD82LL76Yp59+OrfddlsGDBhQ7qhQ8a6+\n+uqGr19++eWMHj06xxxzTHr27JmpU6fm+uuvz9ChQzNixIgypoTiu+qqqzJmzJicddZZqampybRp\n03L++efnqKOOSrdu3TJixIjsueeeueyyy8odFSre5ptv3ujxm2++mWXLlqVTp06ZPXt2wzXsqzpT\ngo82xZaKMWTIkHzqU59qdOT2mmuuyV//+tdceeWVueSSS3LDDTfkkUceKWNKKJ7+/ftn1KhR+dSn\nPtUw9re//S1nn3127r777jImg+L7+Mc/nrvvvjvdunVrGHvttddywAEH5Kmnnsqzzz6bAw44wAdx\naKKf/OQnmTRpUn784x+nXbt2mTt3boYPH56ddtopp5xySrnjUYEUWypGp06dMmPGjEb3/lu2bFm6\ndu2aWbNmZfHixdlkk00yd+7cMqaE4mnXrl1mz57daGbkZcuWpWPHjpk3b14Zk0HxtW/fPm+99VZa\ntmzZMFZbW5tNNtmkYf9q06ZNFixYUK6IUEibb755nnvuuVRXVzeMLVy4MDvssENefvnlMiajUrl7\nOBWjbdu2eeyxxxqNPf7442nTpk3DYze8h6arqanJtdde22hs7Nix2XLLLcsTCNYju+yyS0477bQs\nWrQoyTsfvIcPH55ddtklSfL888+na9eu5YwIhVRbW5s5c+Y0Gps7d27Dvgb/yX1sqRgnnXRSPvvZ\nz+brX/96ttxyy7z00ksZM2ZMhg0bliS57bbbsuuuu5Y5JRTP//7v/+awww7L5Zdfnp49e2batGl5\n8sknM27cuHJHg8K74oorcsghh6R9+/bp1KlTZs2ala233jq///3vkyQzZ87MxRdfXOaUUDyHHXZY\nDj300IwcObLh+vVzzjknhx9+eLmjUaGcikxFue6663L99dfn1VdfTY8ePfLVr37VzHewFkydOjU3\n3nhjXnnllWy22Wb5yle+kp49e5Y7FqwXli1bloceeiivvfZaevTokU9+8pONTv0Hmm7hwoUZNmxY\nrr/++ixZsiQtW7bM0UcfnUsuuaTR2XzwLsUWAACoSKVSKW+//Xa6du26Wrex46NLsaWiLFiwIE8/\n/XTmz5/faHy//fYrUyIopuuvvz5f/epXkyRjxoxZ5Xarun80sHoWLFiQH/3oR/n73/++wu+u+++/\nv0ypAD56FFsqxvjx43Pssceu8MGgqqoqy5YtK1MqKKZevXpl8uTJSbLKU46rqqry4osvfpixYL3z\nxS9+MZMmTcrhhx+e1q1bN1rnPtHQNB/72Mfy9NNPJ3lnVuRVHaF1+yxWRrGlYmy77bYZOnRovvGN\nb6RVq1bljgMA76tjx4555plnsskmm5Q7ChTeDTfckCOPPDJJcu21166y2B577LEfZiwKQrGlYrRr\n1849NWEdeHcyNmDt69mzZ5599tlsuOGG5Y4C8JHmpqBUjH79+uWJJ54odwxY72yxxRb5+Mc/nmHD\nhuWOO+5wD0BYi84888yceeaZWb58ebmjwHplyJAhuemmmzJ79uxyR6EgHLGlYowaNSpXX311hgwZ\nkm7dujVaZ4Ib+ODefPPN3HXXXbnrrrty9913Z9asWfnUpz6VgQMH5rvf/W6540Ghbb755nnjjTfS\nokWLdOnSpdE61wHCBzd06NDcddddmTZtWnbeeecccMABGTBgQPbcc880b9683PGoQIotFcMEN7Du\nLVq0KD/72c9y/vnnZ968eSZmgzU0duzYVa5zHSCsuWnTpuXOO+/MnXfembvvvjulUilz584tdywq\nkD93UDGmTp1a7giwXnryySdz5513ZsKECXn44YfTp0+fnH766Rk4cGC5o0HhKa+w7ixfvjyvvfZa\nXnnllbz88stZvnx59t5773LHokI5YkvFKZVKeeONN1Y4HRn4YJo1a5btttsu55xzTg466KC0a9eu\n3JFgvTJ16tTceOONee211/Kzn/0sU6ZMSV1dXT72sY+VOxoU1uc///nce++92XLLLTNgwIAMGDAg\n/fr1M1Ebq2TyKCrGokWLcuKJJ6a6ujrbbLNNkuTWW2/NeeedV+ZkUGwjRoxI586dc+KJJ+aLX/xi\nLrnkkjz11FPljgXrhXvuuSe9e/fOn//854bTkl9//fUMHz68zMmg2O6444506dIlgwcPzuDBg7Pf\nfvsptbwnR2ypGCeffHKef/75jBgxIgcffHDmzJmTl19+OZ/97GczefLkcseDwps3b17+9Kc/5c47\n78xvfvObtG7dOi+//HK5Y0Gh7bbbbjn77LNz2GGHpWPHjpk9e3Zqa2uz1VZb5fXXXy93PCisJUuW\n5P7772+4vvbVV1/NZz7zmQwcODAnnHBCueNRgRRbKsbmm2+eJ554Ip06dUqnTp0ya9asJGn4oAB8\ncP9eaidOnJjp06dn5513zt///vdyR4NC69ChQ+bMmZMkfnfBOvLGG29k7NixueCCC0x8yCqZPIqK\nUVdXt8K1f7W1tamuri5TIlg/7Lnnnnn00UfTvXv3HHDAAbngggvSv3//dOrUqdzRoPC6d++eKVOm\nNFxCkyTPPPNMNttsszKmguK76667Go7WTp48OTvssEOOPfbYDBgwoNzRqFCKLRVjt912y+jRo3Pq\nqac2jF177bX55Cc/WcZUUHxHHnlkrrnmmmy//fbljgLrna9//ev54he/mAsvvDDLly/Pgw8+mDPO\nOCMnnnhiuaNBoR111FHZf//9c9ppp2XAgAHp0aNHuSNR4ZyKTMV45plnss8++2TbbbfNo48+mn79\n+uXxxx/PQw89lO22267c8QBgBcuXL8/IkSPz4x//OPPmzUt1dXW++c1v5qKLLkpVVVW54wF8ZCi2\nVJSZM2fmuuuuy/PPP59NN900xx13XDbffPNyxwKA9/XWW2+lQ4cOZm4FKAPFFgAAgEJzjS1lNWbM\nmNXa7vjjj1/HSQBg9Wy++eardZrx9OnTP4Q0ACSO2FJmPXv2fN9tqqqq8uKLL34IaQDg/Y0dO3a1\ntjv22GPXcRIA3qXYAqyHnA0BAHyUKLYA6yFnQwBQNE7zZ024xhZgPTR16tRyRwCAJjn33HPLHYEC\nc8QWAACAQnPEFuAj4K677sqdd96Zt956K//+98zrrruujKkA4L0tXLhwhd9dW221VRkTUamalTsA\nAOvW6NGjc+ihh+b555/Pb37zm8ybNy833XRTli1bVu5oALBS06ZNy5577pl27dplm222ybbbbtuw\nwMo4YktZmbkV1r2f/vSnGTduXD772c+mY8eOGT9+fH73u9/l3nvvLXc0KCQT3MC691//9V/p2rVr\nHn300ey777657777cvbZZ+eLX/xiuaNRoVxjS1mZuRXWvXbt2mXevHlJkg4dOmTOnDlZtmxZevTo\nkTfeeKPM6aB43McW1r2NN944zzzzTDp16tTwu+u1117LwQcfnMcff7zc8ahAjthSVmZuhXWvXbt2\nmT9/ftq2bZtNNtkkU6ZMSefOnbNo0aJyR4NCUlhh3auvr0+nTp2SJK1atcqiRYvSvXv3vPDCC2VO\nRqVSbAHWc3vuuWduueWWHHvssTn00ENz6KGHpmXLltlnn33KHQ3WGya4gbVrq622ypNPPpnevXtn\nxx13zOWXX54OHTqkc+fO5Y5GhXIqMhXFzK2w9i1ZsiSlUikbbbRRli5dmh/96EeZN29ehg8f7gMC\nrKFp06blyCOPzMMPP7zCOhO0wQd30003pV27dhkwYEDuu+++HHrooVm8eHGuvPJKZ02wUootFWP0\n6NE5/fTTc+CBB2bChAk58MADc+edd2bw4MH51a9+Ve54ALCCww47LElyzjnnrDDBzTHHHFPmdLD+\nqKury9KlS9O6detyR6FCud0PFePdmVvHjx+f6urqjB8/PmPHjk379u3LHQ0K78Ybb8wBBxyQHXbY\nIf37988NN9xQ7kiwXnjooYdyzTXXpG/fvqmqqkqfPn1yxRVX5JJLLil3NCi0gw8+uNHjFi1apHXr\n1hk0aFCZElHpHLGlYpi5FdaN//3f/80FF1yQIUOGpGfPnpk6dWquuuqqnHHGGTnjjDPKHQ8KrVOn\nTpk1a1aSpHv37pkyZUpatWrV6Hca0HSr2of+fZ+Df2fyKCqGmVth3fj5z3+e22+/PXvssUfD2Oc+\n97kcccQRii2sIRPcwNp1zz33JHnnGvV777230Zwrzz77bNq2bVuuaFQ4xZaKYeZWWDfmzp2bXXfd\ntdHYLrvs4mgSrAXf+9738vrrr6d37975wQ9+0GiCG6Dp+vfvnySpqqrK/vvv3zBeVVWVbt265fzz\nzy9XNCqcU5GpGGZuhXVjyJAh2WOPPXLCCSc0jI0ZMyZ/+9vfcsUVV5QxGax/THADa0evXr0yefLk\ncsegQBRbgPXcl770pYwfPz477bRTevbsmWnTpuWJJ57I4MGDs+GGGzZs57Za0HQHH3xw/vjHP64w\nPmjQoNx2221lSATw0WRWZCqKmVth7WvVqlWOPPLI9OrVK61bt87HP/7xHHnkkamurs4GG2zQsABN\n98ADD6x0/MEHH/yQk8D6Zfny5Tn//POz7bbbNtwhY+LEiU7zZ5VcY0vF+PeZW7/whS9k6tSpOfXU\nU/PKK6+Y4AbWwDXXXFPuCLDeMcENrFvnnHNOfv/73+eHP/xhhg4dmiTZZpttcuaZZ2bIkCFlTkcl\ncioyFaOmpia/+c1vGs3c+ve//z1HHHFEXnrppTImg+JbtmxZHn744bz88sv50pe+lMWLF6eqqiot\nW7YsdzQopGbN3jnpraqqqlGp/fcJbr761a+WKx4UXs+ePXP//fdn8803b7jFz/Lly9OlSxe3+2Gl\nFFsqRseOHTNjxoxGp0QuW7YsXbp0yezZs8uYDIpt6tSpOeSQQzJ16tRUVVVl4cKFueWWWzJ+/HjX\n1cIaMsENrBtdunTJ22+/naqqqoZiW1dXlx49euStt94qdzwqkGtsqRhf+MIXVjhlcuzYsTniiCPK\nlAjWD6ecckoGDRqU+fPnN0wW9ZnPfCb3339/mZNB8Sm1sG707t07N910U6OxW2+9NX379i1TIiqd\nI7ZUDDO3wrrRtWvXvPbaa2nRokXDX72TpH379pk7d26Z00GxLV++PBdeeGHGjBmTt956K3Pnzs3E\niRMzffp01wHCGnj44YfTv3//DBo0KOPGjcuRRx6Zm266KXfddVd22223csejAjliS8UwcyusG61b\nt86iRYsajb399tvuDw1rwTnnnJPf/va3+eEPf5iqqqok70xwc9lll5U5GRTbHnvskUcffTRdunTJ\nvvvum+XLl+fuu+9WalklR2wB1nMnnXRSFi5cmMsvvzybbbZZ3n777Xzzm99Mq1atcumll5Y7HhSa\nCW4AKoPb/VBRzNwKa98FF1yQww8/PJ06dUpdXV3atm2bXr165a677ip3NCi8+fPnZ7PNNms0tmzZ\nsjRv7iMWrKmHHnooY8aMycsvv5zNNtssxx9/fPbcc89yx6JCORWZijF16tTstNNO6d+/f44//vgk\nye233+4aJVhD7du3z7333puHHnooN954YyZMmJC//e1vDTe8Bz44E9zAunH99ddn3333zfz589O3\nb98sXLgw+++/v7lWWCWnIlMxDjnkkPTu3Tvnnntuwy1+Zs+enb59+2batGnljgfrjSlTpmSDDTZI\nz549yx0FCs8EN7BubLfddrn00kvz2c9+tmFswoQJOeWUU/L888+XMRmVyhFbKsbDDz+ckSNHZoMN\nNmiYgKNjx47uYQtr6Pjjj8+DDz6YJPn1r3+d7bffPttuu21uvPHGMieD4jPBDawbb7zxRgYOHNho\nbMCAAXnzzTfLlIhK54gtFaOmpiZPPPFE2rdv3zABx9tvv5099tgjL774YrnjQWF169YtL7zwQlq1\napU99tgjw4cPT7t27fKd73wn//znP8sdDwBW8PnPfz5f//rXc9BBBzWM3XHHHbnqqqty8803lzEZ\nlUqxpWKYuRXWjXfvVzt//vxsscUWmTlzZpo1a5YOHTpkzpw55Y4HhWeCG1j7TjnllIwZMyYHHXRQ\nevbsmWnTpuX222/P8ccfnw4dOjRsN3LkyPKFpKKYso+KYeZWWDe6du2ap59+OpMnT84nP/nJNGvW\nLAsXLmw45R/44K6//vqccMIJGTx4cMOcEPvvv39+8Ytf5Jhjjil3PCisyZMnZ/fdd8+MGTMyY8aM\nJMluu+2WJ598smEbv8f4d4otFePdmVsff/zxPP/889l0002z9957p1kzl4LDmjjttNOy6667Jnnn\nGtskuf/++/Pxj3+8nLFgvTBq1KiMHz9+pRPcKLbwwd17773ljkDBOBWZimXmVlh7pkyZkubNm6em\npiZJ8txzz2Xp0qXp1atXeYNBwbVr1y5z5sxp9EfY5cuXp0OHDpk3b14ZkwF8tDgURsUwcyusO9ts\ns01DqU3euY2CUgtr7oADDsiECRMajU2cODEHHHBAmRIBfDQ5YkvFMHMrAEVjghuAyqDYUjHM3ApA\n0XzmM595322qqqpyzz33fAhpAD66TB5FxTBzKwBFY4IbgMqg2FIxzNwKAAB8EE5FpqKYuRUAAGgq\nxRYAAIBCc7sfAAAACk2xBQAAoNAUWwAAAApNsQUAAKDQFFsAAAAKTbEFAACg0BRbAAAACu3/A1t+\nPpf9g1V9AAAAAElFTkSuQmCC\n"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "# Get feature importance from the RandomForest model\n",
        "importances = clf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Plot the feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), iris.feature_names, rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "925a5f59"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The bar chart is showing the relative importance of each feature, making\n",
        "it easier to understand which features have the most predictive power.\n",
        "\n",
        "## Out-of-Bag (OOB) Error Estimate\n",
        "\n",
        "Random Forest uses **Out-of-Bag (OOB)** samples as an alternative to\n",
        "cross-validation. Since each tree is trained on a bootstrap sample,\n",
        "about one-third of the data is left out in each iteration. These\n",
        "“out-of-bag” samples can be used to estimate the model’s performance\n",
        "without the need for a separate validation set.\n",
        "\n",
        "### Enabling OOB in Python\n",
        "\n",
        "You can enable the out-of-bag error estimate by setting `oob_score=True`\n",
        "in the `RandomForestClassifier` or `RandomForestRegressor`."
      ],
      "id": "70ab1a19-a8ef-47ba-8891-237edd18a277"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9428571428571428"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Access the OOB score\n",
        "print(f\"OOB Score: {clf.oob_score_}\")"
      ],
      "id": "3ac6e332"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The OOB score is an unbiased estimate of the model’s performance, which\n",
        "is particularly useful when the dataset is small and splitting it\n",
        "further into training/validation sets might reduce training\n",
        "effectiveness.\n",
        "\n",
        "## Dealing with Imbalanced Data\n",
        "\n",
        "For imbalanced classification tasks (where one class is much more\n",
        "frequent than the others), Random Forest may be biased toward predicting\n",
        "the majority class. Several techniques can help mitigate this issue:\n",
        "\n",
        "-   **Class Weights:** You can assign higher weights to the minority\n",
        "    class to force the model to pay more attention to it."
      ],
      "id": "ed87ed67-f27d-462d-9afc-00d666b4a0fc"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "            </details>\n",
              "        </div>\n",
              "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
              "    // Get the parameter prefix from the closest toggleable content\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
              "\n",
              "    const originalStyle = element.style;\n",
              "    const computedStyle = window.getComputedStyle(element);\n",
              "    const originalWidth = computedStyle.width;\n",
              "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
              "\n",
              "    navigator.clipboard.writeText(fullParamName)\n",
              "        .then(() => {\n",
              "            element.style.width = originalWidth;\n",
              "            element.style.color = 'green';\n",
              "            element.innerHTML = \"Copied!\";\n",
              "\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        })\n",
              "        .catch(err => {\n",
              "            console.error('Failed to copy:', err);\n",
              "            element.style.color = 'red';\n",
              "            element.innerHTML = \"Failed!\";\n",
              "            setTimeout(() => {\n",
              "                element.innerHTML = originalHTML;\n",
              "                element.style = originalStyle;\n",
              "            }, 2000);\n",
              "        });\n",
              "    return false;\n",
              "}\n",
              "\n",
              "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
              "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
              "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
              "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
              "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
              "\n",
              "    element.setAttribute('title', fullParamName);\n",
              "});\n",
              "</script></body>"
            ]
          }
        }
      ],
      "source": [
        "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "clf.fit(X_train, y_train)"
      ],
      "id": "214ff8dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   **Resampling:** You can either oversample the minority class or\n",
        "    undersample the majority class."
      ],
      "id": "eb140e69-87a9-4c16-a93e-2a671a59dcd9"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)"
      ],
      "id": "e06634a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest in Practice: Best Practices\n",
        "\n",
        "-   **Cross-Validation:** Always perform cross-validation to ensure the\n",
        "    model generalizes well\n",
        "-   **Parallelization:** Random Forest naturally supports\n",
        "    parallelization. If using `scikit-learn`, set `n_jobs=-1` to utilize\n",
        "    all CPU cores for training.  \n",
        "-   **Ensemble Methods:** For better results, you can combine Random\n",
        "    Forest with other ensemble methods, such as boosting (e.g., XGBoost\n",
        "    or Gradient Boosting) to further improve performance.\n",
        "\n",
        "Random Forest is a highly flexible, non-parametric machine learning\n",
        "algorithm that can be used for both classification and regression tasks.\n",
        "Its ensemble-based approach reduces overfitting, improves predictive\n",
        "performance, and provides valuable insights like feature importance.\n",
        "Despite its many advantages, Random Forest is computationally intensive\n",
        "and may not be the best choice for real-time applications or datasets\n",
        "with extremely high dimensionality.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## References\n",
        "\n",
        "1.  Breiman, L. (2001). “Random Forests”. Machine Learning, 45(1), 5-32.\n",
        "2.  Pedregosa, F., et al. (2011). “Scikit-learn: Machine Learning in\n",
        "    Python”. Journal of Machine Learning Research, 12, 2825-2830.\n",
        "3.  Hastie, T., Tibshirani, R., & Friedman, J. (2009). “The Elements of\n",
        "    Statistical Learning”. Springer Series in Statistics.\n",
        "\n",
        "**Share on**\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer.php?u=https://mrislambd.github.io/dsandml/posts/randomforest/\" target=\"_blank\" style=\"color:#1877F2; text-decoration: none;\">\n",
        "\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https://mrislambd.github.io/dsandml/posts/randomforest/\" target=\"_blank\" style=\"color:#0077B5; text-decoration: none;\">\n",
        "\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.twitter.com/intent/tweet?url=https://mrislambd.github.io/dsandml/posts/randomforest/\" target=\"_blank\" style=\"color:#1DA1F2; text-decoration: none;\">\n",
        "\n",
        "</a>"
      ],
      "id": "34f35ae6-92bb-4097-b620-6044c167be3c"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<script src=\"https://giscus.app/client.js\"\n",
        "        data-repo=\"mrislambd/mrislambd.github.io\" \n",
        "        data-repo-id=\"R_kgDOMV8crA\"\n",
        "        data-category=\"Announcements\"\n",
        "        data-category-id=\"DIC_kwDOMV8crM4CjbQW\"\n",
        "        data-mapping=\"pathname\"\n",
        "        data-strict=\"0\"\n",
        "        data-reactions-enabled=\"1\"\n",
        "        data-emit-metadata=\"0\"\n",
        "        data-input-position=\"bottom\"\n",
        "        data-theme=\"light\"\n",
        "        data-lang=\"en\"\n",
        "        crossorigin=\"anonymous\"\n",
        "        async>\n",
        "</script>"
      ],
      "id": "b1dc9061-d3be-43fe-bd17-e3a236057f4e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [],
      "id": "9bf004cd-a3ef-4fdf-b10e-eb2f46cde9ee"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<script async defer crossorigin=\"anonymous\"\n",
        " src=\"https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v20.0\"></script>"
      ],
      "id": "9a38a122-145f-4587-aaeb-af29e4f59e46"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**You may also like**"
      ],
      "id": "65359e4b-6481-462b-aa4c-2a497b169f6b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/opt/hostedtoolcache/Python/3.10.18/x64/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  }
}